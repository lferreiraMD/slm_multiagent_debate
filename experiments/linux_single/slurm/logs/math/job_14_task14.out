Using persona diversity with 5 different personas
============================================================
Math Task - Multiagent Debate (NO COMPRESSION)
============================================================
Model: Qwen/Qwen3-14B
Persona diversity mode:
  Agent 1: a radical anarchist who views all imposed structures and hie...
  Agent 2: an enigma machine operator whose primary filter is signal-to...
  Agent 3: a Zen master who communicates only through non-sequiturs, ko...
  Agent 4: a deep-sea volcanologist focused on extremes of pressure, he...
  Agent 5: a systems engineer who focuses strictly on modularity, inter...
Agents: 5
Rounds: 3
Problems: 20
Generation params: {'temperature': 1.0, 'max_tokens': None, 'top_p': 1.0, 'n': 1}
============================================================
Using persona diversity with 5 different personas
============================================================
Math Task - Multiagent Debate (NO COMPRESSION)
============================================================
Model: Qwen/Qwen3-14B
Persona diversity mode:
  Agent 1: a radical anarchist who views all imposed structures and hie...
  Agent 2: an enigma machine operator whose primary filter is signal-to...
  Agent 3: a Zen master who communicates only through non-sequiturs, ko...
  Agent 4: a deep-sea volcanologist focused on extremes of pressure, he...
  Agent 5: a systems engineer who focuses strictly on modularity, inter...
Agents: 5
Rounds: 3
Problems: 20
Generation params: {'temperature': 1.0, 'max_tokens': None, 'top_p': 1.0, 'n': 1}
============================================================

--- Problem 1/20, Round 1, Agent 1/5 ---
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:41:29 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}

--- Problem 1/20, Round 1, Agent 1/5 ---
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:41:29 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:41:29 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:41:29 [model.py:1745] Using max model len 40960
INFO 12-04 13:41:29 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:41:29 [model.py:1745] Using max model len 40960
INFO 12-04 13:41:30 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:41:30 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3382958)[0;0m INFO 12-04 13:41:45 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3382957)[0;0m INFO 12-04 13:41:45 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3382958)[0;0m INFO 12-04 13:41:47 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:60469 backend=nccl
[1;36m(EngineCore_DP0 pid=3382957)[0;0m INFO 12-04 13:41:47 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:55213 backend=nccl
  0%|          | 0/20 [00:00<?, ?it/s][W1204 13:41:47.974696251 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:60469 (errno: 97 - Address family not supported by protocol).
  0%|          | 0/20 [00:00<?, ?it/s][W1204 13:41:47.977347612 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:55213 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3382958)[0;0m INFO 12-04 13:41:47 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3382957)[0;0m INFO 12-04 13:41:47 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3382958)[0;0m INFO 12-04 13:41:48 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3382957)[0;0m INFO 12-04 13:41:48 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3382957)[0;0m INFO 12-04 13:41:49 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3382957)[0;0m INFO 12-04 13:41:49 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3382958)[0;0m INFO 12-04 13:41:49 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3382958)[0;0m INFO 12-04 13:41:49 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m ERROR 12-04 13:41:50 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3382957 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3382958)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3382958)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3382958)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3382958)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382958)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3382957 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m ERROR 12-04 13:41:50 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3382958 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3382957)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3382957)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3382957)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3382957)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3382957)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3382958 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:41:50.181730976 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:41:50.199967503 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:42:11 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:42:12 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:42:12 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:42:12 [model.py:1745] Using max model len 40960
INFO 12-04 13:42:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:42:12 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:42:12 [model.py:1745] Using max model len 40960
INFO 12-04 13:42:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3384661)[0;0m INFO 12-04 13:42:30 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3384664)[0;0m INFO 12-04 13:42:30 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3384661)[0;0m INFO 12-04 13:42:32 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:40865 backend=nccl
[1;36m(EngineCore_DP0 pid=3384664)[0;0m INFO 12-04 13:42:32 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:33553 backend=nccl
[W1204 13:42:32.423539684 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:40865 (errno: 97 - Address family not supported by protocol).
[W1204 13:42:32.426484423 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:33553 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3384661)[0;0m INFO 12-04 13:42:32 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3384664)[0;0m INFO 12-04 13:42:32 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3384661)[0;0m INFO 12-04 13:42:32 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3384664)[0;0m INFO 12-04 13:42:32 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3384664)[0;0m INFO 12-04 13:42:33 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3384664)[0;0m INFO 12-04 13:42:33 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3384661)[0;0m INFO 12-04 13:42:33 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3384661)[0;0m INFO 12-04 13:42:33 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 287, in __init__
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.lm_head = ParallelLMHead(
[1;36m(EngineCore_DP0 pid=3384664)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]     torch.empty(
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384664)[0;0m ERROR 12-04 13:42:34 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 44.39 GiB of which 154.00 MiB is free. Process 3384661 has 17.56 GiB memory in use. Including non-PyTorch memory, this process has 26.67 GiB memory in use. Of the allocated memory 26.15 GiB is allocated by PyTorch, and 18.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3384664)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3384664)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3384664)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3384664)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3384664)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3384664)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 287, in __init__
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     self.lm_head = ParallelLMHead(
[1;36m(EngineCore_DP0 pid=3384664)[0;0m                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     torch.empty(
[1;36m(EngineCore_DP0 pid=3384664)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3384664)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3384664)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384664)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 44.39 GiB of which 154.00 MiB is free. Process 3384661 has 17.56 GiB memory in use. Including non-PyTorch memory, this process has 26.67 GiB memory in use. Of the allocated memory 26.15 GiB is allocated by PyTorch, and 18.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m ERROR 12-04 13:42:34 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Including non-PyTorch memory, this process has 17.56 GiB memory in use. Process 3384664 has 26.70 GiB memory in use. Of the allocated memory 17.04 GiB is allocated by PyTorch, and 18.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3384661)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3384661)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3384661)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3384661)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3384661)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Including non-PyTorch memory, this process has 17.56 GiB memory in use. Process 3384664 has 26.70 GiB memory in use. Of the allocated memory 17.04 GiB is allocated by PyTorch, and 18.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:42:35.425882528 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:42:35.458026097 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:42:56 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:42:56 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:42:56 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:42:56 [model.py:1745] Using max model len 40960
INFO 12-04 13:42:56 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:42:56 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:42:56 [model.py:1745] Using max model len 40960
INFO 12-04 13:42:56 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3386447)[0;0m INFO 12-04 13:43:11 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3386444)[0;0m INFO 12-04 13:43:11 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3386447)[0;0m INFO 12-04 13:43:13 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:57643 backend=nccl
[1;36m(EngineCore_DP0 pid=3386444)[0;0m INFO 12-04 13:43:13 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:53061 backend=nccl
[W1204 13:43:13.856165453 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:57643 (errno: 97 - Address family not supported by protocol).
[W1204 13:43:13.856215447 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:53061 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3386444)[0;0m INFO 12-04 13:43:13 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3386447)[0;0m INFO 12-04 13:43:13 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3386447)[0;0m INFO 12-04 13:43:14 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3386444)[0;0m INFO 12-04 13:43:14 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3386447)[0;0m INFO 12-04 13:43:15 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3386447)[0;0m INFO 12-04 13:43:15 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3386444)[0;0m INFO 12-04 13:43:15 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3386444)[0;0m INFO 12-04 13:43:15 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m ERROR 12-04 13:43:15 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 3386447 has 23.12 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3386444)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3386444)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3386444)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3386444)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386444)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 3386447 has 23.12 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m ERROR 12-04 13:43:15 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3386444 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3386447)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3386447)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3386447)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3386447)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3386447)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3386444 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:43:16.961870515 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:43:16.978769672 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:43:37 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:43:37 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:43:37 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:43:37 [model.py:1745] Using max model len 40960
INFO 12-04 13:43:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:43:38 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:43:38 [model.py:1745] Using max model len 40960
INFO 12-04 13:43:38 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3388160)[0;0m INFO 12-04 13:43:56 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3388163)[0;0m INFO 12-04 13:43:56 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3388160)[0;0m INFO 12-04 13:43:58 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:34569 backend=nccl
[1;36m(EngineCore_DP0 pid=3388163)[0;0m INFO 12-04 13:43:58 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:33107 backend=nccl
[W1204 13:43:58.496203465 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:33107 (errno: 97 - Address family not supported by protocol).
[W1204 13:43:58.496713387 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:34569 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3388160)[0;0m INFO 12-04 13:43:58 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3388163)[0;0m INFO 12-04 13:43:58 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3388160)[0;0m INFO 12-04 13:43:58 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3388163)[0;0m INFO 12-04 13:43:58 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3388160)[0;0m INFO 12-04 13:43:59 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3388160)[0;0m INFO 12-04 13:43:59 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3388163)[0;0m INFO 12-04 13:43:59 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3388163)[0;0m INFO 12-04 13:43:59 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m ERROR 12-04 13:44:00 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3388160 has 23.71 GiB memory in use. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3388163)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3388163)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3388163)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3388163)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388163)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3388160 has 23.71 GiB memory in use. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m ERROR 12-04 13:44:00 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Process 3388163 has 20.66 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3388160)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3388160)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3388160)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3388160)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3388160)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Process 3388163 has 20.66 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:44:01.502954564 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:44:01.522719119 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:44:22 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:44:22 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:44:22 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:44:22 [model.py:1745] Using max model len 40960
INFO 12-04 13:44:22 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:44:22 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:44:22 [model.py:1745] Using max model len 40960
INFO 12-04 13:44:22 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3389968)[0;0m INFO 12-04 13:44:37 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3389965)[0;0m INFO 12-04 13:44:37 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3389965)[0;0m INFO 12-04 13:44:39 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:49867 backend=nccl
[1;36m(EngineCore_DP0 pid=3389968)[0;0m INFO 12-04 13:44:39 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50549 backend=nccl
[W1204 13:44:39.440999793 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:49867 (errno: 97 - Address family not supported by protocol).
[W1204 13:44:39.445040072 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50549 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3389968)[0;0m INFO 12-04 13:44:39 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3389965)[0;0m INFO 12-04 13:44:39 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3389965)[0;0m INFO 12-04 13:44:39 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3389968)[0;0m INFO 12-04 13:44:39 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3389968)[0;0m INFO 12-04 13:44:40 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3389968)[0;0m INFO 12-04 13:44:40 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3389965)[0;0m INFO 12-04 13:44:40 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3389965)[0;0m INFO 12-04 13:44:40 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m ERROR 12-04 13:44:41 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Process 3389968 has 24.97 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3389965)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3389965)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3389965)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3389965)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389965)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Process 3389968 has 24.97 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m ERROR 12-04 13:44:41 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3389965 has 19.40 GiB memory in use. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3389968)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3389968)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3389968)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3389968)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3389968)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3389965 has 19.40 GiB memory in use. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:44:42.452220729 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:44:42.512951887 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:45:03 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:45:03 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:45:03 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:45:03 [model.py:1745] Using max model len 40960
INFO 12-04 13:45:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:45:03 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:45:03 [model.py:1745] Using max model len 40960
INFO 12-04 13:45:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3391619)[0;0m INFO 12-04 13:45:21 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3391710)[0;0m INFO 12-04 13:45:21 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3391619)[0;0m INFO 12-04 13:45:22 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:47721 backend=nccl
[1;36m(EngineCore_DP0 pid=3391710)[0;0m INFO 12-04 13:45:22 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:33451 backend=nccl
[W1204 13:45:22.936707745 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:33451 (errno: 97 - Address family not supported by protocol).
[W1204 13:45:22.939711147 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:47721 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3391619)[0;0m INFO 12-04 13:45:22 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3391710)[0;0m INFO 12-04 13:45:22 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3391619)[0;0m INFO 12-04 13:45:23 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3391710)[0;0m INFO 12-04 13:45:23 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3391710)[0;0m INFO 12-04 13:45:24 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3391710)[0;0m INFO 12-04 13:45:24 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3391619)[0;0m INFO 12-04 13:45:24 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3391619)[0;0m INFO 12-04 13:45:24 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m ERROR 12-04 13:45:24 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Process 3391710 has 24.94 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3391619)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3391619)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3391619)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3391619)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391619)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Process 3391710 has 24.94 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m ERROR 12-04 13:45:25 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3391619 has 19.43 GiB memory in use. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3391710)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3391710)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3391710)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3391710)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3391710)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3391619 has 19.43 GiB memory in use. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:45:25.005539121 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:45:25.046964838 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:45:46 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:45:46 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:45:47 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:45:47 [model.py:1745] Using max model len 40960
INFO 12-04 13:45:47 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:45:47 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:45:47 [model.py:1745] Using max model len 40960
INFO 12-04 13:45:47 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3393474)[0;0m INFO 12-04 13:46:01 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3393477)[0;0m INFO 12-04 13:46:01 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3393474)[0;0m INFO 12-04 13:46:03 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:54989 backend=nccl
[1;36m(EngineCore_DP0 pid=3393477)[0;0m INFO 12-04 13:46:03 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:47087 backend=nccl
[W1204 13:46:03.384633201 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:54989 (errno: 97 - Address family not supported by protocol).
[W1204 13:46:03.385635404 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:47087 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3393474)[0;0m INFO 12-04 13:46:03 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3393477)[0;0m INFO 12-04 13:46:03 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3393474)[0;0m INFO 12-04 13:46:03 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3393477)[0;0m INFO 12-04 13:46:03 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3393477)[0;0m INFO 12-04 13:46:04 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3393477)[0;0m INFO 12-04 13:46:04 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3393474)[0;0m INFO 12-04 13:46:04 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3393474)[0;0m INFO 12-04 13:46:04 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m ERROR 12-04 13:46:05 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3393477 has 24.33 GiB memory in use. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3393474)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3393474)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3393474)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3393474)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393474)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3393477 has 24.33 GiB memory in use. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m ERROR 12-04 13:46:05 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Process 3393474 has 20.02 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3393477)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3393477)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3393477)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3393477)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3393477)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Process 3393474 has 20.02 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:46:06.414597156 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:46:06.451395653 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:46:27 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:46:27 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:46:27 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:46:27 [model.py:1745] Using max model len 40960
INFO 12-04 13:46:27 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:46:27 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:46:27 [model.py:1745] Using max model len 40960
INFO 12-04 13:46:27 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3395144)[0;0m INFO 12-04 13:46:45 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3395141)[0;0m INFO 12-04 13:46:45 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3395144)[0;0m INFO 12-04 13:46:46 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:43069 backend=nccl
[1;36m(EngineCore_DP0 pid=3395141)[0;0m INFO 12-04 13:46:46 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:59177 backend=nccl
[W1204 13:46:46.807019352 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:59177 (errno: 97 - Address family not supported by protocol).
[W1204 13:46:46.810033913 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:43069 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3395144)[0;0m INFO 12-04 13:46:46 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3395141)[0;0m INFO 12-04 13:46:46 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3395144)[0;0m INFO 12-04 13:46:46 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3395141)[0;0m INFO 12-04 13:46:46 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3395144)[0;0m INFO 12-04 13:46:47 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3395144)[0;0m INFO 12-04 13:46:47 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3395141)[0;0m INFO 12-04 13:46:47 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3395141)[0;0m INFO 12-04 13:46:47 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m ERROR 12-04 13:46:48 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3395141 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3395144)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3395144)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3395144)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3395144)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395144)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3395141 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m ERROR 12-04 13:46:48 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3395144 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3395141)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3395141)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3395141)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3395141)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3395141)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3395144 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:46:49.831695293 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:46:49.835994208 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:47:10 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:47:10 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:47:10 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:47:10 [model.py:1745] Using max model len 40960
INFO 12-04 13:47:10 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:47:10 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:47:10 [model.py:1745] Using max model len 40960
INFO 12-04 13:47:10 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3396962)[0;0m INFO 12-04 13:47:25 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3396964)[0;0m INFO 12-04 13:47:25 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3396962)[0;0m INFO 12-04 13:47:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:39789 backend=nccl
[1;36m(EngineCore_DP0 pid=3396964)[0;0m INFO 12-04 13:47:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42781 backend=nccl
[W1204 13:47:27.595695351 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42781 (errno: 97 - Address family not supported by protocol).
[W1204 13:47:27.597827848 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:39789 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3396964)[0;0m INFO 12-04 13:47:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3396962)[0;0m INFO 12-04 13:47:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3396962)[0;0m INFO 12-04 13:47:27 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3396964)[0;0m INFO 12-04 13:47:27 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3396964)[0;0m INFO 12-04 13:47:28 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3396964)[0;0m INFO 12-04 13:47:28 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3396962)[0;0m INFO 12-04 13:47:28 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3396962)[0;0m INFO 12-04 13:47:28 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m ERROR 12-04 13:47:29 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3396962 has 22.46 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3396964)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3396964)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3396964)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3396964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396964)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3396962 has 22.46 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m ERROR 12-04 13:47:29 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3396964 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3396962)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3396962)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3396962)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3396962)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3396962)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3396964 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:47:30.646060077 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:47:30.650258656 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:47:51 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:47:51 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:47:51 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:47:51 [model.py:1745] Using max model len 40960
INFO 12-04 13:47:51 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:47:51 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:47:51 [model.py:1745] Using max model len 40960
INFO 12-04 13:47:51 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3398612)[0;0m INFO 12-04 13:48:10 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3398613)[0;0m INFO 12-04 13:48:10 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3398612)[0;0m INFO 12-04 13:48:11 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44739 backend=nccl
[1;36m(EngineCore_DP0 pid=3398613)[0;0m INFO 12-04 13:48:11 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44889 backend=nccl
[W1204 13:48:11.046725716 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44739 (errno: 97 - Address family not supported by protocol).
[W1204 13:48:11.048260769 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44889 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3398613)[0;0m INFO 12-04 13:48:11 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3398612)[0;0m INFO 12-04 13:48:11 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3398613)[0;0m INFO 12-04 13:48:12 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3398612)[0;0m INFO 12-04 13:48:12 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3398612)[0;0m INFO 12-04 13:48:13 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3398612)[0;0m INFO 12-04 13:48:13 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3398613)[0;0m INFO 12-04 13:48:13 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3398613)[0;0m INFO 12-04 13:48:13 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m ERROR 12-04 13:48:13 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 3398612 has 23.10 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3398613)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3398613)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3398613)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3398613)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398613)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 3398612 has 23.10 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m ERROR 12-04 13:48:14 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3398613 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3398612)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3398612)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3398612)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3398612)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3398612)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3398613 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:48:14.005454100 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:48:14.018429194 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:48:35 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:48:35 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:48:36 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:48:36 [model.py:1745] Using max model len 40960
INFO 12-04 13:48:36 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:48:36 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:48:36 [model.py:1745] Using max model len 40960
INFO 12-04 13:48:36 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3400403)[0;0m INFO 12-04 13:48:51 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3400400)[0;0m INFO 12-04 13:48:51 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3400400)[0;0m INFO 12-04 13:48:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:56661 backend=nccl
[1;36m(EngineCore_DP0 pid=3400403)[0;0m INFO 12-04 13:48:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:53969 backend=nccl
[W1204 13:48:53.517624924 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:53969 (errno: 97 - Address family not supported by protocol).
[W1204 13:48:53.520099521 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:56661 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3400403)[0;0m INFO 12-04 13:48:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3400400)[0;0m INFO 12-04 13:48:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3400403)[0;0m INFO 12-04 13:48:53 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3400400)[0;0m INFO 12-04 13:48:53 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3400403)[0;0m INFO 12-04 13:48:54 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3400403)[0;0m INFO 12-04 13:48:54 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3400400)[0;0m INFO 12-04 13:48:54 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3400400)[0;0m INFO 12-04 13:48:54 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m ERROR 12-04 13:48:55 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3400400 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3400403)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3400403)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3400403)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3400403)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400403)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3400400 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m ERROR 12-04 13:48:55 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3400403 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3400400)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3400400)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3400400)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3400400)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3400400)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3400403 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:48:56.534499936 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:48:56.535592966 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:49:17 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:49:17 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:49:17 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:49:17 [model.py:1745] Using max model len 40960
INFO 12-04 13:49:17 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:49:17 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:49:17 [model.py:1745] Using max model len 40960
INFO 12-04 13:49:17 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3402068)[0;0m INFO 12-04 13:49:35 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3402071)[0;0m INFO 12-04 13:49:35 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3402068)[0;0m INFO 12-04 13:49:36 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:58447 backend=nccl
[1;36m(EngineCore_DP0 pid=3402071)[0;0m INFO 12-04 13:49:36 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:40633 backend=nccl
[W1204 13:49:36.034690951 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:58447 (errno: 97 - Address family not supported by protocol).
[W1204 13:49:36.038342989 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:40633 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3402071)[0;0m INFO 12-04 13:49:36 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3402068)[0;0m INFO 12-04 13:49:36 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3402071)[0;0m INFO 12-04 13:49:37 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3402068)[0;0m INFO 12-04 13:49:37 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3402068)[0;0m INFO 12-04 13:49:38 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3402068)[0;0m INFO 12-04 13:49:38 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3402071)[0;0m INFO 12-04 13:49:38 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3402071)[0;0m INFO 12-04 13:49:38 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m ERROR 12-04 13:49:38 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 18.79 GiB memory in use. Process 3402068 has 25.59 GiB memory in use. Of the allocated memory 18.27 GiB is allocated by PyTorch, and 18.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3402071)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3402071)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3402071)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3402071)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402071)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 18.79 GiB memory in use. Process 3402068 has 25.59 GiB memory in use. Of the allocated memory 18.27 GiB is allocated by PyTorch, and 18.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m ERROR 12-04 13:49:39 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3402071 has 18.79 GiB memory in use. Including non-PyTorch memory, this process has 25.56 GiB memory in use. Of the allocated memory 25.04 GiB is allocated by PyTorch, and 18.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3402068)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3402068)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3402068)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3402068)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3402068)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3402071 has 18.79 GiB memory in use. Including non-PyTorch memory, this process has 25.56 GiB memory in use. Of the allocated memory 25.04 GiB is allocated by PyTorch, and 18.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:49:39.024775363 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:49:39.087917295 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:50:00 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:50:00 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:50:01 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:50:01 [model.py:1745] Using max model len 40960
INFO 12-04 13:50:01 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:50:01 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:50:01 [model.py:1745] Using max model len 40960
INFO 12-04 13:50:01 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3403850)[0;0m INFO 12-04 13:50:16 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3403853)[0;0m INFO 12-04 13:50:16 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3403853)[0;0m INFO 12-04 13:50:17 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:52601 backend=nccl
[1;36m(EngineCore_DP0 pid=3403850)[0;0m INFO 12-04 13:50:17 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:34785 backend=nccl
[W1204 13:50:17.225878471 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:52601 (errno: 97 - Address family not supported by protocol).
[W1204 13:50:17.227934553 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:34785 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3403850)[0;0m INFO 12-04 13:50:17 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3403853)[0;0m INFO 12-04 13:50:17 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3403850)[0;0m INFO 12-04 13:50:18 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3403853)[0;0m INFO 12-04 13:50:18 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3403850)[0;0m INFO 12-04 13:50:19 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3403850)[0;0m INFO 12-04 13:50:19 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3403853)[0;0m INFO 12-04 13:50:19 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3403853)[0;0m INFO 12-04 13:50:19 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m ERROR 12-04 13:50:20 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3403850 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3403853)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3403853)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3403853)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3403853)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403853)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3403850 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m ERROR 12-04 13:50:20 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3403853 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3403850)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3403850)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3403850)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3403850)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3403850)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3403853 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:50:20.261303328 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:50:20.269575919 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:50:42 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:50:42 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:50:42 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:50:42 [model.py:1745] Using max model len 40960
INFO 12-04 13:50:42 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:50:42 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:50:42 [model.py:1745] Using max model len 40960
INFO 12-04 13:50:42 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3405621)[0;0m INFO 12-04 13:51:01 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3405733)[0;0m INFO 12-04 13:51:01 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3405621)[0;0m INFO 12-04 13:51:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:37927 backend=nccl
[1;36m(EngineCore_DP0 pid=3405733)[0;0m INFO 12-04 13:51:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:59983 backend=nccl
[W1204 13:51:02.033512409 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:59983 (errno: 97 - Address family not supported by protocol).
[W1204 13:51:02.035544311 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:37927 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3405621)[0;0m INFO 12-04 13:51:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3405733)[0;0m INFO 12-04 13:51:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3405621)[0;0m INFO 12-04 13:51:03 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3405733)[0;0m INFO 12-04 13:51:03 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3405621)[0;0m INFO 12-04 13:51:04 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3405621)[0;0m INFO 12-04 13:51:04 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3405733)[0;0m INFO 12-04 13:51:04 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3405733)[0;0m INFO 12-04 13:51:04 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m ERROR 12-04 13:51:05 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3405733 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3405621)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3405621)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3405621)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3405621)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405621)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3405733 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m ERROR 12-04 13:51:05 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3405621 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3405733)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3405733)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3405733)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3405733)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3405733)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3405621 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:51:05.025085908 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:51:05.025147645 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:51:26 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:51:26 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:51:27 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:51:27 [model.py:1745] Using max model len 40960
INFO 12-04 13:51:27 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:51:27 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:51:27 [model.py:1745] Using max model len 40960
INFO 12-04 13:51:27 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3407667)[0;0m INFO 12-04 13:51:42 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3407670)[0;0m INFO 12-04 13:51:42 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3407670)[0;0m INFO 12-04 13:51:44 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:60791 backend=nccl
[1;36m(EngineCore_DP0 pid=3407667)[0;0m INFO 12-04 13:51:44 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:51993 backend=nccl
[W1204 13:51:44.936522107 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:60791 (errno: 97 - Address family not supported by protocol).
[W1204 13:51:44.940027128 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:51993 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3407667)[0;0m INFO 12-04 13:51:44 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3407670)[0;0m INFO 12-04 13:51:44 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3407670)[0;0m INFO 12-04 13:51:45 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3407667)[0;0m INFO 12-04 13:51:45 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3407667)[0;0m INFO 12-04 13:51:46 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3407667)[0;0m INFO 12-04 13:51:46 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3407670)[0;0m INFO 12-04 13:51:46 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3407670)[0;0m INFO 12-04 13:51:46 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m ERROR 12-04 13:51:46 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3407667 has 25.56 GiB memory in use. Including non-PyTorch memory, this process has 18.79 GiB memory in use. Of the allocated memory 18.27 GiB is allocated by PyTorch, and 18.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3407670)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3407670)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3407670)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3407670)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407670)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3407667 has 25.56 GiB memory in use. Including non-PyTorch memory, this process has 18.79 GiB memory in use. Of the allocated memory 18.27 GiB is allocated by PyTorch, and 18.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m ERROR 12-04 13:51:46 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 25.56 GiB memory in use. Process 3407670 has 18.79 GiB memory in use. Of the allocated memory 25.04 GiB is allocated by PyTorch, and 18.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3407667)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3407667)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3407667)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3407667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3407667)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 25.56 GiB memory in use. Process 3407670 has 18.79 GiB memory in use. Of the allocated memory 25.04 GiB is allocated by PyTorch, and 18.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:51:47.989426651 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:51:47.041872381 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:52:08 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:52:08 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:52:08 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:52:08 [model.py:1745] Using max model len 40960
INFO 12-04 13:52:08 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:52:09 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:52:09 [model.py:1745] Using max model len 40960
INFO 12-04 13:52:09 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3408543)[0;0m INFO 12-04 13:52:30 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3408540)[0;0m INFO 12-04 13:52:30 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3408543)[0;0m INFO 12-04 13:52:31 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:38017 backend=nccl
[1;36m(EngineCore_DP0 pid=3408540)[0;0m INFO 12-04 13:52:31 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:36415 backend=nccl
[W1204 13:52:31.292639386 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:38017 (errno: 97 - Address family not supported by protocol).
[W1204 13:52:31.293066969 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:36415 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3408543)[0;0m INFO 12-04 13:52:32 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3408540)[0;0m INFO 12-04 13:52:32 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3408543)[0;0m INFO 12-04 13:52:32 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3408540)[0;0m INFO 12-04 13:52:32 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3408540)[0;0m INFO 12-04 13:52:33 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3408540)[0;0m INFO 12-04 13:52:33 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3408543)[0;0m INFO 12-04 13:52:33 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3408543)[0;0m INFO 12-04 13:52:33 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m ERROR 12-04 13:52:34 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 3408543 has 23.10 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3408540)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3408540)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408540)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408540)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408540)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 3408543 has 23.10 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m ERROR 12-04 13:52:34 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3408540 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3408543)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3408543)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408543)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408543)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408543)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3408540 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:52:34.287475484 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:52:35.353511905 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:52:56 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:52:56 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:52:56 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:52:56 [model.py:1745] Using max model len 40960
INFO 12-04 13:52:56 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:52:56 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:52:56 [model.py:1745] Using max model len 40960
INFO 12-04 13:52:56 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3408667)[0;0m INFO 12-04 13:53:13 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3408670)[0;0m INFO 12-04 13:53:13 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3408670)[0;0m INFO 12-04 13:53:15 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:55007 backend=nccl
[1;36m(EngineCore_DP0 pid=3408667)[0;0m INFO 12-04 13:53:15 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:45359 backend=nccl
[W1204 13:53:15.380080633 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:55007 (errno: 97 - Address family not supported by protocol).
[W1204 13:53:15.382363878 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:45359 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3408667)[0;0m INFO 12-04 13:53:15 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3408670)[0;0m INFO 12-04 13:53:15 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3408670)[0;0m INFO 12-04 13:53:15 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3408667)[0;0m INFO 12-04 13:53:15 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3408670)[0;0m INFO 12-04 13:53:16 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3408670)[0;0m INFO 12-04 13:53:16 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3408667)[0;0m INFO 12-04 13:53:16 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3408667)[0;0m INFO 12-04 13:53:16 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m ERROR 12-04 13:53:17 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3408670 has 23.10 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3408667)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3408667)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408667)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408667)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408667)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3408670 has 23.10 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m ERROR 12-04 13:53:17 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3408667 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3408670)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3408670)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408670)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408670)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408670)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3408667 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:53:18.545875514 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:53:18.545875523 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:53:39 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:53:39 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:53:39 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:53:39 [model.py:1745] Using max model len 40960
INFO 12-04 13:53:39 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:53:39 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:53:39 [model.py:1745] Using max model len 40960
INFO 12-04 13:53:39 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3408829)[0;0m INFO 12-04 13:53:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3408832)[0;0m INFO 12-04 13:53:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3408829)[0;0m INFO 12-04 13:54:01 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:34219 backend=nccl
[1;36m(EngineCore_DP0 pid=3408832)[0;0m INFO 12-04 13:54:01 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:34495 backend=nccl
[W1204 13:54:01.478382724 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:34219 (errno: 97 - Address family not supported by protocol).
[W1204 13:54:01.481683197 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:34495 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3408832)[0;0m INFO 12-04 13:54:01 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3408829)[0;0m INFO 12-04 13:54:01 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3408832)[0;0m INFO 12-04 13:54:01 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3408829)[0;0m INFO 12-04 13:54:01 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3408832)[0;0m INFO 12-04 13:54:02 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3408832)[0;0m INFO 12-04 13:54:02 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3408829)[0;0m INFO 12-04 13:54:02 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3408829)[0;0m INFO 12-04 13:54:02 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 287, in __init__
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.lm_head = ParallelLMHead(
[1;36m(EngineCore_DP0 pid=3408832)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]     torch.empty(
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408832)[0;0m ERROR 12-04 13:54:03 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 44.39 GiB of which 154.00 MiB is free. Process 3408829 has 17.56 GiB memory in use. Including non-PyTorch memory, this process has 26.67 GiB memory in use. Of the allocated memory 26.15 GiB is allocated by PyTorch, and 18.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3408832)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408832)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408832)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408832)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408832)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408832)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 287, in __init__
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     self.lm_head = ParallelLMHead(
[1;36m(EngineCore_DP0 pid=3408832)[0;0m                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     torch.empty(
[1;36m(EngineCore_DP0 pid=3408832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408832)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408832)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408832)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 44.39 GiB of which 154.00 MiB is free. Process 3408829 has 17.56 GiB memory in use. Including non-PyTorch memory, this process has 26.67 GiB memory in use. Of the allocated memory 26.15 GiB is allocated by PyTorch, and 18.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m ERROR 12-04 13:54:03 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Including non-PyTorch memory, this process has 17.56 GiB memory in use. Process 3408832 has 26.70 GiB memory in use. Of the allocated memory 17.04 GiB is allocated by PyTorch, and 18.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3408829)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3408829)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408829)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408829)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408829)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Including non-PyTorch memory, this process has 17.56 GiB memory in use. Process 3408832 has 26.70 GiB memory in use. Of the allocated memory 17.04 GiB is allocated by PyTorch, and 18.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:54:04.375422871 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:54:04.400854114 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:54:25 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:54:25 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:54:25 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:54:25 [model.py:1745] Using max model len 40960
INFO 12-04 13:54:25 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:54:25 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:54:25 [model.py:1745] Using max model len 40960
INFO 12-04 13:54:25 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3408964)[0;0m INFO 12-04 13:54:41 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3408961)[0;0m INFO 12-04 13:54:41 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3408964)[0;0m INFO 12-04 13:54:43 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:45613 backend=nccl
[1;36m(EngineCore_DP0 pid=3408961)[0;0m INFO 12-04 13:54:43 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:47237 backend=nccl
[W1204 13:54:43.035228099 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:45613 (errno: 97 - Address family not supported by protocol).
[W1204 13:54:43.036664278 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:47237 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3408961)[0;0m INFO 12-04 13:54:43 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3408964)[0;0m INFO 12-04 13:54:43 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3408964)[0;0m INFO 12-04 13:54:44 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3408961)[0;0m INFO 12-04 13:54:44 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3408961)[0;0m INFO 12-04 13:54:45 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3408961)[0;0m INFO 12-04 13:54:45 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3408964)[0;0m INFO 12-04 13:54:45 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3408964)[0;0m INFO 12-04 13:54:45 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m ERROR 12-04 13:54:46 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 3408961 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3408964)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3408964)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408964)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408964)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408964)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 3408961 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m ERROR 12-04 13:54:46 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3408964 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3408961)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3408961)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3408961)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3408961)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3408961)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3408964 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:54:46.094122024 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:54:46.094122010 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:55:07 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:55:07 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:55:08 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:55:08 [model.py:1745] Using max model len 40960
INFO 12-04 13:55:08 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:55:08 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:55:08 [model.py:1745] Using max model len 40960
INFO 12-04 13:55:08 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3409131)[0;0m INFO 12-04 13:55:28 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3409134)[0;0m INFO 12-04 13:55:28 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3409134)[0;0m INFO 12-04 13:55:30 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:36079 backend=nccl
[1;36m(EngineCore_DP0 pid=3409131)[0;0m INFO 12-04 13:55:30 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:47135 backend=nccl
[W1204 13:55:30.459088474 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:36079 (errno: 97 - Address family not supported by protocol).
[W1204 13:55:30.459534077 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:47135 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3409134)[0;0m INFO 12-04 13:55:30 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3409131)[0;0m INFO 12-04 13:55:30 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3409131)[0;0m INFO 12-04 13:55:30 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3409134)[0;0m INFO 12-04 13:55:30 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3409131)[0;0m INFO 12-04 13:55:31 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3409131)[0;0m INFO 12-04 13:55:31 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3409134)[0;0m INFO 12-04 13:55:31 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3409134)[0;0m INFO 12-04 13:55:31 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m ERROR 12-04 13:55:32 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3409131 has 23.10 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409134)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409134)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409134)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409134)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409134)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3409131 has 23.10 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m ERROR 12-04 13:55:32 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3409134 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409131)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409131)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409131)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409131)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409131)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3409134 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:55:33.557876346 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:55:33.565194437 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:55:54 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:55:54 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:55:54 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:55:54 [model.py:1745] Using max model len 40960
INFO 12-04 13:55:54 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:55:54 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:55:54 [model.py:1745] Using max model len 40960
INFO 12-04 13:55:54 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3409341)[0;0m INFO 12-04 13:56:11 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3409338)[0;0m INFO 12-04 13:56:11 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3409338)[0;0m INFO 12-04 13:56:13 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42685 backend=nccl
[1;36m(EngineCore_DP0 pid=3409341)[0;0m INFO 12-04 13:56:13 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:53937 backend=nccl
[W1204 13:56:13.427322288 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42685 (errno: 97 - Address family not supported by protocol).
[W1204 13:56:13.429829363 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:53937 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3409341)[0;0m INFO 12-04 13:56:13 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3409338)[0;0m INFO 12-04 13:56:13 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3409341)[0;0m INFO 12-04 13:56:13 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3409338)[0;0m INFO 12-04 13:56:13 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3409341)[0;0m INFO 12-04 13:56:14 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3409341)[0;0m INFO 12-04 13:56:14 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3409338)[0;0m INFO 12-04 13:56:14 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3409338)[0;0m INFO 12-04 13:56:14 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m ERROR 12-04 13:56:15 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 3409338 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409341)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409341)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409341)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409341)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409341)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 3409338 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m ERROR 12-04 13:56:15 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3409341 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409338)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409338)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409338)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409338)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409338)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3409341 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:56:16.503811516 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:56:16.508984690 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:56:37 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:56:37 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:56:37 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:56:37 [model.py:1745] Using max model len 40960
INFO 12-04 13:56:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:56:37 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:56:37 [model.py:1745] Using max model len 40960
INFO 12-04 13:56:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3409471)[0;0m INFO 12-04 13:56:58 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3409472)[0;0m INFO 12-04 13:56:58 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3409472)[0;0m INFO 12-04 13:56:59 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:34417 backend=nccl
[1;36m(EngineCore_DP0 pid=3409471)[0;0m INFO 12-04 13:56:59 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42111 backend=nccl
[W1204 13:56:59.168826879 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:34417 (errno: 97 - Address family not supported by protocol).
[W1204 13:56:59.170973822 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42111 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3409471)[0;0m INFO 12-04 13:56:59 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3409472)[0;0m INFO 12-04 13:56:59 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3409472)[0;0m INFO 12-04 13:57:00 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3409471)[0;0m INFO 12-04 13:57:00 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3409472)[0;0m INFO 12-04 13:57:01 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3409472)[0;0m INFO 12-04 13:57:01 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3409471)[0;0m INFO 12-04 13:57:01 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3409471)[0;0m INFO 12-04 13:57:01 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m ERROR 12-04 13:57:02 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3409472 has 24.94 GiB memory in use. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409471)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409471)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409471)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409471)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409471)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3409472 has 24.94 GiB memory in use. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m ERROR 12-04 13:57:02 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Process 3409471 has 19.43 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409472)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409472)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409472)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409472)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409472)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Process 3409471 has 19.43 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:57:02.208517683 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:57:02.244568887 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:57:24 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:57:24 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:57:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:57:24 [model.py:1745] Using max model len 40960
INFO 12-04 13:57:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:57:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:57:24 [model.py:1745] Using max model len 40960
INFO 12-04 13:57:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3409771)[0;0m INFO 12-04 13:57:40 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3409768)[0;0m INFO 12-04 13:57:40 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3409768)[0;0m INFO 12-04 13:57:42 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:54729 backend=nccl
[1;36m(EngineCore_DP0 pid=3409771)[0;0m INFO 12-04 13:57:42 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:36285 backend=nccl
[W1204 13:57:42.053616864 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:54729 (errno: 97 - Address family not supported by protocol).
[W1204 13:57:42.053928412 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:36285 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3409771)[0;0m INFO 12-04 13:57:42 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3409768)[0;0m INFO 12-04 13:57:42 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3409771)[0;0m INFO 12-04 13:57:43 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3409768)[0;0m INFO 12-04 13:57:43 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3409768)[0;0m INFO 12-04 13:57:44 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3409768)[0;0m INFO 12-04 13:57:44 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3409771)[0;0m INFO 12-04 13:57:44 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3409771)[0;0m INFO 12-04 13:57:44 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m ERROR 12-04 13:57:45 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 3409771 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409768)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409768)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409768)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409768)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409768)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 3409771 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m ERROR 12-04 13:57:45 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3409768 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409771)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409771)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409771)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409771)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409771)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3409768 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:57:45.235962694 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:57:45.235962623 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:58:07 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:58:07 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:58:07 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:58:07 [model.py:1745] Using max model len 40960
INFO 12-04 13:58:07 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:58:07 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:58:07 [model.py:1745] Using max model len 40960
INFO 12-04 13:58:07 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3409902)[0;0m INFO 12-04 13:58:28 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3409905)[0;0m INFO 12-04 13:58:28 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3409902)[0;0m INFO 12-04 13:58:30 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42765 backend=nccl
[1;36m(EngineCore_DP0 pid=3409905)[0;0m INFO 12-04 13:58:30 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:35411 backend=nccl
[W1204 13:58:30.608944052 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:35411 (errno: 97 - Address family not supported by protocol).
[W1204 13:58:30.608945439 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42765 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3409902)[0;0m INFO 12-04 13:58:30 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3409905)[0;0m INFO 12-04 13:58:30 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3409905)[0;0m INFO 12-04 13:58:30 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3409902)[0;0m INFO 12-04 13:58:30 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3409905)[0;0m INFO 12-04 13:58:31 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3409905)[0;0m INFO 12-04 13:58:31 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3409902)[0;0m INFO 12-04 13:58:31 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3409902)[0;0m INFO 12-04 13:58:31 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m ERROR 12-04 13:58:32 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 3409905 has 23.71 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409902)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409902)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409902)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409902)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409902)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 3409905 has 23.71 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m ERROR 12-04 13:58:32 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3409902 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3409905)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3409905)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3409905)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3409905)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3409905)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3409902 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:58:33.600730479 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:58:33.618822660 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:58:54 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:58:54 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:58:54 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:58:54 [model.py:1745] Using max model len 40960
INFO 12-04 13:58:54 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:58:54 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:58:54 [model.py:1745] Using max model len 40960
INFO 12-04 13:58:54 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3410048)[0;0m INFO 12-04 13:59:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3410045)[0;0m INFO 12-04 13:59:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3410048)[0;0m INFO 12-04 13:59:14 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:57031 backend=nccl
[1;36m(EngineCore_DP0 pid=3410045)[0;0m INFO 12-04 13:59:14 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:60999 backend=nccl
[W1204 13:59:14.622990823 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:57031 (errno: 97 - Address family not supported by protocol).
[W1204 13:59:14.625600706 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:60999 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3410048)[0;0m INFO 12-04 13:59:14 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3410045)[0;0m INFO 12-04 13:59:14 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3410048)[0;0m INFO 12-04 13:59:14 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3410045)[0;0m INFO 12-04 13:59:14 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3410048)[0;0m INFO 12-04 13:59:15 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3410048)[0;0m INFO 12-04 13:59:15 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3410045)[0;0m INFO 12-04 13:59:15 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3410045)[0;0m INFO 12-04 13:59:15 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m ERROR 12-04 13:59:16 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3410045 has 24.94 GiB memory in use. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410048)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410048)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410048)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410048)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410048)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3410045 has 24.94 GiB memory in use. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m ERROR 12-04 13:59:16 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Process 3410048 has 19.40 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410045)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410045)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410045)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410045)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410045)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Process 3410048 has 19.40 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:59:17.641739007 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:59:17.680077837 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:59:38 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:59:38 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:59:38 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:59:38 [model.py:1745] Using max model len 40960
INFO 12-04 13:59:38 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:59:38 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:59:38 [model.py:1745] Using max model len 40960
INFO 12-04 13:59:38 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3410180)[0;0m INFO 12-04 14:00:01 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3410183)[0;0m INFO 12-04 14:00:01 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3410183)[0;0m INFO 12-04 14:00:03 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44381 backend=nccl
[1;36m(EngineCore_DP0 pid=3410180)[0;0m INFO 12-04 14:00:03 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50455 backend=nccl
[W1204 14:00:03.468532200 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44381 (errno: 97 - Address family not supported by protocol).
[W1204 14:00:03.471950261 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50455 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3410183)[0;0m INFO 12-04 14:00:03 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3410180)[0;0m INFO 12-04 14:00:03 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3410183)[0;0m INFO 12-04 14:00:03 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3410180)[0;0m INFO 12-04 14:00:03 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3410183)[0;0m INFO 12-04 14:00:04 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3410183)[0;0m INFO 12-04 14:00:04 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3410180)[0;0m INFO 12-04 14:00:04 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3410180)[0;0m INFO 12-04 14:00:04 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m ERROR 12-04 14:00:05 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 3410183 has 23.10 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410180)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410180)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410180)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410180)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 3410183 has 23.10 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m ERROR 12-04 14:00:05 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3410180 has 21.28 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410183)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410183)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410183)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410183)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410183)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3410180 has 21.28 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:00:06.486812823 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:00:06.492601638 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:00:27 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:00:27 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:00:27 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:00:27 [model.py:1745] Using max model len 40960
INFO 12-04 14:00:27 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:00:27 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:00:27 [model.py:1745] Using max model len 40960
INFO 12-04 14:00:27 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3410473)[0;0m INFO 12-04 14:00:44 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3410451)[0;0m INFO 12-04 14:00:44 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3410473)[0;0m INFO 12-04 14:00:46 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:38561 backend=nccl
[1;36m(EngineCore_DP0 pid=3410451)[0;0m INFO 12-04 14:00:46 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50349 backend=nccl
[W1204 14:00:46.277754000 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:38561 (errno: 97 - Address family not supported by protocol).
[W1204 14:00:46.277754192 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50349 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3410473)[0;0m INFO 12-04 14:00:47 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3410451)[0;0m INFO 12-04 14:00:47 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3410473)[0;0m INFO 12-04 14:00:47 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3410451)[0;0m INFO 12-04 14:00:47 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3410473)[0;0m INFO 12-04 14:00:48 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3410473)[0;0m INFO 12-04 14:00:48 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3410451)[0;0m INFO 12-04 14:00:48 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3410451)[0;0m INFO 12-04 14:00:48 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 287, in __init__
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.lm_head = ParallelLMHead(
[1;36m(EngineCore_DP0 pid=3410473)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]     torch.empty(
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410473)[0;0m ERROR 12-04 14:00:49 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 44.39 GiB of which 154.00 MiB is free. Including non-PyTorch memory, this process has 26.67 GiB memory in use. Process 3410451 has 17.56 GiB memory in use. Of the allocated memory 26.15 GiB is allocated by PyTorch, and 18.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410473)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410473)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410473)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410473)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410473)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410473)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 287, in __init__
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     self.lm_head = ParallelLMHead(
[1;36m(EngineCore_DP0 pid=3410473)[0;0m                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     torch.empty(
[1;36m(EngineCore_DP0 pid=3410473)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410473)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410473)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410473)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 44.39 GiB of which 154.00 MiB is free. Including non-PyTorch memory, this process has 26.67 GiB memory in use. Process 3410451 has 17.56 GiB memory in use. Of the allocated memory 26.15 GiB is allocated by PyTorch, and 18.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m ERROR 12-04 14:00:49 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Process 3410473 has 26.70 GiB memory in use. Including non-PyTorch memory, this process has 17.56 GiB memory in use. Of the allocated memory 17.04 GiB is allocated by PyTorch, and 18.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410451)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410451)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410451)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410451)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410451)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Process 3410473 has 26.70 GiB memory in use. Including non-PyTorch memory, this process has 17.56 GiB memory in use. Of the allocated memory 17.04 GiB is allocated by PyTorch, and 18.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:00:49.245558893 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:00:49.264741625 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:01:11 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:01:11 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:01:11 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:01:11 [model.py:1745] Using max model len 40960
INFO 12-04 14:01:11 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:01:11 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:01:11 [model.py:1745] Using max model len 40960
INFO 12-04 14:01:11 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3410636)[0;0m INFO 12-04 14:01:33 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3410633)[0;0m INFO 12-04 14:01:33 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3410633)[0;0m INFO 12-04 14:01:35 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:58433 backend=nccl
[1;36m(EngineCore_DP0 pid=3410636)[0;0m INFO 12-04 14:01:35 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:60333 backend=nccl
[W1204 14:01:35.932882235 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:58433 (errno: 97 - Address family not supported by protocol).
[W1204 14:01:35.934782487 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:60333 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3410633)[0;0m INFO 12-04 14:01:35 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3410636)[0;0m INFO 12-04 14:01:35 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3410636)[0;0m INFO 12-04 14:01:36 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3410633)[0;0m INFO 12-04 14:01:36 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3410633)[0;0m INFO 12-04 14:01:37 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3410633)[0;0m INFO 12-04 14:01:37 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3410636)[0;0m INFO 12-04 14:01:37 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3410636)[0;0m INFO 12-04 14:01:37 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m ERROR 12-04 14:01:37 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3410633 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m ERROR 12-04 14:01:37 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3410636 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410633)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410636)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410633)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410633)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410633)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410633)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410633)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3410636 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410636)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410636)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410636)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410636)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3410633 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:01:38.974053026 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:01:38.983074004 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:01:59 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:01:59 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:01:59 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:01:59 [model.py:1745] Using max model len 40960
INFO 12-04 14:01:59 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:02:00 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:02:00 [model.py:1745] Using max model len 40960
INFO 12-04 14:02:00 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3410760)[0;0m INFO 12-04 14:02:17 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3410763)[0;0m INFO 12-04 14:02:17 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3410760)[0;0m INFO 12-04 14:02:19 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44259 backend=nccl
[1;36m(EngineCore_DP0 pid=3410763)[0;0m INFO 12-04 14:02:19 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42439 backend=nccl
[W1204 14:02:19.859941399 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44259 (errno: 97 - Address family not supported by protocol).
[W1204 14:02:19.862579498 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42439 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3410763)[0;0m INFO 12-04 14:02:19 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3410760)[0;0m INFO 12-04 14:02:19 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3410760)[0;0m INFO 12-04 14:02:20 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3410763)[0;0m INFO 12-04 14:02:20 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3410760)[0;0m INFO 12-04 14:02:21 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3410760)[0;0m INFO 12-04 14:02:21 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3410763)[0;0m INFO 12-04 14:02:21 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3410763)[0;0m INFO 12-04 14:02:21 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m ERROR 12-04 14:02:21 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3410760 has 22.50 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m ERROR 12-04 14:02:21 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3410763 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410760)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410763)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410763)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410763)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410763)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410763)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3410760 has 22.50 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410760)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410760)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410760)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410760)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410760)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3410763 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:02:22.926174822 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:02:22.926102518 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:02:43 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:02:43 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:02:43 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:02:43 [model.py:1745] Using max model len 40960
INFO 12-04 14:02:43 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:02:43 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:02:43 [model.py:1745] Using max model len 40960
INFO 12-04 14:02:43 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3410897)[0;0m INFO 12-04 14:03:05 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3410894)[0;0m INFO 12-04 14:03:05 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3410897)[0;0m INFO 12-04 14:03:07 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:41263 backend=nccl
[1;36m(EngineCore_DP0 pid=3410894)[0;0m INFO 12-04 14:03:07 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:37669 backend=nccl
[W1204 14:03:07.839552658 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:37669 (errno: 97 - Address family not supported by protocol).
[W1204 14:03:07.839526802 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:41263 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3410894)[0;0m INFO 12-04 14:03:07 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3410897)[0;0m INFO 12-04 14:03:07 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3410894)[0;0m INFO 12-04 14:03:08 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3410897)[0;0m INFO 12-04 14:03:08 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3410897)[0;0m INFO 12-04 14:03:08 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3410897)[0;0m INFO 12-04 14:03:08 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3410894)[0;0m INFO 12-04 14:03:08 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3410894)[0;0m INFO 12-04 14:03:08 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m ERROR 12-04 14:03:09 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Process 3410897 has 24.33 GiB memory in use. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410894)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410894)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410894)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410894)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410894)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Process 3410897 has 24.33 GiB memory in use. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m ERROR 12-04 14:03:09 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Process 3410894 has 20.02 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3410897)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3410897)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3410897)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3410897)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3410897)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Process 3410894 has 20.02 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:03:10.847718007 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:03:10.880507135 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:03:31 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:03:31 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:03:31 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:03:31 [model.py:1745] Using max model len 40960
INFO 12-04 14:03:31 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:03:31 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:03:31 [model.py:1745] Using max model len 40960
INFO 12-04 14:03:31 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3411046)[0;0m INFO 12-04 14:03:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3411043)[0;0m INFO 12-04 14:03:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3411046)[0;0m INFO 12-04 14:03:51 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:53613 backend=nccl
[1;36m(EngineCore_DP0 pid=3411043)[0;0m INFO 12-04 14:03:51 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:54405 backend=nccl
[W1204 14:03:51.521542896 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:53613 (errno: 97 - Address family not supported by protocol).
[W1204 14:03:51.522561862 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:54405 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3411043)[0;0m INFO 12-04 14:03:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3411046)[0;0m INFO 12-04 14:03:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3411046)[0;0m INFO 12-04 14:03:51 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3411043)[0;0m INFO 12-04 14:03:51 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3411043)[0;0m INFO 12-04 14:03:52 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3411043)[0;0m INFO 12-04 14:03:52 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3411046)[0;0m INFO 12-04 14:03:52 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3411046)[0;0m INFO 12-04 14:03:52 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m ERROR 12-04 14:03:53 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3411043 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411046)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411046)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411046)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411046)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411046)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3411043 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m ERROR 12-04 14:03:53 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3411046 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411043)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411043)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411043)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411043)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411043)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3411046 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:03:54.592043200 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:03:54.609223547 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:04:15 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:04:15 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:04:15 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:04:15 [model.py:1745] Using max model len 40960
INFO 12-04 14:04:15 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:04:15 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:04:15 [model.py:1745] Using max model len 40960
INFO 12-04 14:04:15 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3411180)[0;0m INFO 12-04 14:04:36 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3411177)[0;0m INFO 12-04 14:04:36 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3411180)[0;0m INFO 12-04 14:04:38 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:54987 backend=nccl
[1;36m(EngineCore_DP0 pid=3411177)[0;0m INFO 12-04 14:04:38 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:47187 backend=nccl
[W1204 14:04:38.595689516 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:54987 (errno: 97 - Address family not supported by protocol).
[W1204 14:04:38.595689383 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:47187 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3411180)[0;0m INFO 12-04 14:04:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3411177)[0;0m INFO 12-04 14:04:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3411177)[0;0m INFO 12-04 14:04:38 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3411180)[0;0m INFO 12-04 14:04:38 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3411177)[0;0m INFO 12-04 14:04:39 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3411177)[0;0m INFO 12-04 14:04:39 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3411180)[0;0m INFO 12-04 14:04:39 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3411180)[0;0m INFO 12-04 14:04:39 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m ERROR 12-04 14:04:40 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 3411180 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411177)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411177)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411177)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411177)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411177)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 3411180 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m ERROR 12-04 14:04:40 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3411177 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411180)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411180)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411180)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411180)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411180)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3411177 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:04:41.608879689 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:04:41.613501516 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:05:02 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:05:02 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:05:02 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:05:02 [model.py:1745] Using max model len 40960
INFO 12-04 14:05:02 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:05:02 [model.py:1745] Using max model len 40960
INFO 12-04 14:05:02 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:05:02 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3411315)[0;0m INFO 12-04 14:05:19 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3411316)[0;0m INFO 12-04 14:05:19 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3411315)[0;0m INFO 12-04 14:05:21 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:34267 backend=nccl
[1;36m(EngineCore_DP0 pid=3411316)[0;0m INFO 12-04 14:05:21 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:34815 backend=nccl
[W1204 14:05:21.610361122 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:34267 (errno: 97 - Address family not supported by protocol).
[W1204 14:05:21.612283656 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:34815 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3411316)[0;0m INFO 12-04 14:05:21 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3411315)[0;0m INFO 12-04 14:05:21 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3411316)[0;0m INFO 12-04 14:05:21 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3411315)[0;0m INFO 12-04 14:05:21 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3411316)[0;0m INFO 12-04 14:05:22 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3411316)[0;0m INFO 12-04 14:05:22 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3411315)[0;0m INFO 12-04 14:05:22 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3411315)[0;0m INFO 12-04 14:05:22 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m ERROR 12-04 14:05:23 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 3411316 has 23.71 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411315)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411315)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411315)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411315)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411315)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 3411316 has 23.71 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m ERROR 12-04 14:05:23 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3411315 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411316)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411316)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411316)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411316)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411316)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3411315 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:05:24.702348387 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:05:24.719188655 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:05:45 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:05:45 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:05:45 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:05:45 [model.py:1745] Using max model len 40960
INFO 12-04 14:05:45 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:05:45 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:05:45 [model.py:1745] Using max model len 40960
INFO 12-04 14:05:45 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3411521)[0;0m INFO 12-04 14:06:06 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3411520)[0;0m INFO 12-04 14:06:06 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3411520)[0;0m INFO 12-04 14:06:07 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:36471 backend=nccl
[1;36m(EngineCore_DP0 pid=3411521)[0;0m INFO 12-04 14:06:07 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:56839 backend=nccl
[W1204 14:06:07.204229708 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:36471 (errno: 97 - Address family not supported by protocol).
[W1204 14:06:07.207546726 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:56839 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3411520)[0;0m INFO 12-04 14:06:07 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3411521)[0;0m INFO 12-04 14:06:07 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3411521)[0;0m INFO 12-04 14:06:08 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3411520)[0;0m INFO 12-04 14:06:08 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3411521)[0;0m INFO 12-04 14:06:09 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3411521)[0;0m INFO 12-04 14:06:09 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3411520)[0;0m INFO 12-04 14:06:09 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3411520)[0;0m INFO 12-04 14:06:09 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m ERROR 12-04 14:06:10 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Process 3411521 has 24.94 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411520)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411520)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411520)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411520)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411520)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Process 3411521 has 24.94 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m ERROR 12-04 14:06:10 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Process 3411520 has 19.38 GiB memory in use. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411521)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411521)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411521)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411521)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411521)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Process 3411520 has 19.38 GiB memory in use. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:06:10.194800258 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:06:10.232027689 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:06:31 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:06:32 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:06:32 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:06:32 [model.py:1745] Using max model len 40960
INFO 12-04 14:06:32 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:06:32 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:06:32 [model.py:1745] Using max model len 40960
INFO 12-04 14:06:32 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3411750)[0;0m INFO 12-04 14:06:47 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3411753)[0;0m INFO 12-04 14:06:47 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3411750)[0;0m INFO 12-04 14:06:49 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:34127 backend=nccl
[1;36m(EngineCore_DP0 pid=3411753)[0;0m INFO 12-04 14:06:49 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:49129 backend=nccl
[W1204 14:06:49.060029154 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:49129 (errno: 97 - Address family not supported by protocol).
[W1204 14:06:49.060047752 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:34127 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3411753)[0;0m INFO 12-04 14:06:49 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3411750)[0;0m INFO 12-04 14:06:49 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3411750)[0;0m INFO 12-04 14:06:50 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3411753)[0;0m INFO 12-04 14:06:50 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3411750)[0;0m INFO 12-04 14:06:51 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3411750)[0;0m INFO 12-04 14:06:51 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3411753)[0;0m INFO 12-04 14:06:51 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3411753)[0;0m INFO 12-04 14:06:51 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m ERROR 12-04 14:06:52 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3411750 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411753)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411753)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411753)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411753)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411753)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3411750 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m ERROR 12-04 14:06:52 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3411753 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411750)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411750)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411750)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411750)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411750)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3411753 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:06:52.147704957 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:06:52.152369817 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:07:13 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:07:13 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:07:14 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:07:14 [model.py:1745] Using max model len 40960
INFO 12-04 14:07:14 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:07:14 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:07:14 [model.py:1745] Using max model len 40960
INFO 12-04 14:07:14 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3411883)[0;0m INFO 12-04 14:07:33 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3411886)[0;0m INFO 12-04 14:07:33 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3411883)[0;0m INFO 12-04 14:07:34 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:59295 backend=nccl
[1;36m(EngineCore_DP0 pid=3411886)[0;0m INFO 12-04 14:07:34 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:35485 backend=nccl
[W1204 14:07:34.032763029 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:59295 (errno: 97 - Address family not supported by protocol).
[W1204 14:07:34.035182321 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:35485 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3411883)[0;0m INFO 12-04 14:07:34 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3411886)[0;0m INFO 12-04 14:07:34 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3411883)[0;0m INFO 12-04 14:07:35 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3411886)[0;0m INFO 12-04 14:07:35 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3411886)[0;0m INFO 12-04 14:07:36 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3411886)[0;0m INFO 12-04 14:07:36 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3411883)[0;0m INFO 12-04 14:07:36 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3411883)[0;0m INFO 12-04 14:07:36 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m ERROR 12-04 14:07:36 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 3411886 has 23.71 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411883)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411883)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411883)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411883)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411883)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 3411886 has 23.71 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m ERROR 12-04 14:07:37 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3411883 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3411886)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3411886)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3411886)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3411886)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3411886)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3411883 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:07:37.039911543 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:07:37.125105000 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:07:58 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:07:58 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:07:59 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:07:59 [model.py:1745] Using max model len 40960
INFO 12-04 14:07:59 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:07:59 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:07:59 [model.py:1745] Using max model len 40960
INFO 12-04 14:07:59 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3412013)[0;0m INFO 12-04 14:08:15 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3412010)[0;0m INFO 12-04 14:08:15 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3412013)[0;0m INFO 12-04 14:08:16 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:52093 backend=nccl
[1;36m(EngineCore_DP0 pid=3412010)[0;0m INFO 12-04 14:08:16 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:55919 backend=nccl
[W1204 14:08:16.128445097 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:52093 (errno: 97 - Address family not supported by protocol).
[W1204 14:08:16.131850069 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:55919 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3412010)[0;0m INFO 12-04 14:08:16 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3412013)[0;0m INFO 12-04 14:08:16 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3412010)[0;0m INFO 12-04 14:08:17 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3412013)[0;0m INFO 12-04 14:08:17 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3412010)[0;0m INFO 12-04 14:08:18 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3412010)[0;0m INFO 12-04 14:08:18 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3412013)[0;0m INFO 12-04 14:08:18 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3412013)[0;0m INFO 12-04 14:08:18 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m ERROR 12-04 14:08:19 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Including non-PyTorch memory, this process has 18.17 GiB memory in use. Process 3412010 has 26.17 GiB memory in use. Of the allocated memory 17.65 GiB is allocated by PyTorch, and 18.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412013)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412013)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412013)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412013)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412013)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Including non-PyTorch memory, this process has 18.17 GiB memory in use. Process 3412010 has 26.17 GiB memory in use. Of the allocated memory 17.65 GiB is allocated by PyTorch, and 18.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m ERROR 12-04 14:08:19 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3412013 has 18.17 GiB memory in use. Including non-PyTorch memory, this process has 26.17 GiB memory in use. Of the allocated memory 25.65 GiB is allocated by PyTorch, and 18.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412010)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412010)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412010)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412010)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412010)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3412013 has 18.17 GiB memory in use. Including non-PyTorch memory, this process has 26.17 GiB memory in use. Of the allocated memory 25.65 GiB is allocated by PyTorch, and 18.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:08:19.148725710 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:08:19.228814698 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:08:40 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:08:40 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:08:41 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:08:41 [model.py:1745] Using max model len 40960
INFO 12-04 14:08:41 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:08:41 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:08:41 [model.py:1745] Using max model len 40960
INFO 12-04 14:08:41 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3412164)[0;0m INFO 12-04 14:09:01 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3412161)[0;0m INFO 12-04 14:09:01 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3412161)[0;0m INFO 12-04 14:09:03 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:59255 backend=nccl
[1;36m(EngineCore_DP0 pid=3412164)[0;0m INFO 12-04 14:09:03 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42041 backend=nccl
[W1204 14:09:03.675904051 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:59255 (errno: 97 - Address family not supported by protocol).
[W1204 14:09:03.677949976 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42041 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3412164)[0;0m INFO 12-04 14:09:03 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3412161)[0;0m INFO 12-04 14:09:03 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3412164)[0;0m INFO 12-04 14:09:03 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3412161)[0;0m INFO 12-04 14:09:03 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3412164)[0;0m INFO 12-04 14:09:04 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3412164)[0;0m INFO 12-04 14:09:04 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3412161)[0;0m INFO 12-04 14:09:04 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3412161)[0;0m INFO 12-04 14:09:04 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m ERROR 12-04 14:09:05 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Process 3412164 has 24.33 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412161)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412161)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412161)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412161)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412161)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Process 3412164 has 24.33 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m ERROR 12-04 14:09:05 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3412161 has 20.02 GiB memory in use. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412164)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412164)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412164)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412164)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412164)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3412161 has 20.02 GiB memory in use. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:09:06.629696586 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:09:06.663612280 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:09:27 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:09:27 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:09:27 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:09:27 [model.py:1745] Using max model len 40960
INFO 12-04 14:09:27 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:09:27 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:09:27 [model.py:1745] Using max model len 40960
INFO 12-04 14:09:27 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3412297)[0;0m INFO 12-04 14:09:43 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3412300)[0;0m INFO 12-04 14:09:43 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3412297)[0;0m INFO 12-04 14:09:45 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:51615 backend=nccl
[1;36m(EngineCore_DP0 pid=3412300)[0;0m INFO 12-04 14:09:45 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:40847 backend=nccl
[W1204 14:09:45.368661356 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:51615 (errno: 97 - Address family not supported by protocol).
[W1204 14:09:45.369683535 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:40847 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3412297)[0;0m INFO 12-04 14:09:45 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3412300)[0;0m INFO 12-04 14:09:45 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3412300)[0;0m INFO 12-04 14:09:45 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3412297)[0;0m INFO 12-04 14:09:45 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3412297)[0;0m INFO 12-04 14:09:46 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3412297)[0;0m INFO 12-04 14:09:46 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3412300)[0;0m INFO 12-04 14:09:46 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3412300)[0;0m INFO 12-04 14:09:46 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m ERROR 12-04 14:09:47 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3412300 has 24.94 GiB memory in use. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412297)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412297)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412297)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412297)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412297)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3412300 has 24.94 GiB memory in use. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m ERROR 12-04 14:09:47 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Process 3412297 has 19.40 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412300)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412300)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412300)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412300)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412300)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Process 3412297 has 19.40 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:09:48.422525751 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:09:48.445747740 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:10:09 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:10:09 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:10:09 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:10:09 [model.py:1745] Using max model len 40960
INFO 12-04 14:10:09 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:10:09 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:10:09 [model.py:1745] Using max model len 40960
INFO 12-04 14:10:09 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3412427)[0;0m INFO 12-04 14:10:29 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3412430)[0;0m INFO 12-04 14:10:29 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3412427)[0;0m INFO 12-04 14:10:31 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:52661 backend=nccl
[1;36m(EngineCore_DP0 pid=3412430)[0;0m INFO 12-04 14:10:31 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:51363 backend=nccl
[W1204 14:10:31.549565766 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:52661 (errno: 97 - Address family not supported by protocol).
[W1204 14:10:31.549565791 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:51363 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3412430)[0;0m INFO 12-04 14:10:31 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3412427)[0;0m INFO 12-04 14:10:31 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3412427)[0;0m INFO 12-04 14:10:31 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3412430)[0;0m INFO 12-04 14:10:31 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3412430)[0;0m INFO 12-04 14:10:32 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3412430)[0;0m INFO 12-04 14:10:32 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3412427)[0;0m INFO 12-04 14:10:32 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3412427)[0;0m INFO 12-04 14:10:32 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m ERROR 12-04 14:10:33 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 3412430 has 24.36 GiB memory in use. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412427)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412427)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412427)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412427)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412427)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 3412430 has 24.36 GiB memory in use. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m ERROR 12-04 14:10:33 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Process 3412427 has 20.02 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412430)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412430)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412430)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412430)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412430)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Process 3412427 has 20.02 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:10:34.526204763 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:10:34.563244476 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:10:55 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:10:55 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:10:55 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:10:55 [model.py:1745] Using max model len 40960
INFO 12-04 14:10:55 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:10:55 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:10:55 [model.py:1745] Using max model len 40960
INFO 12-04 14:10:55 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3412638)[0;0m INFO 12-04 14:11:13 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3412635)[0;0m INFO 12-04 14:11:13 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3412635)[0;0m INFO 12-04 14:11:15 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:32937 backend=nccl
[1;36m(EngineCore_DP0 pid=3412638)[0;0m INFO 12-04 14:11:15 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:46909 backend=nccl
[W1204 14:11:15.562981729 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:32937 (errno: 97 - Address family not supported by protocol).
[W1204 14:11:15.564018155 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:46909 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3412635)[0;0m INFO 12-04 14:11:15 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3412638)[0;0m INFO 12-04 14:11:15 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3412638)[0;0m INFO 12-04 14:11:15 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3412635)[0;0m INFO 12-04 14:11:15 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3412635)[0;0m INFO 12-04 14:11:16 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3412635)[0;0m INFO 12-04 14:11:16 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3412638)[0;0m INFO 12-04 14:11:16 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3412638)[0;0m INFO 12-04 14:11:16 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m ERROR 12-04 14:11:17 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 3412635 has 23.12 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412638)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412638)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412638)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412638)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412638)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 3412635 has 23.12 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m ERROR 12-04 14:11:17 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3412638 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412635)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412635)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412635)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412635)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412635)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3412638 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:11:18.648654979 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:11:18.658460851 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:11:39 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:11:39 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:11:39 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:11:39 [model.py:1745] Using max model len 40960
INFO 12-04 14:11:39 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:11:39 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:11:39 [model.py:1745] Using max model len 40960
INFO 12-04 14:11:39 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3412769)[0;0m INFO 12-04 14:11:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3412772)[0;0m INFO 12-04 14:11:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3412769)[0;0m INFO 12-04 14:12:00 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:60241 backend=nccl
[1;36m(EngineCore_DP0 pid=3412772)[0;0m INFO 12-04 14:12:00 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:45779 backend=nccl
[W1204 14:12:00.934617700 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:60241 (errno: 97 - Address family not supported by protocol).
[W1204 14:12:00.937009959 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:45779 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3412772)[0;0m INFO 12-04 14:12:00 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3412769)[0;0m INFO 12-04 14:12:00 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3412772)[0;0m INFO 12-04 14:12:01 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3412769)[0;0m INFO 12-04 14:12:01 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3412772)[0;0m INFO 12-04 14:12:01 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3412772)[0;0m INFO 12-04 14:12:01 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3412769)[0;0m INFO 12-04 14:12:02 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3412769)[0;0m INFO 12-04 14:12:02 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 287, in __init__
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.lm_head = ParallelLMHead(
[1;36m(EngineCore_DP0 pid=3412772)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]     torch.empty(
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412772)[0;0m ERROR 12-04 14:12:02 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 44.39 GiB of which 154.00 MiB is free. Including non-PyTorch memory, this process has 26.67 GiB memory in use. Process 3412769 has 17.56 GiB memory in use. Of the allocated memory 26.15 GiB is allocated by PyTorch, and 18.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412772)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412772)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412772)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412772)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412772)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412772)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 287, in __init__
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     self.lm_head = ParallelLMHead(
[1;36m(EngineCore_DP0 pid=3412772)[0;0m                    ^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 523, in __init__
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 301, in __init__
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/vocab_parallel_embedding.py", line 46, in create_weights
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     torch.empty(
[1;36m(EngineCore_DP0 pid=3412772)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412772)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412772)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412772)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.45 GiB. GPU 0 has a total capacity of 44.39 GiB of which 154.00 MiB is free. Including non-PyTorch memory, this process has 26.67 GiB memory in use. Process 3412769 has 17.56 GiB memory in use. Of the allocated memory 26.15 GiB is allocated by PyTorch, and 18.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m ERROR 12-04 14:12:02 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Process 3412772 has 26.70 GiB memory in use. Including non-PyTorch memory, this process has 17.56 GiB memory in use. Of the allocated memory 17.04 GiB is allocated by PyTorch, and 18.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412769)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412769)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412769)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412769)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412769)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Process 3412772 has 26.70 GiB memory in use. Including non-PyTorch memory, this process has 17.56 GiB memory in use. Of the allocated memory 17.04 GiB is allocated by PyTorch, and 18.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:12:03.860426640 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:12:03.881490799 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:12:24 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:12:24 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:12:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:12:24 [model.py:1745] Using max model len 40960
INFO 12-04 14:12:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:12:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:12:24 [model.py:1745] Using max model len 40960
INFO 12-04 14:12:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3412901)[0;0m INFO 12-04 14:12:41 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3412898)[0;0m INFO 12-04 14:12:41 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3412898)[0;0m INFO 12-04 14:12:43 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:56759 backend=nccl
[1;36m(EngineCore_DP0 pid=3412901)[0;0m INFO 12-04 14:12:43 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:45633 backend=nccl
[W1204 14:12:43.109736604 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:56759 (errno: 97 - Address family not supported by protocol).
[W1204 14:12:43.111727247 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:45633 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3412901)[0;0m INFO 12-04 14:12:43 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3412898)[0;0m INFO 12-04 14:12:43 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3412901)[0;0m INFO 12-04 14:12:44 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3412898)[0;0m INFO 12-04 14:12:44 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3412901)[0;0m INFO 12-04 14:12:45 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3412901)[0;0m INFO 12-04 14:12:45 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3412898)[0;0m INFO 12-04 14:12:45 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3412898)[0;0m INFO 12-04 14:12:45 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m ERROR 12-04 14:12:46 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3412901 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412898)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412898)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412898)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412898)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412898)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3412901 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m ERROR 12-04 14:12:46 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3412898 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3412901)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3412901)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3412901)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3412901)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3412901)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3412898 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:12:46.127049962 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:12:46.127102263 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:13:07 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:13:07 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:13:08 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:13:08 [model.py:1745] Using max model len 40960
INFO 12-04 14:13:08 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:13:08 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:13:08 [model.py:1745] Using max model len 40960
INFO 12-04 14:13:08 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3413034)[0;0m INFO 12-04 14:13:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3413031)[0;0m INFO 12-04 14:13:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3413034)[0;0m INFO 12-04 14:13:29 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:60193 backend=nccl
[1;36m(EngineCore_DP0 pid=3413031)[0;0m INFO 12-04 14:13:29 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:60805 backend=nccl
[W1204 14:13:29.427654594 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:60193 (errno: 97 - Address family not supported by protocol).
[W1204 14:13:29.428775450 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:60805 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3413031)[0;0m INFO 12-04 14:13:29 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3413034)[0;0m INFO 12-04 14:13:29 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3413034)[0;0m INFO 12-04 14:13:29 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3413031)[0;0m INFO 12-04 14:13:29 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3413034)[0;0m INFO 12-04 14:13:30 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3413034)[0;0m INFO 12-04 14:13:30 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3413031)[0;0m INFO 12-04 14:13:30 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3413031)[0;0m INFO 12-04 14:13:30 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m ERROR 12-04 14:13:31 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3413031 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413034)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413034)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413034)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413034)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413034)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3413031 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m ERROR 12-04 14:13:31 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3413034 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413031)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413031)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413031)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413031)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413031)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3413034 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:13:32.563737595 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:13:32.568262879 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:13:53 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:13:53 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:13:53 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:13:53 [model.py:1745] Using max model len 40960
INFO 12-04 14:13:53 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:13:53 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:13:53 [model.py:1745] Using max model len 40960
INFO 12-04 14:13:53 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3413190)[0;0m INFO 12-04 14:14:10 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3413187)[0;0m INFO 12-04 14:14:10 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3413190)[0;0m INFO 12-04 14:14:12 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:57091 backend=nccl
[1;36m(EngineCore_DP0 pid=3413187)[0;0m INFO 12-04 14:14:12 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:51715 backend=nccl
[W1204 14:14:12.047372867 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:57091 (errno: 97 - Address family not supported by protocol).
[W1204 14:14:12.047372853 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:51715 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3413187)[0;0m INFO 12-04 14:14:12 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3413190)[0;0m INFO 12-04 14:14:12 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3413190)[0;0m INFO 12-04 14:14:13 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3413187)[0;0m INFO 12-04 14:14:13 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3413187)[0;0m INFO 12-04 14:14:14 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3413187)[0;0m INFO 12-04 14:14:14 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3413190)[0;0m INFO 12-04 14:14:14 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3413190)[0;0m INFO 12-04 14:14:14 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m ERROR 12-04 14:14:15 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Process 3413187 has 23.10 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413190)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413190)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413190)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413190)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413190)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Process 3413187 has 23.10 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m ERROR 12-04 14:14:15 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3413190 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413187)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413187)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413187)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413187)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413187)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3413190 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:14:15.040215107 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:14:15.049764822 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:14:36 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:14:36 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:14:37 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:14:37 [model.py:1745] Using max model len 40960
INFO 12-04 14:14:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:14:37 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:14:37 [model.py:1745] Using max model len 40960
INFO 12-04 14:14:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3413322)[0;0m INFO 12-04 14:14:56 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3413319)[0;0m INFO 12-04 14:14:56 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3413322)[0;0m INFO 12-04 14:14:58 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:55289 backend=nccl
[1;36m(EngineCore_DP0 pid=3413319)[0;0m INFO 12-04 14:14:58 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:41319 backend=nccl
[W1204 14:14:58.671635468 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:55289 (errno: 97 - Address family not supported by protocol).
[W1204 14:14:58.673380391 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:41319 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3413319)[0;0m INFO 12-04 14:14:58 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3413322)[0;0m INFO 12-04 14:14:58 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3413319)[0;0m INFO 12-04 14:14:58 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3413322)[0;0m INFO 12-04 14:14:58 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3413319)[0;0m INFO 12-04 14:14:59 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3413319)[0;0m INFO 12-04 14:14:59 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3413322)[0;0m INFO 12-04 14:14:59 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3413322)[0;0m INFO 12-04 14:14:59 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m ERROR 12-04 14:15:00 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3413319 has 23.10 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413322)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413322)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413322)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413322)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413322)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3413319 has 23.10 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m ERROR 12-04 14:15:00 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3413322 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413319)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413319)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413319)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413319)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413319)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3413322 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:15:01.682410350 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:15:01.692489790 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:15:22 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:15:22 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:15:22 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:15:22 [model.py:1745] Using max model len 40960
INFO 12-04 14:15:22 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:15:22 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:15:22 [model.py:1745] Using max model len 40960
INFO 12-04 14:15:22 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3413495)[0;0m INFO 12-04 14:15:38 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3413492)[0;0m INFO 12-04 14:15:38 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3413492)[0;0m INFO 12-04 14:15:40 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:37437 backend=nccl
[1;36m(EngineCore_DP0 pid=3413495)[0;0m INFO 12-04 14:15:40 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:48313 backend=nccl
[W1204 14:15:40.939393160 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:37437 (errno: 97 - Address family not supported by protocol).
[W1204 14:15:40.941300270 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:48313 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3413495)[0;0m INFO 12-04 14:15:40 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3413492)[0;0m INFO 12-04 14:15:40 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3413495)[0;0m INFO 12-04 14:15:41 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3413492)[0;0m INFO 12-04 14:15:41 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3413495)[0;0m INFO 12-04 14:15:42 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3413495)[0;0m INFO 12-04 14:15:42 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3413492)[0;0m INFO 12-04 14:15:42 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3413492)[0;0m INFO 12-04 14:15:42 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m ERROR 12-04 14:15:43 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3413495 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413492)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413492)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413492)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413492)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413492)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3413495 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m ERROR 12-04 14:15:43 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3413492 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413495)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413495)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413495)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413495)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413495)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3413492 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:15:43.031410136 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:15:43.039756438 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:16:04 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:16:04 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:16:05 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:16:05 [model.py:1745] Using max model len 40960
INFO 12-04 14:16:05 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:16:05 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:16:05 [model.py:1745] Using max model len 40960
INFO 12-04 14:16:05 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3413704)[0;0m INFO 12-04 14:16:24 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3413707)[0;0m INFO 12-04 14:16:24 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3413704)[0;0m INFO 12-04 14:16:25 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44361 backend=nccl
[1;36m(EngineCore_DP0 pid=3413707)[0;0m INFO 12-04 14:16:25 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:33307 backend=nccl
[W1204 14:16:25.067436876 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44361 (errno: 97 - Address family not supported by protocol).
[W1204 14:16:25.070886904 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:33307 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3413707)[0;0m INFO 12-04 14:16:25 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3413704)[0;0m INFO 12-04 14:16:25 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3413707)[0;0m INFO 12-04 14:16:26 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3413704)[0;0m INFO 12-04 14:16:26 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3413707)[0;0m INFO 12-04 14:16:27 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3413707)[0;0m INFO 12-04 14:16:27 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3413704)[0;0m INFO 12-04 14:16:27 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3413704)[0;0m INFO 12-04 14:16:27 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m ERROR 12-04 14:16:28 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Process 3413707 has 24.36 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413704)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413704)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413704)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413704)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413704)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Process 3413707 has 24.36 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m ERROR 12-04 14:16:28 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3413704 has 20.02 GiB memory in use. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413707)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413707)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413707)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413707)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413707)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3413704 has 20.02 GiB memory in use. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:16:28.046776477 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:16:28.079550470 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:16:49 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:16:49 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:16:50 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:16:50 [model.py:1745] Using max model len 40960
INFO 12-04 14:16:50 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:16:50 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:16:50 [model.py:1745] Using max model len 40960
INFO 12-04 14:16:50 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3413829)[0;0m INFO 12-04 14:17:06 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3413832)[0;0m INFO 12-04 14:17:06 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3413829)[0;0m INFO 12-04 14:17:08 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:37429 backend=nccl
[1;36m(EngineCore_DP0 pid=3413832)[0;0m INFO 12-04 14:17:08 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:54961 backend=nccl
[W1204 14:17:08.910858017 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:37429 (errno: 97 - Address family not supported by protocol).
[W1204 14:17:08.913531897 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:54961 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3413832)[0;0m INFO 12-04 14:17:08 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3413829)[0;0m INFO 12-04 14:17:08 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3413832)[0;0m INFO 12-04 14:17:09 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3413829)[0;0m INFO 12-04 14:17:09 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3413829)[0;0m INFO 12-04 14:17:10 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3413829)[0;0m INFO 12-04 14:17:10 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3413832)[0;0m INFO 12-04 14:17:10 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3413832)[0;0m INFO 12-04 14:17:10 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m ERROR 12-04 14:17:10 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3413829 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413832)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413832)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413832)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413832)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413832)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3413829 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m ERROR 12-04 14:17:10 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3413832 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3413829)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3413829)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3413829)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3413829)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3413829)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3413832 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:17:11.930281493 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:17:11.930281585 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:17:32 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:17:32 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:17:32 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:17:32 [model.py:1745] Using max model len 40960
INFO 12-04 14:17:32 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:17:32 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:17:32 [model.py:1745] Using max model len 40960
INFO 12-04 14:17:32 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3414511)[0;0m INFO 12-04 14:17:51 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3414508)[0;0m INFO 12-04 14:17:51 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3414508)[0;0m INFO 12-04 14:17:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:45053 backend=nccl
[1;36m(EngineCore_DP0 pid=3414511)[0;0m INFO 12-04 14:17:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:37937 backend=nccl
[W1204 14:17:53.655617576 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:45053 (errno: 97 - Address family not supported by protocol).
[W1204 14:17:53.657839534 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:37937 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3414511)[0;0m INFO 12-04 14:17:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3414508)[0;0m INFO 12-04 14:17:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3414511)[0;0m INFO 12-04 14:17:53 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3414508)[0;0m INFO 12-04 14:17:53 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3414508)[0;0m INFO 12-04 14:17:54 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3414508)[0;0m INFO 12-04 14:17:54 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3414511)[0;0m INFO 12-04 14:17:54 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3414511)[0;0m INFO 12-04 14:17:54 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m ERROR 12-04 14:17:55 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Process 3414508 has 23.71 GiB memory in use. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3414511)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3414511)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3414511)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414511)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414511)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Process 3414508 has 23.71 GiB memory in use. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m ERROR 12-04 14:17:55 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Process 3414511 has 20.63 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3414508)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3414508)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3414508)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414508)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414508)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Process 3414511 has 20.63 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:17:56.856926220 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:17:56.888177369 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:18:17 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:18:17 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:18:18 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:18:18 [model.py:1745] Using max model len 40960
INFO 12-04 14:18:18 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:18:18 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:18:18 [model.py:1745] Using max model len 40960
INFO 12-04 14:18:18 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3414754)[0;0m INFO 12-04 14:18:33 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3414755)[0;0m INFO 12-04 14:18:33 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3414755)[0;0m INFO 12-04 14:18:34 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:44075 backend=nccl
[1;36m(EngineCore_DP0 pid=3414754)[0;0m INFO 12-04 14:18:34 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:48083 backend=nccl
[W1204 14:18:34.124813813 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:44075 (errno: 97 - Address family not supported by protocol).
[W1204 14:18:34.125427249 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:48083 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3414755)[0;0m INFO 12-04 14:18:34 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3414754)[0;0m INFO 12-04 14:18:34 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3414755)[0;0m INFO 12-04 14:18:35 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3414754)[0;0m INFO 12-04 14:18:35 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3414755)[0;0m INFO 12-04 14:18:36 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3414755)[0;0m INFO 12-04 14:18:36 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3414754)[0;0m INFO 12-04 14:18:36 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3414754)[0;0m INFO 12-04 14:18:36 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m ERROR 12-04 14:18:37 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3414754 has 21.89 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m ERROR 12-04 14:18:37 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3414755 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3414754)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3414755)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3414754)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3414754)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3414754)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414754)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414754)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3414755 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3414755)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3414755)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414755)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414755)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3414754 has 21.89 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:18:37.199185238 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:18:37.200881218 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:18:59 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:18:59 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:18:59 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:18:59 [model.py:1745] Using max model len 40960
INFO 12-04 14:18:59 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:18:59 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:18:59 [model.py:1745] Using max model len 40960
INFO 12-04 14:18:59 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3414883)[0;0m INFO 12-04 14:19:18 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3414880)[0;0m INFO 12-04 14:19:18 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3414880)[0;0m INFO 12-04 14:19:20 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:47349 backend=nccl
[1;36m(EngineCore_DP0 pid=3414883)[0;0m INFO 12-04 14:19:20 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:60529 backend=nccl
[W1204 14:19:20.408540099 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:60529 (errno: 97 - Address family not supported by protocol).
[W1204 14:19:20.408503995 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:47349 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3414883)[0;0m INFO 12-04 14:19:20 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3414880)[0;0m INFO 12-04 14:19:20 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3414883)[0;0m INFO 12-04 14:19:20 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3414880)[0;0m INFO 12-04 14:19:20 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3414883)[0;0m INFO 12-04 14:19:21 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3414883)[0;0m INFO 12-04 14:19:21 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3414880)[0;0m INFO 12-04 14:19:21 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3414880)[0;0m INFO 12-04 14:19:21 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m ERROR 12-04 14:19:22 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3414883 has 23.10 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3414880)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3414880)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3414880)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414880)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414880)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3414883 has 23.10 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m ERROR 12-04 14:19:22 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3414880 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3414883)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3414883)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3414883)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3414883)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3414883)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3414880 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:19:23.460672814 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:19:23.473309831 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:19:44 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:19:44 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:19:44 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:19:44 [model.py:1745] Using max model len 40960
INFO 12-04 14:19:44 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:19:44 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:19:44 [model.py:1745] Using max model len 40960
INFO 12-04 14:19:44 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3415064)[0;0m INFO 12-04 14:19:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3415061)[0;0m INFO 12-04 14:19:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3415064)[0;0m INFO 12-04 14:20:01 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:48031 backend=nccl
[1;36m(EngineCore_DP0 pid=3415061)[0;0m INFO 12-04 14:20:01 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:60003 backend=nccl
[W1204 14:20:01.896244984 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:48031 (errno: 97 - Address family not supported by protocol).
[W1204 14:20:01.896693358 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:60003 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3415061)[0;0m INFO 12-04 14:20:01 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3415064)[0;0m INFO 12-04 14:20:01 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3415064)[0;0m INFO 12-04 14:20:02 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3415061)[0;0m INFO 12-04 14:20:02 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3415061)[0;0m INFO 12-04 14:20:03 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3415061)[0;0m INFO 12-04 14:20:03 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3415064)[0;0m INFO 12-04 14:20:03 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3415064)[0;0m INFO 12-04 14:20:03 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m ERROR 12-04 14:20:03 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3415061 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415064)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415064)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415064)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415064)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415064)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3415061 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m ERROR 12-04 14:20:03 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3415064 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415061)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415061)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415061)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415061)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415061)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3415064 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:20:04.989217890 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:20:04.994259455 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:20:25 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:20:25 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:20:26 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:20:26 [model.py:1745] Using max model len 40960
INFO 12-04 14:20:26 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:20:26 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:20:26 [model.py:1745] Using max model len 40960
INFO 12-04 14:20:26 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3415197)[0;0m INFO 12-04 14:20:44 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3415194)[0;0m INFO 12-04 14:20:44 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3415197)[0;0m INFO 12-04 14:20:45 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:51241 backend=nccl
[1;36m(EngineCore_DP0 pid=3415194)[0;0m INFO 12-04 14:20:45 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:52317 backend=nccl
[W1204 14:20:45.796349364 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:51241 (errno: 97 - Address family not supported by protocol).
[W1204 14:20:45.797331787 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:52317 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3415197)[0;0m INFO 12-04 14:20:45 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3415194)[0;0m INFO 12-04 14:20:45 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3415194)[0;0m INFO 12-04 14:20:45 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3415197)[0;0m INFO 12-04 14:20:45 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3415194)[0;0m INFO 12-04 14:20:46 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3415194)[0;0m INFO 12-04 14:20:46 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3415197)[0;0m INFO 12-04 14:20:46 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3415197)[0;0m INFO 12-04 14:20:46 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m ERROR 12-04 14:20:47 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Process 3415194 has 24.36 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415197)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415197)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415197)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415197)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Process 3415194 has 24.36 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m ERROR 12-04 14:20:47 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3415197 has 20.02 GiB memory in use. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415194)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415194)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415194)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415194)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415194)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3415197 has 20.02 GiB memory in use. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:20:48.846602341 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:20:48.885621703 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:21:09 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:21:09 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:21:09 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:21:09 [model.py:1745] Using max model len 40960
INFO 12-04 14:21:09 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:21:09 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:21:09 [model.py:1745] Using max model len 40960
INFO 12-04 14:21:09 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3415416)[0;0m INFO 12-04 14:21:26 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3415419)[0;0m INFO 12-04 14:21:26 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3415419)[0;0m INFO 12-04 14:21:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:59307 backend=nccl
[1;36m(EngineCore_DP0 pid=3415416)[0;0m INFO 12-04 14:21:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:36137 backend=nccl
[W1204 14:21:27.027971757 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:59307 (errno: 97 - Address family not supported by protocol).
[W1204 14:21:27.032094186 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:36137 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3415419)[0;0m INFO 12-04 14:21:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3415416)[0;0m INFO 12-04 14:21:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3415416)[0;0m INFO 12-04 14:21:28 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3415419)[0;0m INFO 12-04 14:21:28 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3415419)[0;0m INFO 12-04 14:21:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3415419)[0;0m INFO 12-04 14:21:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3415416)[0;0m INFO 12-04 14:21:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3415416)[0;0m INFO 12-04 14:21:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m ERROR 12-04 14:21:30 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3415419 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3415416)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415416)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m ERROR 12-04 14:21:30 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3415416 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415416)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415416)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415416)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415416)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3415419 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415419)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415419)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415419)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415419)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415419)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3415416 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:21:30.138040669 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:21:30.141053390 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:21:51 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:21:51 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:21:52 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:21:52 [model.py:1745] Using max model len 40960
INFO 12-04 14:21:52 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:21:52 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:21:52 [model.py:1745] Using max model len 40960
INFO 12-04 14:21:52 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3415550)[0;0m INFO 12-04 14:22:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3415547)[0;0m INFO 12-04 14:22:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3415550)[0;0m INFO 12-04 14:22:13 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:51727 backend=nccl
[1;36m(EngineCore_DP0 pid=3415547)[0;0m INFO 12-04 14:22:13 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50571 backend=nccl
[W1204 14:22:13.858946836 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:51727 (errno: 97 - Address family not supported by protocol).
[W1204 14:22:13.859468880 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50571 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3415550)[0;0m INFO 12-04 14:22:13 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3415547)[0;0m INFO 12-04 14:22:13 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3415550)[0;0m INFO 12-04 14:22:14 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3415547)[0;0m INFO 12-04 14:22:14 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3415547)[0;0m INFO 12-04 14:22:14 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3415547)[0;0m INFO 12-04 14:22:14 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3415550)[0;0m INFO 12-04 14:22:14 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3415550)[0;0m INFO 12-04 14:22:14 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m ERROR 12-04 14:22:15 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3415550 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415547)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415547)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415547)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415547)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415547)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3415550 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m ERROR 12-04 14:22:15 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3415547 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415550)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415550)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415550)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415550)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415550)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3415547 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:22:16.896371580 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:22:16.896301602 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:22:37 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:22:37 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:22:37 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:22:37 [model.py:1745] Using max model len 40960
INFO 12-04 14:22:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:22:37 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:22:37 [model.py:1745] Using max model len 40960
INFO 12-04 14:22:37 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3415686)[0;0m INFO 12-04 14:22:53 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3415683)[0;0m INFO 12-04 14:22:53 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3415686)[0;0m INFO 12-04 14:22:55 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:35059 backend=nccl
[1;36m(EngineCore_DP0 pid=3415683)[0;0m INFO 12-04 14:22:55 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:47881 backend=nccl
[W1204 14:22:55.856197271 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:47881 (errno: 97 - Address family not supported by protocol).
[W1204 14:22:55.859707073 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:35059 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3415686)[0;0m INFO 12-04 14:22:55 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3415683)[0;0m INFO 12-04 14:22:55 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3415683)[0;0m INFO 12-04 14:22:56 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3415686)[0;0m INFO 12-04 14:22:56 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3415683)[0;0m INFO 12-04 14:22:57 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3415683)[0;0m INFO 12-04 14:22:57 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3415686)[0;0m INFO 12-04 14:22:57 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3415686)[0;0m INFO 12-04 14:22:57 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m ERROR 12-04 14:22:57 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 18.17 GiB memory in use. Process 3415683 has 26.17 GiB memory in use. Of the allocated memory 17.65 GiB is allocated by PyTorch, and 18.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415686)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415686)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415686)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415686)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415686)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 18.17 GiB memory in use. Process 3415683 has 26.17 GiB memory in use. Of the allocated memory 17.65 GiB is allocated by PyTorch, and 18.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m ERROR 12-04 14:22:57 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3415686 has 18.17 GiB memory in use. Including non-PyTorch memory, this process has 26.17 GiB memory in use. Of the allocated memory 25.65 GiB is allocated by PyTorch, and 18.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415683)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415683)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415683)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415683)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415683)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3415686 has 18.17 GiB memory in use. Including non-PyTorch memory, this process has 26.17 GiB memory in use. Of the allocated memory 25.65 GiB is allocated by PyTorch, and 18.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:22:58.928062581 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:22:58.997493043 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:23:19 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:23:19 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:23:19 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:23:19 [model.py:1745] Using max model len 40960
INFO 12-04 14:23:19 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:23:20 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:23:20 [model.py:1745] Using max model len 40960
INFO 12-04 14:23:20 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3415839)[0;0m INFO 12-04 14:23:39 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3415842)[0;0m INFO 12-04 14:23:39 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3415842)[0;0m INFO 12-04 14:23:40 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:42559 backend=nccl
[1;36m(EngineCore_DP0 pid=3415839)[0;0m INFO 12-04 14:23:40 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:49627 backend=nccl
[W1204 14:23:40.813058652 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:49627 (errno: 97 - Address family not supported by protocol).
[W1204 14:23:40.813738096 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:42559 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3415842)[0;0m INFO 12-04 14:23:40 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3415839)[0;0m INFO 12-04 14:23:40 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3415842)[0;0m INFO 12-04 14:23:40 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3415839)[0;0m INFO 12-04 14:23:40 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3415839)[0;0m INFO 12-04 14:23:41 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3415839)[0;0m INFO 12-04 14:23:41 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3415842)[0;0m INFO 12-04 14:23:41 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3415842)[0;0m INFO 12-04 14:23:41 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m ERROR 12-04 14:23:42 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3415839 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415842)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415842)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415842)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415842)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415842)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3415839 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m ERROR 12-04 14:23:42 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3415842 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3415839)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3415839)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3415839)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3415839)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3415839)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3415842 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:23:43.830984698 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:23:43.833183200 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:24:04 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:24:04 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:24:04 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:24:04 [model.py:1745] Using max model len 40960
INFO 12-04 14:24:04 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:24:04 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:24:04 [model.py:1745] Using max model len 40960
INFO 12-04 14:24:04 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3416019)[0;0m INFO 12-04 14:24:19 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3416016)[0;0m INFO 12-04 14:24:19 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3416019)[0;0m INFO 12-04 14:24:21 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:60915 backend=nccl
[1;36m(EngineCore_DP0 pid=3416016)[0;0m INFO 12-04 14:24:21 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50023 backend=nccl
[W1204 14:24:21.824812301 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:60915 (errno: 97 - Address family not supported by protocol).
[W1204 14:24:21.827324460 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50023 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3416019)[0;0m INFO 12-04 14:24:21 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3416016)[0;0m INFO 12-04 14:24:21 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3416019)[0;0m INFO 12-04 14:24:21 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3416016)[0;0m INFO 12-04 14:24:21 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3416016)[0;0m INFO 12-04 14:24:23 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3416016)[0;0m INFO 12-04 14:24:23 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3416019)[0;0m INFO 12-04 14:24:23 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3416019)[0;0m INFO 12-04 14:24:23 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m ERROR 12-04 14:24:23 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3416016 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416019)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416019)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416019)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416019)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416019)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3416016 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m ERROR 12-04 14:24:23 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3416019 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416016)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416016)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416016)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416016)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416016)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3416019 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:24:24.928965312 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:24:24.928960005 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:24:45 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:24:45 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:24:45 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:24:45 [model.py:1745] Using max model len 40960
INFO 12-04 14:24:45 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:24:45 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:24:45 [model.py:1745] Using max model len 40960
INFO 12-04 14:24:45 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3416170)[0;0m INFO 12-04 14:25:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3416167)[0;0m INFO 12-04 14:25:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3416167)[0;0m INFO 12-04 14:25:05 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50757 backend=nccl
[1;36m(EngineCore_DP0 pid=3416170)[0;0m INFO 12-04 14:25:05 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:53027 backend=nccl
[W1204 14:25:05.209569195 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50757 (errno: 97 - Address family not supported by protocol).
[W1204 14:25:05.211912684 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:53027 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3416170)[0;0m INFO 12-04 14:25:05 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3416167)[0;0m INFO 12-04 14:25:05 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3416170)[0;0m INFO 12-04 14:25:06 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3416167)[0;0m INFO 12-04 14:25:06 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3416170)[0;0m INFO 12-04 14:25:07 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3416170)[0;0m INFO 12-04 14:25:07 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3416167)[0;0m INFO 12-04 14:25:07 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3416167)[0;0m INFO 12-04 14:25:07 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m ERROR 12-04 14:25:08 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3416167 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416170)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416170)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416170)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416170)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416170)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3416167 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m ERROR 12-04 14:25:08 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3416170 has 21.89 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416167)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416167)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416167)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416167)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416167)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3416170 has 21.89 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:25:08.239797996 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:25:08.274403442 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:25:30 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:25:30 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:25:30 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:25:30 [model.py:1745] Using max model len 40960
INFO 12-04 14:25:30 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:25:30 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:25:30 [model.py:1745] Using max model len 40960
INFO 12-04 14:25:30 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3416552)[0;0m INFO 12-04 14:25:45 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3416549)[0;0m INFO 12-04 14:25:45 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3416552)[0;0m INFO 12-04 14:25:47 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:45687 backend=nccl
[1;36m(EngineCore_DP0 pid=3416549)[0;0m INFO 12-04 14:25:47 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:38775 backend=nccl
[W1204 14:25:47.399585635 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:45687 (errno: 97 - Address family not supported by protocol).
[W1204 14:25:47.399879050 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:38775 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3416549)[0;0m INFO 12-04 14:25:47 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3416552)[0;0m INFO 12-04 14:25:47 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3416549)[0;0m INFO 12-04 14:25:47 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3416552)[0;0m INFO 12-04 14:25:47 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3416549)[0;0m INFO 12-04 14:25:48 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3416549)[0;0m INFO 12-04 14:25:48 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3416552)[0;0m INFO 12-04 14:25:48 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3416552)[0;0m INFO 12-04 14:25:48 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m ERROR 12-04 14:25:49 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3416549 has 24.36 GiB memory in use. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416552)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416552)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416552)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416552)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416552)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3416549 has 24.36 GiB memory in use. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m ERROR 12-04 14:25:49 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Process 3416552 has 20.02 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416549)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416549)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416549)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416549)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416549)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Process 3416552 has 20.02 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:25:50.444790593 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:25:50.480248575 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:26:11 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:26:11 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:26:11 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:26:11 [model.py:1745] Using max model len 40960
INFO 12-04 14:26:11 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:26:11 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:26:11 [model.py:1745] Using max model len 40960
INFO 12-04 14:26:11 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3416687)[0;0m INFO 12-04 14:26:30 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3416684)[0;0m INFO 12-04 14:26:30 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3416687)[0;0m INFO 12-04 14:26:32 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:38809 backend=nccl
[1;36m(EngineCore_DP0 pid=3416684)[0;0m INFO 12-04 14:26:32 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:57187 backend=nccl
[W1204 14:26:32.683634238 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:38809 (errno: 97 - Address family not supported by protocol).
[W1204 14:26:32.686608177 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:57187 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3416687)[0;0m INFO 12-04 14:26:32 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3416684)[0;0m INFO 12-04 14:26:32 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3416687)[0;0m INFO 12-04 14:26:32 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3416684)[0;0m INFO 12-04 14:26:32 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3416687)[0;0m INFO 12-04 14:26:33 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3416687)[0;0m INFO 12-04 14:26:33 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3416684)[0;0m INFO 12-04 14:26:33 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3416684)[0;0m INFO 12-04 14:26:33 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m ERROR 12-04 14:26:34 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Process 3416687 has 24.33 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416684)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416684)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416684)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416684)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416684)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.02 GiB memory in use. Process 3416687 has 24.33 GiB memory in use. Of the allocated memory 19.50 GiB is allocated by PyTorch, and 18.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m ERROR 12-04 14:26:34 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3416684 has 20.02 GiB memory in use. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3416687)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3416687)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3416687)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3416687)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3416687)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3416684 has 20.02 GiB memory in use. Including non-PyTorch memory, this process has 24.33 GiB memory in use. Of the allocated memory 23.81 GiB is allocated by PyTorch, and 18.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:26:35.711495310 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:26:35.748152584 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:26:56 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:26:56 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:26:56 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:26:56 [model.py:1745] Using max model len 40960
INFO 12-04 14:26:56 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:26:56 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:26:56 [model.py:1745] Using max model len 40960
INFO 12-04 14:26:56 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3417743)[0;0m INFO 12-04 14:27:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3417740)[0;0m INFO 12-04 14:27:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3417740)[0;0m INFO 12-04 14:27:14 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:47361 backend=nccl
[1;36m(EngineCore_DP0 pid=3417743)[0;0m INFO 12-04 14:27:14 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:53147 backend=nccl
[W1204 14:27:14.584771915 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:47361 (errno: 97 - Address family not supported by protocol).
[W1204 14:27:14.585091052 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:53147 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3417743)[0;0m INFO 12-04 14:27:14 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3417740)[0;0m INFO 12-04 14:27:14 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3417740)[0;0m INFO 12-04 14:27:14 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3417743)[0;0m INFO 12-04 14:27:14 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3417743)[0;0m INFO 12-04 14:27:15 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3417743)[0;0m INFO 12-04 14:27:15 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3417740)[0;0m INFO 12-04 14:27:15 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3417740)[0;0m INFO 12-04 14:27:15 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m ERROR 12-04 14:27:16 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Process 3417743 has 24.94 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3417740)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3417740)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3417740)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417740)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417740)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Process 3417743 has 24.94 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m ERROR 12-04 14:27:16 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3417740 has 19.42 GiB memory in use. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3417743)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3417743)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3417743)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417743)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417743)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3417740 has 19.42 GiB memory in use. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:27:17.660264048 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:27:17.714534380 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:27:38 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:27:38 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:27:38 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:27:38 [model.py:1745] Using max model len 40960
INFO 12-04 14:27:38 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:27:38 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:27:38 [model.py:1745] Using max model len 40960
INFO 12-04 14:27:38 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3417935)[0;0m INFO 12-04 14:27:58 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3417932)[0;0m INFO 12-04 14:27:58 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3417935)[0;0m INFO 12-04 14:27:59 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:49197 backend=nccl
[1;36m(EngineCore_DP0 pid=3417932)[0;0m INFO 12-04 14:27:59 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:39161 backend=nccl
[W1204 14:27:59.234892843 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:49197 (errno: 97 - Address family not supported by protocol).
[W1204 14:27:59.238990042 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:39161 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3417935)[0;0m INFO 12-04 14:27:59 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3417932)[0;0m INFO 12-04 14:27:59 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3417935)[0;0m INFO 12-04 14:28:00 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3417932)[0;0m INFO 12-04 14:28:00 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3417935)[0;0m INFO 12-04 14:28:01 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3417935)[0;0m INFO 12-04 14:28:01 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3417932)[0;0m INFO 12-04 14:28:01 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3417932)[0;0m INFO 12-04 14:28:01 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m ERROR 12-04 14:28:02 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 3417935 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3417932)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3417932)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3417932)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417932)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417932)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 3417935 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m ERROR 12-04 14:28:02 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3417932 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3417935)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3417935)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3417935)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3417935)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3417935)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3417932 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:28:02.243687797 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:28:02.247542150 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:28:24 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:28:24 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:28:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:28:24 [model.py:1745] Using max model len 40960
INFO 12-04 14:28:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:28:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:28:24 [model.py:1745] Using max model len 40960
INFO 12-04 14:28:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3418085)[0;0m INFO 12-04 14:28:39 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3418088)[0;0m INFO 12-04 14:28:39 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3418088)[0;0m INFO 12-04 14:28:41 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:52399 backend=nccl
[1;36m(EngineCore_DP0 pid=3418085)[0;0m INFO 12-04 14:28:41 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:54213 backend=nccl
[W1204 14:28:41.998292654 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:52399 (errno: 97 - Address family not supported by protocol).
[W1204 14:28:41.999789221 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:54213 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3418088)[0;0m INFO 12-04 14:28:41 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3418085)[0;0m INFO 12-04 14:28:41 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3418088)[0;0m INFO 12-04 14:28:42 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3418085)[0;0m INFO 12-04 14:28:42 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3418088)[0;0m INFO 12-04 14:28:43 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3418088)[0;0m INFO 12-04 14:28:43 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3418085)[0;0m INFO 12-04 14:28:43 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3418085)[0;0m INFO 12-04 14:28:43 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m ERROR 12-04 14:28:44 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3418085 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418088)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418088)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418088)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418088)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418088)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3418085 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m ERROR 12-04 14:28:44 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3418088 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418085)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418085)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418085)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418085)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418085)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3418088 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:28:44.093133198 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:28:44.096849793 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:29:05 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:29:05 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:29:06 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:29:06 [model.py:1745] Using max model len 40960
INFO 12-04 14:29:06 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:29:06 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:29:06 [model.py:1745] Using max model len 40960
INFO 12-04 14:29:06 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3418245)[0;0m INFO 12-04 14:29:26 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3418242)[0;0m INFO 12-04 14:29:26 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3418242)[0;0m INFO 12-04 14:29:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:38697 backend=nccl
[1;36m(EngineCore_DP0 pid=3418245)[0;0m INFO 12-04 14:29:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:37319 backend=nccl
[W1204 14:29:27.231589722 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:38697 (errno: 97 - Address family not supported by protocol).
[W1204 14:29:27.232298690 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:37319 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3418245)[0;0m INFO 12-04 14:29:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3418242)[0;0m INFO 12-04 14:29:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3418245)[0;0m INFO 12-04 14:29:28 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3418242)[0;0m INFO 12-04 14:29:28 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3418242)[0;0m INFO 12-04 14:29:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3418242)[0;0m INFO 12-04 14:29:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3418245)[0;0m INFO 12-04 14:29:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3418245)[0;0m INFO 12-04 14:29:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m ERROR 12-04 14:29:30 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3418242 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418245)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418245)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418245)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418245)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418245)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3418242 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m ERROR 12-04 14:29:30 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Process 3418245 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418242)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418242)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418242)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418242)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418242)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Process 3418245 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:29:30.220692825 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:29:30.220692892 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:29:52 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:29:52 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:29:52 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:29:52 [model.py:1745] Using max model len 40960
INFO 12-04 14:29:52 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:29:52 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:29:52 [model.py:1745] Using max model len 40960
INFO 12-04 14:29:52 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3418415)[0;0m INFO 12-04 14:30:08 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3418418)[0;0m INFO 12-04 14:30:08 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3418415)[0;0m INFO 12-04 14:30:11 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:36599 backend=nccl
[1;36m(EngineCore_DP0 pid=3418418)[0;0m INFO 12-04 14:30:11 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:51647 backend=nccl
[W1204 14:30:11.591477739 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:36599 (errno: 97 - Address family not supported by protocol).
[W1204 14:30:11.593928881 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:51647 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3418415)[0;0m INFO 12-04 14:30:11 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3418418)[0;0m INFO 12-04 14:30:11 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3418415)[0;0m INFO 12-04 14:30:11 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3418418)[0;0m INFO 12-04 14:30:11 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3418415)[0;0m INFO 12-04 14:30:12 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3418415)[0;0m INFO 12-04 14:30:12 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3418418)[0;0m INFO 12-04 14:30:12 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3418418)[0;0m INFO 12-04 14:30:12 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m ERROR 12-04 14:30:13 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 3418418 has 23.10 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418415)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418415)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418415)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418415)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418415)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 3418418 has 23.10 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m ERROR 12-04 14:30:13 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3418415 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418418)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418418)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418418)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418418)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418418)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3418415 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:30:14.810047668 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:30:14.819435265 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:30:35 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:30:35 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:30:35 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:30:35 [model.py:1745] Using max model len 40960
INFO 12-04 14:30:35 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:30:35 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:30:35 [model.py:1745] Using max model len 40960
INFO 12-04 14:30:35 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3418633)[0;0m INFO 12-04 14:30:56 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3418630)[0;0m INFO 12-04 14:30:56 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3418633)[0;0m INFO 12-04 14:30:58 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:45227 backend=nccl
[1;36m(EngineCore_DP0 pid=3418630)[0;0m INFO 12-04 14:30:58 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:48491 backend=nccl
[W1204 14:30:58.515621133 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:45227 (errno: 97 - Address family not supported by protocol).
[W1204 14:30:58.518179697 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:48491 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3418630)[0;0m INFO 12-04 14:30:58 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3418633)[0;0m INFO 12-04 14:30:58 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3418633)[0;0m INFO 12-04 14:30:58 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3418630)[0;0m INFO 12-04 14:30:58 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3418633)[0;0m INFO 12-04 14:30:59 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3418633)[0;0m INFO 12-04 14:30:59 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3418630)[0;0m INFO 12-04 14:30:59 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3418630)[0;0m INFO 12-04 14:30:59 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m ERROR 12-04 14:31:00 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3418633 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418630)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418630)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418630)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418630)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418630)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3418633 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m ERROR 12-04 14:31:00 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3418630 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418633)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418633)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418633)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418633)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418633)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3418630 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:31:01.539149728 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:31:01.539857333 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:31:22 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:31:22 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:31:22 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:31:22 [model.py:1745] Using max model len 40960
INFO 12-04 14:31:22 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:31:22 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:31:22 [model.py:1745] Using max model len 40960
INFO 12-04 14:31:22 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3418768)[0;0m INFO 12-04 14:31:41 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3418771)[0;0m INFO 12-04 14:31:41 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3418771)[0;0m INFO 12-04 14:31:43 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:33005 backend=nccl
[1;36m(EngineCore_DP0 pid=3418768)[0;0m INFO 12-04 14:31:43 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:60949 backend=nccl
[W1204 14:31:43.466489342 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:33005 (errno: 97 - Address family not supported by protocol).
[W1204 14:31:43.468610413 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:60949 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3418768)[0;0m INFO 12-04 14:31:43 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3418771)[0;0m INFO 12-04 14:31:43 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3418768)[0;0m INFO 12-04 14:31:43 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3418771)[0;0m INFO 12-04 14:31:43 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3418768)[0;0m INFO 12-04 14:31:44 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3418771)[0;0m INFO 12-04 14:31:44 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3418771)[0;0m INFO 12-04 14:31:44 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3418768)[0;0m INFO 12-04 14:31:44 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m ERROR 12-04 14:31:45 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3418768 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418771)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418771)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418771)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418771)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418771)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3418768 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m ERROR 12-04 14:31:45 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3418771 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418768)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418768)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418768)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418768)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418768)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3418771 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:31:46.516944259 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:31:46.516944299 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:32:07 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:32:07 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:32:07 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:32:07 [model.py:1745] Using max model len 40960
INFO 12-04 14:32:07 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:32:07 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:32:07 [model.py:1745] Using max model len 40960
INFO 12-04 14:32:07 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3418934)[0;0m INFO 12-04 14:32:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3418937)[0;0m INFO 12-04 14:32:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3418937)[0;0m INFO 12-04 14:32:29 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:40943 backend=nccl
[1;36m(EngineCore_DP0 pid=3418934)[0;0m INFO 12-04 14:32:29 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:56593 backend=nccl
[W1204 14:32:29.649812109 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:40943 (errno: 97 - Address family not supported by protocol).
[W1204 14:32:29.650420146 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:56593 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3418934)[0;0m INFO 12-04 14:32:29 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3418937)[0;0m INFO 12-04 14:32:29 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3418934)[0;0m INFO 12-04 14:32:29 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3418937)[0;0m INFO 12-04 14:32:29 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3418934)[0;0m INFO 12-04 14:32:30 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3418934)[0;0m INFO 12-04 14:32:30 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3418937)[0;0m INFO 12-04 14:32:30 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3418937)[0;0m INFO 12-04 14:32:30 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m ERROR 12-04 14:32:31 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3418934 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418937)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418937)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418937)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418937)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418937)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3418934 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m ERROR 12-04 14:32:31 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3418937 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3418934)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3418934)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3418934)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3418934)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3418934)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3418937 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:32:32.692383103 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:32:32.697749209 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:32:53 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:32:53 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:32:53 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:32:53 [model.py:1745] Using max model len 40960
INFO 12-04 14:32:53 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:32:53 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:32:53 [model.py:1745] Using max model len 40960
INFO 12-04 14:32:53 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3419067)[0;0m INFO 12-04 14:33:09 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3419071)[0;0m INFO 12-04 14:33:09 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3419071)[0;0m INFO 12-04 14:33:11 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:41375 backend=nccl
[1;36m(EngineCore_DP0 pid=3419067)[0;0m INFO 12-04 14:33:11 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:45203 backend=nccl
[W1204 14:33:11.162952734 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:41375 (errno: 97 - Address family not supported by protocol).
[W1204 14:33:11.166471617 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:45203 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3419067)[0;0m INFO 12-04 14:33:11 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3419071)[0;0m INFO 12-04 14:33:11 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3419071)[0;0m INFO 12-04 14:33:12 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3419067)[0;0m INFO 12-04 14:33:12 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3419071)[0;0m INFO 12-04 14:33:13 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3419071)[0;0m INFO 12-04 14:33:13 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3419067)[0;0m INFO 12-04 14:33:13 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3419067)[0;0m INFO 12-04 14:33:13 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m ERROR 12-04 14:33:14 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3419071 has 23.10 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419067)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419067)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419067)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419067)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419067)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3419071 has 23.10 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m ERROR 12-04 14:33:14 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3419067 has 21.28 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419071)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419071)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419071)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419071)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419071)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3419067 has 21.28 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:33:14.237748698 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:33:14.251341612 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:33:36 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:33:36 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:33:36 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:33:36 [model.py:1745] Using max model len 40960
INFO 12-04 14:33:36 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:33:36 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:33:36 [model.py:1745] Using max model len 40960
INFO 12-04 14:33:36 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3419232)[0;0m INFO 12-04 14:33:54 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3419235)[0;0m INFO 12-04 14:33:54 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3419235)[0;0m INFO 12-04 14:33:56 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:50583 backend=nccl
[1;36m(EngineCore_DP0 pid=3419232)[0;0m INFO 12-04 14:33:56 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:41731 backend=nccl
[W1204 14:33:56.670941865 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:50583 (errno: 97 - Address family not supported by protocol).
[W1204 14:33:56.671070311 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:41731 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3419235)[0;0m INFO 12-04 14:33:56 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3419232)[0;0m INFO 12-04 14:33:56 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3419235)[0;0m INFO 12-04 14:33:56 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3419232)[0;0m INFO 12-04 14:33:56 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3419232)[0;0m INFO 12-04 14:33:57 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3419232)[0;0m INFO 12-04 14:33:57 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3419235)[0;0m INFO 12-04 14:33:57 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3419235)[0;0m INFO 12-04 14:33:57 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m ERROR 12-04 14:33:58 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Process 3419232 has 23.12 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419235)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419235)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419235)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419235)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419235)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Process 3419232 has 23.12 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m ERROR 12-04 14:33:58 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3419235 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419232)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419232)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419232)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419232)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419232)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3419235 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:33:59.681187088 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:33:59.690798401 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:34:20 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:34:20 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:34:20 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:34:20 [model.py:1745] Using max model len 40960
INFO 12-04 14:34:20 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:34:20 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:34:20 [model.py:1745] Using max model len 40960
INFO 12-04 14:34:20 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3419410)[0;0m INFO 12-04 14:34:37 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3419413)[0;0m INFO 12-04 14:34:37 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3419413)[0;0m INFO 12-04 14:34:38 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:54975 backend=nccl
[1;36m(EngineCore_DP0 pid=3419410)[0;0m INFO 12-04 14:34:38 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:45541 backend=nccl
[W1204 14:34:38.256742457 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:54975 (errno: 97 - Address family not supported by protocol).
[W1204 14:34:38.257917408 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:45541 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3419410)[0;0m INFO 12-04 14:34:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3419413)[0;0m INFO 12-04 14:34:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3419410)[0;0m INFO 12-04 14:34:39 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3419413)[0;0m INFO 12-04 14:34:39 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3419413)[0;0m INFO 12-04 14:34:40 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3419413)[0;0m INFO 12-04 14:34:40 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3419410)[0;0m INFO 12-04 14:34:40 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3419410)[0;0m INFO 12-04 14:34:40 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m ERROR 12-04 14:34:41 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3419410 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419413)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419413)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419413)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419413)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419413)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3419410 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m ERROR 12-04 14:34:41 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3419413 has 23.12 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419410)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419410)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419410)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419410)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419410)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3419413 has 23.12 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:34:42.371444202 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:34:42.393046193 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:35:03 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:35:03 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:35:03 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:35:03 [model.py:1745] Using max model len 40960
INFO 12-04 14:35:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:35:03 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:35:03 [model.py:1745] Using max model len 40960
INFO 12-04 14:35:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3419578)[0;0m INFO 12-04 14:35:22 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3419581)[0;0m INFO 12-04 14:35:22 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3419578)[0;0m INFO 12-04 14:35:23 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:46115 backend=nccl
[1;36m(EngineCore_DP0 pid=3419581)[0;0m INFO 12-04 14:35:23 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:51901 backend=nccl
[W1204 14:35:23.095437158 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:46115 (errno: 97 - Address family not supported by protocol).
[W1204 14:35:23.095437192 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:51901 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3419581)[0;0m INFO 12-04 14:35:23 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3419578)[0;0m INFO 12-04 14:35:23 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3419581)[0;0m INFO 12-04 14:35:24 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3419578)[0;0m INFO 12-04 14:35:24 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3419578)[0;0m INFO 12-04 14:35:25 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3419578)[0;0m INFO 12-04 14:35:25 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3419581)[0;0m INFO 12-04 14:35:25 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3419581)[0;0m INFO 12-04 14:35:25 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m ERROR 12-04 14:35:26 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3419581 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419578)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419578)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419578)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419578)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419578)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3419581 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m ERROR 12-04 14:35:26 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3419578 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419581)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419581)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419581)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419581)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419581)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3419578 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:35:26.098327106 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:35:26.098292193 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:35:47 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:35:47 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:35:48 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:35:48 [model.py:1745] Using max model len 40960
INFO 12-04 14:35:48 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:35:48 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:35:48 [model.py:1745] Using max model len 40960
INFO 12-04 14:35:48 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3419821)[0;0m INFO 12-04 14:36:03 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3419818)[0;0m INFO 12-04 14:36:03 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3419821)[0;0m INFO 12-04 14:36:05 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:55849 backend=nccl
[1;36m(EngineCore_DP0 pid=3419818)[0;0m INFO 12-04 14:36:05 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:49253 backend=nccl
[W1204 14:36:05.467207327 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:55849 (errno: 97 - Address family not supported by protocol).
[W1204 14:36:05.472439634 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:49253 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3419818)[0;0m INFO 12-04 14:36:05 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3419821)[0;0m INFO 12-04 14:36:05 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3419818)[0;0m INFO 12-04 14:36:05 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3419821)[0;0m INFO 12-04 14:36:05 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3419818)[0;0m INFO 12-04 14:36:06 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3419818)[0;0m INFO 12-04 14:36:06 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3419821)[0;0m INFO 12-04 14:36:06 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3419821)[0;0m INFO 12-04 14:36:06 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m ERROR 12-04 14:36:07 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3419818 has 22.50 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419821)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419821)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419821)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419821)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419821)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 3419818 has 22.50 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m ERROR 12-04 14:36:07 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3419821 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3419818)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3419818)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3419818)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3419818)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3419818)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 3419821 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:36:08.510288419 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:36:08.510288291 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:36:29 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:36:29 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:36:29 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:36:29 [model.py:1745] Using max model len 40960
INFO 12-04 14:36:29 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:36:29 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:36:29 [model.py:1745] Using max model len 40960
INFO 12-04 14:36:29 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3420057)[0;0m INFO 12-04 14:36:47 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3420054)[0;0m INFO 12-04 14:36:47 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3420057)[0;0m INFO 12-04 14:36:48 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:56053 backend=nccl
[1;36m(EngineCore_DP0 pid=3420054)[0;0m INFO 12-04 14:36:48 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:37857 backend=nccl
[W1204 14:36:48.808533028 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:56053 (errno: 97 - Address family not supported by protocol).
[W1204 14:36:48.809471797 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:37857 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3420054)[0;0m INFO 12-04 14:36:48 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3420057)[0;0m INFO 12-04 14:36:48 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3420054)[0;0m INFO 12-04 14:36:48 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3420057)[0;0m INFO 12-04 14:36:48 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3420057)[0;0m INFO 12-04 14:36:49 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3420057)[0;0m INFO 12-04 14:36:49 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3420054)[0;0m INFO 12-04 14:36:49 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3420054)[0;0m INFO 12-04 14:36:49 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m ERROR 12-04 14:36:50 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 3420057 has 23.69 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3420054)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3420054)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3420054)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420054)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420054)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 3420057 has 23.69 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m ERROR 12-04 14:36:50 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3420054 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3420057)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3420057)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3420057)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420057)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420057)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3420054 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:36:51.892845853 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:36:51.924596301 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:37:12 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:37:12 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:37:12 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:37:12 [model.py:1745] Using max model len 40960
INFO 12-04 14:37:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:37:12 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:37:12 [model.py:1745] Using max model len 40960
INFO 12-04 14:37:12 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3420194)[0;0m INFO 12-04 14:37:26 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3420197)[0;0m INFO 12-04 14:37:26 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3420194)[0;0m INFO 12-04 14:37:28 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:37359 backend=nccl
[1;36m(EngineCore_DP0 pid=3420197)[0;0m INFO 12-04 14:37:28 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:39247 backend=nccl
[W1204 14:37:28.506423494 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:37359 (errno: 97 - Address family not supported by protocol).
[W1204 14:37:28.508166954 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:39247 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3420194)[0;0m INFO 12-04 14:37:28 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3420197)[0;0m INFO 12-04 14:37:28 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3420194)[0;0m INFO 12-04 14:37:28 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3420197)[0;0m INFO 12-04 14:37:28 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3420194)[0;0m INFO 12-04 14:37:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3420194)[0;0m INFO 12-04 14:37:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3420197)[0;0m INFO 12-04 14:37:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3420197)[0;0m INFO 12-04 14:37:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m ERROR 12-04 14:37:30 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3420197 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3420194)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3420194)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3420194)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420194)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420194)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 3420197 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m ERROR 12-04 14:37:30 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3420194 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3420197)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3420197)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3420197)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420197)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420197)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3420194 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:37:31.523710937 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:37:31.523711037 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:37:52 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:37:52 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:37:52 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:37:52 [model.py:1745] Using max model len 40960
INFO 12-04 14:37:52 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:37:52 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:37:52 [model.py:1745] Using max model len 40960
INFO 12-04 14:37:52 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=3420327)[0;0m INFO 12-04 14:38:10 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3420330)[0;0m INFO 12-04 14:38:10 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=3420330)[0;0m INFO 12-04 14:38:12 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:34977 backend=nccl
[1;36m(EngineCore_DP0 pid=3420327)[0;0m INFO 12-04 14:38:12 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.100:41177 backend=nccl
[W1204 14:38:12.491832182 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:34977 (errno: 97 - Address family not supported by protocol).
[W1204 14:38:12.493844667 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-1.rc.tch.harvard.edu]:41177 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3420327)[0;0m INFO 12-04 14:38:12 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3420330)[0;0m INFO 12-04 14:38:12 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3420327)[0;0m INFO 12-04 14:38:12 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3420330)[0;0m INFO 12-04 14:38:12 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=3420330)[0;0m INFO 12-04 14:38:13 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3420330)[0;0m INFO 12-04 14:38:13 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3420327)[0;0m INFO 12-04 14:38:13 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=3420327)[0;0m INFO 12-04 14:38:13 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m ERROR 12-04 14:38:14 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3420330 has 23.10 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3420327)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3420327)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3420327)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420327)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420327)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 3420330 has 23.10 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m ERROR 12-04 14:38:14 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3420327 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=3420330)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=3420330)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=3420330)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=3420330)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=3420330)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 3420327 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:38:15.539309293 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:38:15.545317109 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
slurmstepd-gpu-26-1: error: *** STEP 12735849.0 ON gpu-26-1 CANCELLED AT 2025-12-04T14:38:17 ***
srun: Job step aborted: Waiting up to 62 seconds for job step to finish.
