Using persona diversity with 7 different personas
============================================================
Math Task - Multiagent Debate (NO COMPRESSION)
============================================================
Model: Qwen/Qwen3-14B
Persona diversity mode:
  Agent 1: a Roman imperial jurist who strictly adheres to precedent an...
  Agent 2: a radical anarchist who views all imposed structures and hie...
  Agent 3: an enigma machine operator whose primary filter is signal-to...
  Agent 4: a Zen master who communicates only through non-sequiturs, ko...
  Agent 5: a deep-sea volcanologist focused on extremes of pressure, he...
  Agent 6: a systems engineer who focuses strictly on modularity, inter...
  Agent 7: a mythological hero's sidekick who is overly cautious, risk-...
Agents: 7
Rounds: 3
Problems: 20
Generation params: {'temperature': 1.0, 'max_tokens': None, 'top_p': 1.0, 'n': 1}
============================================================
Using persona diversity with 7 different personas
============================================================
Math Task - Multiagent Debate (NO COMPRESSION)
============================================================
Model: Qwen/Qwen3-14B
Persona diversity mode:
  Agent 1: a Roman imperial jurist who strictly adheres to precedent an...
  Agent 2: a radical anarchist who views all imposed structures and hie...
  Agent 3: an enigma machine operator whose primary filter is signal-to...
  Agent 4: a Zen master who communicates only through non-sequiturs, ko...
  Agent 5: a deep-sea volcanologist focused on extremes of pressure, he...
  Agent 6: a systems engineer who focuses strictly on modularity, inter...
  Agent 7: a mythological hero's sidekick who is overly cautious, risk-...
Agents: 7
Rounds: 3
Problems: 20
Generation params: {'temperature': 1.0, 'max_tokens': None, 'top_p': 1.0, 'n': 1}
============================================================

--- Problem 1/20, Round 1, Agent 1/7 ---
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:48:16 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}

--- Problem 1/20, Round 1, Agent 1/7 ---
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:48:16 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:48:16 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:48:16 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:48:16 [model.py:1745] Using max model len 40960
INFO 12-04 13:48:16 [model.py:1745] Using max model len 40960
INFO 12-04 13:48:20 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:48:20 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2162496)[0;0m INFO 12-04 13:48:50 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2162502)[0;0m INFO 12-04 13:48:50 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2162496)[0;0m INFO 12-04 13:48:59 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:59583 backend=nccl
[1;36m(EngineCore_DP0 pid=2162502)[0;0m INFO 12-04 13:48:59 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:40371 backend=nccl
  0%|          | 0/20 [00:00<?, ?it/s][W1204 13:48:59.008741778 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:59583 (errno: 97 - Address family not supported by protocol).
  0%|          | 0/20 [00:00<?, ?it/s][W1204 13:48:59.008776243 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:40371 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2162502)[0;0m INFO 12-04 13:48:59 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2162496)[0;0m INFO 12-04 13:48:59 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2162496)[0;0m INFO 12-04 13:49:00 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2162502)[0;0m INFO 12-04 13:49:00 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2162496)[0;0m INFO 12-04 13:49:04 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2162496)[0;0m INFO 12-04 13:49:04 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2162502)[0;0m INFO 12-04 13:49:04 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2162502)[0;0m INFO 12-04 13:49:04 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m ERROR 12-04 13:49:05 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Process 2162502 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m ERROR 12-04 13:49:05 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2162496 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2162496)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2162496)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2162496)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2162496)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2162496)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2162502)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2162496)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2162496)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2162496)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162496)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Process 2162502 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2162502)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2162502)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2162502)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2162502)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2162496 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:49:05.222448919 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:49:05.222448916 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:49:33 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:49:33 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:49:33 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:49:33 [model.py:1745] Using max model len 40960
INFO 12-04 13:49:33 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:49:33 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:49:33 [model.py:1745] Using max model len 40960
INFO 12-04 13:49:33 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2164384)[0;0m INFO 12-04 13:50:02 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2164387)[0;0m INFO 12-04 13:50:02 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2164384)[0;0m INFO 12-04 13:50:06 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:50733 backend=nccl
[1;36m(EngineCore_DP0 pid=2164387)[0;0m INFO 12-04 13:50:06 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:40137 backend=nccl
[W1204 13:50:06.506309400 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:50733 (errno: 97 - Address family not supported by protocol).
[W1204 13:50:06.507377876 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:40137 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2164384)[0;0m INFO 12-04 13:50:06 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2164387)[0;0m INFO 12-04 13:50:06 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2164384)[0;0m INFO 12-04 13:50:06 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2164387)[0;0m INFO 12-04 13:50:06 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2164384)[0;0m INFO 12-04 13:50:07 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2164384)[0;0m INFO 12-04 13:50:07 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2164387)[0;0m INFO 12-04 13:50:07 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2164387)[0;0m INFO 12-04 13:50:07 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m ERROR 12-04 13:50:08 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2164384 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2164387)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2164387)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2164387)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2164387)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164387)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2164384 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m ERROR 12-04 13:50:08 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2164387 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2164384)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2164384)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2164384)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2164384)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2164384)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2164387 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:50:09.705581895 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:50:09.717870574 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:50:30 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:50:30 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:50:30 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:50:30 [model.py:1745] Using max model len 40960
INFO 12-04 13:50:30 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:50:30 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:50:30 [model.py:1745] Using max model len 40960
INFO 12-04 13:50:30 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2165645)[0;0m INFO 12-04 13:50:57 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2165648)[0;0m INFO 12-04 13:50:57 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2165645)[0;0m INFO 12-04 13:50:59 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:38591 backend=nccl
[1;36m(EngineCore_DP0 pid=2165648)[0;0m INFO 12-04 13:50:59 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:49215 backend=nccl
[W1204 13:50:59.209037037 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:38591 (errno: 97 - Address family not supported by protocol).
[W1204 13:50:59.211610399 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:49215 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2165648)[0;0m INFO 12-04 13:50:59 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2165645)[0;0m INFO 12-04 13:50:59 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2165645)[0;0m INFO 12-04 13:51:00 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2165648)[0;0m INFO 12-04 13:51:00 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2165645)[0;0m INFO 12-04 13:51:01 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2165645)[0;0m INFO 12-04 13:51:01 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2165648)[0;0m INFO 12-04 13:51:01 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2165648)[0;0m INFO 12-04 13:51:01 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m ERROR 12-04 13:51:02 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2165645 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2165648)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2165648)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2165648)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2165648)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165648)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2165645 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m ERROR 12-04 13:51:02 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2165648 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2165645)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2165645)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2165645)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2165645)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2165645)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2165648 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:51:02.165762626 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:51:02.165762751 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:51:23 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:51:23 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:51:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:51:24 [model.py:1745] Using max model len 40960
INFO 12-04 13:51:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:51:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:51:24 [model.py:1745] Using max model len 40960
INFO 12-04 13:51:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2166518)[0;0m INFO 12-04 13:51:51 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2166521)[0;0m INFO 12-04 13:51:51 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2166521)[0;0m INFO 12-04 13:51:54 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:33567 backend=nccl
[1;36m(EngineCore_DP0 pid=2166518)[0;0m INFO 12-04 13:51:54 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:51093 backend=nccl
[W1204 13:51:54.903228274 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:33567 (errno: 97 - Address family not supported by protocol).
[W1204 13:51:54.904678736 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:51093 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2166521)[0;0m INFO 12-04 13:51:54 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2166518)[0;0m INFO 12-04 13:51:54 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2166518)[0;0m INFO 12-04 13:51:55 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2166521)[0;0m INFO 12-04 13:51:55 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2166518)[0;0m INFO 12-04 13:51:56 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2166518)[0;0m INFO 12-04 13:51:56 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2166521)[0;0m INFO 12-04 13:51:56 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2166521)[0;0m INFO 12-04 13:51:56 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m ERROR 12-04 13:51:57 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2166521 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2166518)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2166518)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2166518)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2166518)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166518)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2166521 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m ERROR 12-04 13:51:57 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2166518 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2166521)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2166521)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2166521)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2166521)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2166521)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2166518 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:51:57.068233382 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:51:57.078224466 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:52:18 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:52:18 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:52:19 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:52:19 [model.py:1745] Using max model len 40960
INFO 12-04 13:52:19 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:52:19 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:52:19 [model.py:1745] Using max model len 40960
INFO 12-04 13:52:19 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2167482)[0;0m INFO 12-04 13:52:43 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2167479)[0;0m INFO 12-04 13:52:43 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2167479)[0;0m INFO 12-04 13:52:46 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:46349 backend=nccl
[1;36m(EngineCore_DP0 pid=2167482)[0;0m INFO 12-04 13:52:46 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:37251 backend=nccl
[W1204 13:52:46.522511971 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:37251 (errno: 97 - Address family not supported by protocol).
[W1204 13:52:46.522511966 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:46349 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2167482)[0;0m INFO 12-04 13:52:46 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2167479)[0;0m INFO 12-04 13:52:46 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2167482)[0;0m INFO 12-04 13:52:46 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2167479)[0;0m INFO 12-04 13:52:46 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2167482)[0;0m INFO 12-04 13:52:47 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2167482)[0;0m INFO 12-04 13:52:47 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2167479)[0;0m INFO 12-04 13:52:47 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2167479)[0;0m INFO 12-04 13:52:47 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m ERROR 12-04 13:52:48 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2167482 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2167479)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2167479)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2167479)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2167479)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167479)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2167482 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m ERROR 12-04 13:52:48 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2167479 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2167482)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2167482)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2167482)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2167482)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2167482)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2167479 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:52:49.621407264 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:52:49.629941279 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:53:10 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:53:10 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:53:10 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:53:10 [model.py:1745] Using max model len 40960
INFO 12-04 13:53:10 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:53:10 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:53:10 [model.py:1745] Using max model len 40960
INFO 12-04 13:53:10 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2168372)[0;0m INFO 12-04 13:53:36 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2168369)[0;0m INFO 12-04 13:53:36 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2168369)[0;0m INFO 12-04 13:53:39 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:48093 backend=nccl
[1;36m(EngineCore_DP0 pid=2168372)[0;0m INFO 12-04 13:53:39 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:47081 backend=nccl
[W1204 13:53:39.445454331 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:48093 (errno: 97 - Address family not supported by protocol).
[W1204 13:53:39.445824964 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:47081 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2168372)[0;0m INFO 12-04 13:53:39 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2168369)[0;0m INFO 12-04 13:53:39 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2168372)[0;0m INFO 12-04 13:53:39 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2168369)[0;0m INFO 12-04 13:53:39 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2168372)[0;0m INFO 12-04 13:53:40 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2168372)[0;0m INFO 12-04 13:53:40 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2168369)[0;0m INFO 12-04 13:53:40 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2168369)[0;0m INFO 12-04 13:53:40 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m ERROR 12-04 13:53:41 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2168369 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2168372)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2168372)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2168372)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2168372)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168372)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2168369 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m ERROR 12-04 13:53:41 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2168372 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2168369)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2168369)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2168369)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2168369)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2168369)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2168372 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:53:42.545298224 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:53:42.551446931 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:54:03 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:54:03 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:54:03 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:54:03 [model.py:1745] Using max model len 40960
INFO 12-04 13:54:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:54:03 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:54:03 [model.py:1745] Using max model len 40960
INFO 12-04 13:54:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2169470)[0;0m INFO 12-04 13:54:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2169469)[0;0m INFO 12-04 13:54:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2169470)[0;0m INFO 12-04 13:54:30 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:53683 backend=nccl
[1;36m(EngineCore_DP0 pid=2169469)[0;0m INFO 12-04 13:54:30 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:55787 backend=nccl
[W1204 13:54:30.779543547 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:53683 (errno: 97 - Address family not supported by protocol).
[W1204 13:54:30.780485519 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:55787 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2169470)[0;0m INFO 12-04 13:54:30 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2169469)[0;0m INFO 12-04 13:54:30 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2169470)[0;0m INFO 12-04 13:54:31 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2169469)[0;0m INFO 12-04 13:54:31 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2169470)[0;0m INFO 12-04 13:54:32 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2169470)[0;0m INFO 12-04 13:54:32 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2169469)[0;0m INFO 12-04 13:54:32 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2169469)[0;0m INFO 12-04 13:54:32 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m ERROR 12-04 13:54:32 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2169469 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2169470)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2169470)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2169470)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2169470)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169470)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2169469 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m ERROR 12-04 13:54:32 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2169470 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2169469)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2169469)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2169469)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2169469)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2169469)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2169470 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:54:33.986322918 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:54:33.996675785 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:54:54 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:54:54 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:54:54 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:54:54 [model.py:1745] Using max model len 40960
INFO 12-04 13:54:54 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:54:55 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:54:55 [model.py:1745] Using max model len 40960
INFO 12-04 13:54:55 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2170178)[0;0m INFO 12-04 13:55:23 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2170181)[0;0m INFO 12-04 13:55:23 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2170181)[0;0m INFO 12-04 13:55:25 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:50389 backend=nccl
[1;36m(EngineCore_DP0 pid=2170178)[0;0m INFO 12-04 13:55:25 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:36223 backend=nccl
[W1204 13:55:25.333355553 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:50389 (errno: 97 - Address family not supported by protocol).
[W1204 13:55:25.333355766 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:36223 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2170181)[0;0m INFO 12-04 13:55:26 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2170178)[0;0m INFO 12-04 13:55:26 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2170181)[0;0m INFO 12-04 13:55:26 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2170178)[0;0m INFO 12-04 13:55:26 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2170178)[0;0m INFO 12-04 13:55:27 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2170178)[0;0m INFO 12-04 13:55:27 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2170181)[0;0m INFO 12-04 13:55:27 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2170181)[0;0m INFO 12-04 13:55:27 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m ERROR 12-04 13:55:28 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2170181 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2170178)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2170178)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2170178)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2170178)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170178)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2170181 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m ERROR 12-04 13:55:28 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2170178 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2170181)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2170181)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2170181)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2170181)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2170181)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2170178 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:55:29.381813280 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:55:29.410972210 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:55:50 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:55:50 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:55:50 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:55:50 [model.py:1745] Using max model len 40960
INFO 12-04 13:55:50 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:55:50 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:55:50 [model.py:1745] Using max model len 40960
INFO 12-04 13:55:50 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2171372)[0;0m INFO 12-04 13:56:11 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2171369)[0;0m INFO 12-04 13:56:11 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2171372)[0;0m INFO 12-04 13:56:14 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:37171 backend=nccl
[1;36m(EngineCore_DP0 pid=2171369)[0;0m INFO 12-04 13:56:14 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:57437 backend=nccl
[W1204 13:56:14.407485239 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:37171 (errno: 97 - Address family not supported by protocol).
[W1204 13:56:14.407485227 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:57437 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2171369)[0;0m INFO 12-04 13:56:14 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2171372)[0;0m INFO 12-04 13:56:14 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2171372)[0;0m INFO 12-04 13:56:14 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2171369)[0;0m INFO 12-04 13:56:14 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2171369)[0;0m INFO 12-04 13:56:15 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2171369)[0;0m INFO 12-04 13:56:15 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2171372)[0;0m INFO 12-04 13:56:15 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2171372)[0;0m INFO 12-04 13:56:15 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m ERROR 12-04 13:56:16 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 2171369 has 23.10 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2171372)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2171372)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2171372)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2171372)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171372)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 2171369 has 23.10 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m ERROR 12-04 13:56:16 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2171372 has 21.28 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2171369)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2171369)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2171369)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2171369)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2171369)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2171372 has 21.28 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:56:17.445015472 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:56:17.452188413 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:56:38 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:56:38 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:56:38 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:56:38 [model.py:1745] Using max model len 40960
INFO 12-04 13:56:38 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:56:38 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:56:38 [model.py:1745] Using max model len 40960
INFO 12-04 13:56:38 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2172345)[0;0m INFO 12-04 13:57:00 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2172339)[0;0m INFO 12-04 13:57:00 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2172339)[0;0m INFO 12-04 13:57:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:59019 backend=nccl
[1;36m(EngineCore_DP0 pid=2172345)[0;0m INFO 12-04 13:57:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:47643 backend=nccl
[W1204 13:57:02.201488584 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:59019 (errno: 97 - Address family not supported by protocol).
[W1204 13:57:02.204964285 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:47643 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2172345)[0;0m INFO 12-04 13:57:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2172339)[0;0m INFO 12-04 13:57:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2172345)[0;0m INFO 12-04 13:57:03 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2172339)[0;0m INFO 12-04 13:57:03 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2172339)[0;0m INFO 12-04 13:57:04 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2172339)[0;0m INFO 12-04 13:57:04 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2172345)[0;0m INFO 12-04 13:57:04 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2172345)[0;0m INFO 12-04 13:57:04 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m ERROR 12-04 13:57:05 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2172339 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2172345)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2172345)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2172345)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2172345)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172345)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2172339 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m ERROR 12-04 13:57:05 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2172345 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2172339)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2172339)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2172339)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2172339)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2172339)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2172345 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:57:05.290493644 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:57:05.294479193 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:57:27 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:57:27 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:57:27 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:57:27 [model.py:1745] Using max model len 40960
INFO 12-04 13:57:27 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:57:27 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:57:27 [model.py:1745] Using max model len 40960
INFO 12-04 13:57:27 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2173360)[0;0m INFO 12-04 13:57:54 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2173363)[0;0m INFO 12-04 13:57:54 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2173363)[0;0m INFO 12-04 13:57:57 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:60369 backend=nccl
[1;36m(EngineCore_DP0 pid=2173360)[0;0m INFO 12-04 13:57:57 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:33577 backend=nccl
[W1204 13:57:57.696462229 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:60369 (errno: 97 - Address family not supported by protocol).
[W1204 13:57:57.696352802 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:33577 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2173363)[0;0m INFO 12-04 13:57:57 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2173360)[0;0m INFO 12-04 13:57:57 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2173363)[0;0m INFO 12-04 13:57:57 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2173360)[0;0m INFO 12-04 13:57:57 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2173360)[0;0m INFO 12-04 13:57:58 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2173360)[0;0m INFO 12-04 13:57:58 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2173363)[0;0m INFO 12-04 13:57:58 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2173363)[0;0m INFO 12-04 13:57:58 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m ERROR 12-04 13:57:59 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2173363 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2173360)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2173360)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2173360)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2173360)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173360)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2173363 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m ERROR 12-04 13:57:59 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Process 2173360 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2173363)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2173363)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2173363)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2173363)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2173363)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Process 2173360 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:58:00.818400620 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:58:00.823538014 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:58:21 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:58:21 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:58:21 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:58:21 [model.py:1745] Using max model len 40960
INFO 12-04 13:58:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:58:21 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:58:21 [model.py:1745] Using max model len 40960
INFO 12-04 13:58:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2174217)[0;0m INFO 12-04 13:58:50 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2174214)[0;0m INFO 12-04 13:58:50 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2174217)[0;0m INFO 12-04 13:58:52 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:47021 backend=nccl
[1;36m(EngineCore_DP0 pid=2174214)[0;0m INFO 12-04 13:58:52 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:60575 backend=nccl
[W1204 13:58:52.991269074 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:47021 (errno: 97 - Address family not supported by protocol).
[W1204 13:58:52.991269045 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:60575 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2174217)[0;0m INFO 12-04 13:58:52 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2174214)[0;0m INFO 12-04 13:58:52 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2174217)[0;0m INFO 12-04 13:58:53 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2174214)[0;0m INFO 12-04 13:58:53 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2174217)[0;0m INFO 12-04 13:58:54 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2174217)[0;0m INFO 12-04 13:58:54 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2174214)[0;0m INFO 12-04 13:58:54 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2174214)[0;0m INFO 12-04 13:58:54 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m ERROR 12-04 13:58:55 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2174214 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m ERROR 12-04 13:58:55 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2174217 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2174214)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2174217)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2174217)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2174217)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2174214)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2174214)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2174214)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2174214)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2174214)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2174217 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2174217)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2174214 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:58:55.076095852 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:58:55.076095835 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:59:16 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 13:59:16 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 13:59:17 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:59:17 [model.py:1745] Using max model len 40960
INFO 12-04 13:59:17 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 13:59:17 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 13:59:17 [model.py:1745] Using max model len 40960
INFO 12-04 13:59:17 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2175217)[0;0m INFO 12-04 13:59:43 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2175214)[0;0m INFO 12-04 13:59:43 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2175217)[0;0m INFO 12-04 13:59:46 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:48437 backend=nccl
[1;36m(EngineCore_DP0 pid=2175214)[0;0m INFO 12-04 13:59:46 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:45349 backend=nccl
[W1204 13:59:46.950067795 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:48437 (errno: 97 - Address family not supported by protocol).
[W1204 13:59:46.951259035 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:45349 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2175217)[0;0m INFO 12-04 13:59:46 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2175214)[0;0m INFO 12-04 13:59:46 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2175217)[0;0m INFO 12-04 13:59:47 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2175214)[0;0m INFO 12-04 13:59:47 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2175217)[0;0m INFO 12-04 13:59:48 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2175217)[0;0m INFO 12-04 13:59:48 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2175214)[0;0m INFO 12-04 13:59:48 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2175214)[0;0m INFO 12-04 13:59:48 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m ERROR 12-04 13:59:49 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 2175217 has 23.12 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2175214)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2175214)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2175214)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2175214)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175214)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Process 2175217 has 23.12 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m ERROR 12-04 13:59:49 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2175214 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2175217)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2175217)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2175217)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2175217)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2175217)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2175214 has 21.25 GiB memory in use. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 13:59:49.042922837 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 13:59:49.066131317 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:00:10 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:00:10 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:00:11 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:00:11 [model.py:1745] Using max model len 40960
INFO 12-04 14:00:11 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:00:11 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:00:11 [model.py:1745] Using max model len 40960
INFO 12-04 14:00:11 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2176219)[0;0m INFO 12-04 14:01:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2176218)[0;0m INFO 12-04 14:01:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2176219)[0;0m INFO 12-04 14:01:08 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:60383 backend=nccl
[1;36m(EngineCore_DP0 pid=2176218)[0;0m INFO 12-04 14:01:08 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:45459 backend=nccl
[W1204 14:01:08.218366251 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:60383 (errno: 97 - Address family not supported by protocol).
[W1204 14:01:08.220970203 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:45459 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2176219)[0;0m INFO 12-04 14:01:08 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2176218)[0;0m INFO 12-04 14:01:08 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2176219)[0;0m INFO 12-04 14:01:09 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2176218)[0;0m INFO 12-04 14:01:09 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2176219)[0;0m INFO 12-04 14:01:10 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2176219)[0;0m INFO 12-04 14:01:10 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2176218)[0;0m INFO 12-04 14:01:10 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2176218)[0;0m INFO 12-04 14:01:10 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m ERROR 12-04 14:01:11 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2176218 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m ERROR 12-04 14:01:11 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2176219 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2176219)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2176218)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2176219)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2176219)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2176218)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2176218)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2176218)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176218)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2176219 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2176219)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2176219)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2176219)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2176218 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:01:12.715579896 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:01:12.772913369 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:01:33 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:01:33 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:01:33 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:01:33 [model.py:1745] Using max model len 40960
INFO 12-04 14:01:33 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:01:33 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:01:33 [model.py:1745] Using max model len 40960
INFO 12-04 14:01:33 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2177617)[0;0m INFO 12-04 14:02:10 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2177614)[0;0m INFO 12-04 14:02:10 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2177614)[0;0m INFO 12-04 14:02:13 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:49129 backend=nccl
[1;36m(EngineCore_DP0 pid=2177617)[0;0m INFO 12-04 14:02:13 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:60981 backend=nccl
[W1204 14:02:13.797045272 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:49129 (errno: 97 - Address family not supported by protocol).
[W1204 14:02:13.799739935 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:60981 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2177614)[0;0m INFO 12-04 14:02:13 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2177617)[0;0m INFO 12-04 14:02:13 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2177617)[0;0m INFO 12-04 14:02:13 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2177614)[0;0m INFO 12-04 14:02:13 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2177617)[0;0m INFO 12-04 14:02:15 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2177617)[0;0m INFO 12-04 14:02:15 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2177614)[0;0m INFO 12-04 14:02:15 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2177614)[0;0m INFO 12-04 14:02:15 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m ERROR 12-04 14:02:15 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2177614 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2177617)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2177617)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2177617)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2177617)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177617)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2177614 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m ERROR 12-04 14:02:15 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2177617 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2177614)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2177614)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2177614)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2177614)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2177614)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2177617 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:02:16.002357248 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:02:16.002357506 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:02:37 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:02:37 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:02:38 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:02:38 [model.py:1745] Using max model len 40960
INFO 12-04 14:02:38 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:02:38 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:02:38 [model.py:1745] Using max model len 40960
INFO 12-04 14:02:38 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2178618)[0;0m INFO 12-04 14:03:02 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2178617)[0;0m INFO 12-04 14:03:02 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2178618)[0;0m INFO 12-04 14:03:04 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:43995 backend=nccl
[1;36m(EngineCore_DP0 pid=2178617)[0;0m INFO 12-04 14:03:04 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:59207 backend=nccl
[W1204 14:03:04.870781557 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:43995 (errno: 97 - Address family not supported by protocol).
[W1204 14:03:04.872820004 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:59207 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2178617)[0;0m INFO 12-04 14:03:04 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2178618)[0;0m INFO 12-04 14:03:04 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2178617)[0;0m INFO 12-04 14:03:05 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2178618)[0;0m INFO 12-04 14:03:05 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2178617)[0;0m INFO 12-04 14:03:06 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2178617)[0;0m INFO 12-04 14:03:06 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2178618)[0;0m INFO 12-04 14:03:06 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2178618)[0;0m INFO 12-04 14:03:06 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m ERROR 12-04 14:03:06 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Process 2178617 has 24.94 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2178618)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2178618)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2178618)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2178618)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178618)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Process 2178617 has 24.94 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m ERROR 12-04 14:03:06 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2178618 has 19.40 GiB memory in use. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2178617)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2178617)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2178617)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2178617)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2178617)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2178618 has 19.40 GiB memory in use. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:03:07.899088023 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:03:07.942463959 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:03:28 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:03:28 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:03:28 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:03:28 [model.py:1745] Using max model len 40960
INFO 12-04 14:03:28 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:03:28 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:03:28 [model.py:1745] Using max model len 40960
INFO 12-04 14:03:28 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2179321)[0;0m INFO 12-04 14:04:06 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2179324)[0;0m INFO 12-04 14:04:06 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2179321)[0;0m INFO 12-04 14:04:11 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:49421 backend=nccl
[1;36m(EngineCore_DP0 pid=2179324)[0;0m INFO 12-04 14:04:11 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:53645 backend=nccl
[W1204 14:04:11.404845921 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:49421 (errno: 97 - Address family not supported by protocol).
[W1204 14:04:11.404808051 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:53645 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2179324)[0;0m INFO 12-04 14:04:11 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2179321)[0;0m INFO 12-04 14:04:11 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2179321)[0;0m INFO 12-04 14:04:11 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2179324)[0;0m INFO 12-04 14:04:11 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2179321)[0;0m INFO 12-04 14:04:13 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2179321)[0;0m INFO 12-04 14:04:13 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2179324)[0;0m INFO 12-04 14:04:13 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2179324)[0;0m INFO 12-04 14:04:13 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m ERROR 12-04 14:04:13 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2179321 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2179324)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2179324)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2179324)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2179324)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179324)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2179321 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m ERROR 12-04 14:04:13 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2179324 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2179321)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2179321)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2179321)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2179321)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2179321)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2179324 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:04:14.060886476 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:04:14.060886363 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:04:35 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:04:35 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:04:36 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:04:36 [model.py:1745] Using max model len 40960
INFO 12-04 14:04:36 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:04:36 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:04:36 [model.py:1745] Using max model len 40960
INFO 12-04 14:04:36 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2180687)[0;0m INFO 12-04 14:05:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2180689)[0;0m INFO 12-04 14:05:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2180689)[0;0m INFO 12-04 14:05:30 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:41673 backend=nccl
[1;36m(EngineCore_DP0 pid=2180687)[0;0m INFO 12-04 14:05:30 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:47161 backend=nccl
[W1204 14:05:30.517448914 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:41673 (errno: 97 - Address family not supported by protocol).
[W1204 14:05:30.519841410 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:47161 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2180689)[0;0m INFO 12-04 14:05:30 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2180687)[0;0m INFO 12-04 14:05:30 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2180689)[0;0m INFO 12-04 14:05:30 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2180687)[0;0m INFO 12-04 14:05:30 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2180689)[0;0m INFO 12-04 14:05:31 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2180689)[0;0m INFO 12-04 14:05:31 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2180687)[0;0m INFO 12-04 14:05:31 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2180687)[0;0m INFO 12-04 14:05:31 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m ERROR 12-04 14:05:32 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2180689 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2180687)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2180687)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2180687)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2180687)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180687)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2180689 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m ERROR 12-04 14:05:32 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2180687 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2180689)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2180689)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2180689)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2180689)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2180689)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2180687 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:05:33.652448231 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:05:33.657735977 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:05:54 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:05:54 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:05:54 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:05:54 [model.py:1745] Using max model len 40960
INFO 12-04 14:05:54 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:05:54 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:05:54 [model.py:1745] Using max model len 40960
INFO 12-04 14:05:54 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2182031)[0;0m INFO 12-04 14:06:40 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2182032)[0;0m INFO 12-04 14:06:40 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2182032)[0;0m INFO 12-04 14:06:44 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:39959 backend=nccl
[1;36m(EngineCore_DP0 pid=2182031)[0;0m INFO 12-04 14:06:44 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:55343 backend=nccl
[W1204 14:06:44.097739906 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:39959 (errno: 97 - Address family not supported by protocol).
[W1204 14:06:44.099521434 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:55343 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2182032)[0;0m INFO 12-04 14:06:44 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2182031)[0;0m INFO 12-04 14:06:44 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2182032)[0;0m INFO 12-04 14:06:45 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2182031)[0;0m INFO 12-04 14:06:45 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2182032)[0;0m INFO 12-04 14:06:46 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2182032)[0;0m INFO 12-04 14:06:46 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2182031)[0;0m INFO 12-04 14:06:46 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2182031)[0;0m INFO 12-04 14:06:46 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m ERROR 12-04 14:06:47 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2182031 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2182032)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2182032)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182032)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2182032)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2182032)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2182032)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2182031 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m ERROR 12-04 14:06:47 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2182032 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2182031)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2182031)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2182031)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2182031)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2182031)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2182032 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:06:48.577912613 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:06:48.584385350 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:07:09 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:07:09 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:07:09 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:07:09 [model.py:1745] Using max model len 40960
INFO 12-04 14:07:09 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:07:09 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:07:09 [model.py:1745] Using max model len 40960
INFO 12-04 14:07:09 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2183397)[0;0m INFO 12-04 14:08:06 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2183400)[0;0m INFO 12-04 14:08:06 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2183400)[0;0m INFO 12-04 14:08:11 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:40445 backend=nccl
[1;36m(EngineCore_DP0 pid=2183397)[0;0m INFO 12-04 14:08:11 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:42833 backend=nccl
[W1204 14:08:11.613983000 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:40445 (errno: 97 - Address family not supported by protocol).
[W1204 14:08:11.616470746 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:42833 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2183400)[0;0m INFO 12-04 14:08:11 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2183397)[0;0m INFO 12-04 14:08:11 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2183400)[0;0m INFO 12-04 14:08:11 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2183397)[0;0m INFO 12-04 14:08:11 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2183397)[0;0m INFO 12-04 14:08:13 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2183397)[0;0m INFO 12-04 14:08:13 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2183400)[0;0m INFO 12-04 14:08:13 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2183400)[0;0m INFO 12-04 14:08:13 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m ERROR 12-04 14:08:14 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2183400 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m ERROR 12-04 14:08:14 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2183397 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2183400)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2183397)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2183397)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2183397)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2183397)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183397)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2183400 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2183400)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2183400)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2183400)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2183400)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2183400)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2183397 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:08:15.455595593 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:08:15.477317931 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:08:36 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:08:36 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:08:36 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:08:36 [model.py:1745] Using max model len 40960
INFO 12-04 14:08:36 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:08:36 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:08:36 [model.py:1745] Using max model len 40960
INFO 12-04 14:08:36 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2184977)[0;0m INFO 12-04 14:09:24 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2184978)[0;0m INFO 12-04 14:09:24 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2184977)[0;0m INFO 12-04 14:09:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:38879 backend=nccl
[1;36m(EngineCore_DP0 pid=2184978)[0;0m INFO 12-04 14:09:27 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:58833 backend=nccl
[W1204 14:09:27.735497586 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:58833 (errno: 97 - Address family not supported by protocol).
[W1204 14:09:27.735833470 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:38879 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2184977)[0;0m INFO 12-04 14:09:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2184978)[0;0m INFO 12-04 14:09:27 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2184978)[0;0m INFO 12-04 14:09:28 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2184977)[0;0m INFO 12-04 14:09:28 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2184977)[0;0m INFO 12-04 14:09:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2184977)[0;0m INFO 12-04 14:09:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2184978)[0;0m INFO 12-04 14:09:29 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2184978)[0;0m INFO 12-04 14:09:29 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m ERROR 12-04 14:09:30 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2184977 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2184978)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2184978)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2184978)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2184978)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184978)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2184977 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m ERROR 12-04 14:09:30 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2184978 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2184977)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2184977)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2184977)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2184977)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2184977)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2184978 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:09:31.734861844 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:09:31.736405482 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:09:52 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:09:52 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:09:52 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:09:52 [model.py:1745] Using max model len 40960
INFO 12-04 14:09:52 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:09:52 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:09:52 [model.py:1745] Using max model len 40960
INFO 12-04 14:09:52 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2186581)[0;0m INFO 12-04 14:11:10 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2186580)[0;0m INFO 12-04 14:11:10 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2186580)[0;0m INFO 12-04 14:11:16 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:59583 backend=nccl
[1;36m(EngineCore_DP0 pid=2186581)[0;0m INFO 12-04 14:11:16 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:42829 backend=nccl
[W1204 14:11:16.460584077 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:59583 (errno: 97 - Address family not supported by protocol).
[W1204 14:11:16.463548892 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:42829 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2186580)[0;0m INFO 12-04 14:11:16 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2186581)[0;0m INFO 12-04 14:11:16 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2186580)[0;0m INFO 12-04 14:11:16 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2186581)[0;0m INFO 12-04 14:11:16 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2186580)[0;0m INFO 12-04 14:11:18 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2186580)[0;0m INFO 12-04 14:11:18 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2186581)[0;0m INFO 12-04 14:11:18 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2186581)[0;0m INFO 12-04 14:11:18 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m ERROR 12-04 14:11:19 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2186580 has 22.50 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2186581)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2186581)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2186581)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2186581)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186581)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2186580 has 22.50 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m ERROR 12-04 14:11:19 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2186581 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2186580)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2186580)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2186580)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2186580)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2186580)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2186581 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:11:19.280832056 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:11:19.280992864 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:11:41 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:11:41 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:11:41 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:11:41 [model.py:1745] Using max model len 40960
INFO 12-04 14:11:41 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:11:41 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:11:41 [model.py:1745] Using max model len 40960
INFO 12-04 14:11:41 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2188818)[0;0m INFO 12-04 14:12:33 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2188815)[0;0m INFO 12-04 14:12:33 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2188815)[0;0m INFO 12-04 14:12:37 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:57763 backend=nccl
[1;36m(EngineCore_DP0 pid=2188818)[0;0m INFO 12-04 14:12:37 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:34913 backend=nccl
[W1204 14:12:37.292980610 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:57763 (errno: 97 - Address family not supported by protocol).
[W1204 14:12:37.293496943 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:34913 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2188818)[0;0m INFO 12-04 14:12:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2188815)[0;0m INFO 12-04 14:12:38 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2188818)[0;0m INFO 12-04 14:12:38 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2188815)[0;0m INFO 12-04 14:12:38 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2188818)[0;0m INFO 12-04 14:12:40 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2188818)[0;0m INFO 12-04 14:12:40 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2188815)[0;0m INFO 12-04 14:12:40 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2188815)[0;0m INFO 12-04 14:12:40 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m ERROR 12-04 14:12:41 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2188815 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2188818)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2188818)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2188818)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2188818)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188818)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2188815 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m ERROR 12-04 14:12:41 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2188818 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2188815)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2188815)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2188815)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2188815)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2188815)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2188818 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:12:41.059520536 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:12:41.078054888 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:13:02 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:13:02 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:13:03 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:13:03 [model.py:1745] Using max model len 40960
INFO 12-04 14:13:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:13:03 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:13:03 [model.py:1745] Using max model len 40960
INFO 12-04 14:13:03 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2190126)[0;0m INFO 12-04 14:14:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2190129)[0;0m INFO 12-04 14:14:12 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2190129)[0;0m INFO 12-04 14:14:16 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:55519 backend=nccl
[1;36m(EngineCore_DP0 pid=2190126)[0;0m INFO 12-04 14:14:16 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:36665 backend=nccl
[W1204 14:14:16.319761491 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:55519 (errno: 97 - Address family not supported by protocol).
[W1204 14:14:16.322667025 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:36665 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2190129)[0;0m INFO 12-04 14:14:17 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2190126)[0;0m INFO 12-04 14:14:17 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2190129)[0;0m INFO 12-04 14:14:17 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2190126)[0;0m INFO 12-04 14:14:17 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2190126)[0;0m INFO 12-04 14:14:19 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2190126)[0;0m INFO 12-04 14:14:19 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2190129)[0;0m INFO 12-04 14:14:19 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2190129)[0;0m INFO 12-04 14:14:19 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m ERROR 12-04 14:14:19 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2190129 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2190126)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2190126)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2190126)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2190126)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190126)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2190129 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m ERROR 12-04 14:14:19 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2190126 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2190129)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2190129)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2190129)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2190129)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2190129)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2190126 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:14:20.894958569 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:14:20.928975731 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:14:41 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:14:41 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:14:41 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:14:41 [model.py:1745] Using max model len 40960
INFO 12-04 14:14:41 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:14:41 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:14:41 [model.py:1745] Using max model len 40960
INFO 12-04 14:14:41 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2192033)[0;0m INFO 12-04 14:15:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2192036)[0;0m INFO 12-04 14:15:27 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2192033)[0;0m INFO 12-04 14:15:31 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:51651 backend=nccl
[1;36m(EngineCore_DP0 pid=2192036)[0;0m INFO 12-04 14:15:31 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:35029 backend=nccl
[W1204 14:15:31.567089484 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:35029 (errno: 97 - Address family not supported by protocol).
[W1204 14:15:31.567047685 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:51651 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2192036)[0;0m INFO 12-04 14:15:31 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2192033)[0;0m INFO 12-04 14:15:31 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2192036)[0;0m INFO 12-04 14:15:31 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2192033)[0;0m INFO 12-04 14:15:31 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2192033)[0;0m INFO 12-04 14:15:33 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2192033)[0;0m INFO 12-04 14:15:33 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2192036)[0;0m INFO 12-04 14:15:33 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2192036)[0;0m INFO 12-04 14:15:33 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m ERROR 12-04 14:15:34 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2192036 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2192033)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2192033)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2192033)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2192033)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192033)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2192036 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m ERROR 12-04 14:15:34 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2192033 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2192036)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2192036)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2192036)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2192036)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2192036)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2192033 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:15:34.034391193 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:15:34.036699559 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:15:55 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:15:55 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:15:56 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:15:56 [model.py:1745] Using max model len 40960
INFO 12-04 14:15:56 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:15:56 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:15:56 [model.py:1745] Using max model len 40960
INFO 12-04 14:15:56 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2198856)[0;0m INFO 12-04 14:16:28 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2198835)[0;0m INFO 12-04 14:16:28 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2198856)[0;0m INFO 12-04 14:16:33 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:54545 backend=nccl
[1;36m(EngineCore_DP0 pid=2198835)[0;0m INFO 12-04 14:16:33 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:58899 backend=nccl
[W1204 14:16:33.436600364 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:54545 (errno: 97 - Address family not supported by protocol).
[W1204 14:16:33.436673830 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:58899 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2198835)[0;0m INFO 12-04 14:16:33 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2198856)[0;0m INFO 12-04 14:16:33 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2198856)[0;0m INFO 12-04 14:16:33 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2198835)[0;0m INFO 12-04 14:16:33 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2198835)[0;0m INFO 12-04 14:16:34 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2198835)[0;0m INFO 12-04 14:16:34 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2198856)[0;0m INFO 12-04 14:16:34 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2198856)[0;0m INFO 12-04 14:16:34 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m ERROR 12-04 14:16:35 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2198835 has 22.50 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m ERROR 12-04 14:16:35 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2198856 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2198835)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2198835)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2198856)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2198856)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2198856)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2198856)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198856)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2198835 has 22.50 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2198835)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2198835)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2198835)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2198835)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2198856 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:16:36.646152009 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:16:36.646270118 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:16:57 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:16:57 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:16:57 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:16:57 [model.py:1745] Using max model len 40960
INFO 12-04 14:16:57 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:16:57 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:16:57 [model.py:1745] Using max model len 40960
INFO 12-04 14:16:57 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2202875)[0;0m INFO 12-04 14:17:29 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2202878)[0;0m INFO 12-04 14:17:29 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2202878)[0;0m INFO 12-04 14:17:32 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:58439 backend=nccl
[1;36m(EngineCore_DP0 pid=2202875)[0;0m INFO 12-04 14:17:32 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:49039 backend=nccl
[W1204 14:17:32.080971105 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:58439 (errno: 97 - Address family not supported by protocol).
[W1204 14:17:32.082904001 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:49039 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2202875)[0;0m INFO 12-04 14:17:32 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2202878)[0;0m INFO 12-04 14:17:32 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2202875)[0;0m INFO 12-04 14:17:33 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2202878)[0;0m INFO 12-04 14:17:33 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2202875)[0;0m INFO 12-04 14:17:34 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2202875)[0;0m INFO 12-04 14:17:34 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2202878)[0;0m INFO 12-04 14:17:34 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2202878)[0;0m INFO 12-04 14:17:34 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m ERROR 12-04 14:17:35 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2202875 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2202878)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2202878)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2202878)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2202878)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202878)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2202875 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m ERROR 12-04 14:17:35 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2202878 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2202875)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2202875)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2202875)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2202875)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2202875)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2202878 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:17:35.190718757 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:17:35.199657756 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:17:56 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:17:57 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:17:57 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:17:57 [model.py:1745] Using max model len 40960
INFO 12-04 14:17:57 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:17:57 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:17:57 [model.py:1745] Using max model len 40960
INFO 12-04 14:17:57 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2203993)[0;0m INFO 12-04 14:18:18 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2203990)[0;0m INFO 12-04 14:18:18 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2203993)[0;0m INFO 12-04 14:18:20 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:57283 backend=nccl
[1;36m(EngineCore_DP0 pid=2203990)[0;0m INFO 12-04 14:18:20 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:60061 backend=nccl
[W1204 14:18:20.685608646 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:57283 (errno: 97 - Address family not supported by protocol).
[W1204 14:18:20.686360764 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:60061 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2203993)[0;0m INFO 12-04 14:18:20 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2203990)[0;0m INFO 12-04 14:18:20 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2203990)[0;0m INFO 12-04 14:18:20 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2203993)[0;0m INFO 12-04 14:18:20 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2203990)[0;0m INFO 12-04 14:18:21 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2203990)[0;0m INFO 12-04 14:18:21 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2203993)[0;0m INFO 12-04 14:18:21 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2203993)[0;0m INFO 12-04 14:18:21 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m ERROR 12-04 14:18:22 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2203990 has 23.12 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2203993)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2203993)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2203993)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2203993)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203993)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2203990 has 23.12 GiB memory in use. Including non-PyTorch memory, this process has 21.25 GiB memory in use. Of the allocated memory 20.73 GiB is allocated by PyTorch, and 18.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m ERROR 12-04 14:18:22 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 2203993 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2203990)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2203990)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2203990)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2203990)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2203990)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 23.10 GiB memory in use. Process 2203993 has 21.25 GiB memory in use. Of the allocated memory 22.58 GiB is allocated by PyTorch, and 18.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:18:23.734628315 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:18:23.756102678 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:18:44 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:18:44 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:18:44 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:18:44 [model.py:1745] Using max model len 40960
INFO 12-04 14:18:44 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:18:44 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:18:44 [model.py:1745] Using max model len 40960
INFO 12-04 14:18:44 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2204563)[0;0m INFO 12-04 14:19:17 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2204566)[0;0m INFO 12-04 14:19:17 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2204566)[0;0m INFO 12-04 14:19:22 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:38813 backend=nccl
[1;36m(EngineCore_DP0 pid=2204563)[0;0m INFO 12-04 14:19:22 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:39301 backend=nccl
[W1204 14:19:22.388864929 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:38813 (errno: 97 - Address family not supported by protocol).
[W1204 14:19:22.389354110 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:39301 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2204566)[0;0m INFO 12-04 14:19:22 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2204563)[0;0m INFO 12-04 14:19:22 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2204566)[0;0m INFO 12-04 14:19:22 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2204563)[0;0m INFO 12-04 14:19:22 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2204563)[0;0m INFO 12-04 14:19:23 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2204563)[0;0m INFO 12-04 14:19:23 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2204566)[0;0m INFO 12-04 14:19:23 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2204566)[0;0m INFO 12-04 14:19:23 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m ERROR 12-04 14:19:24 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2204566 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2204563)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2204563)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2204563)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2204563)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204563)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2204566 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m ERROR 12-04 14:19:24 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2204563 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2204566)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2204566)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2204566)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2204566)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2204566)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2204563 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:19:25.778101275 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:19:25.778101210 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:19:46 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:19:46 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:19:46 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:19:46 [model.py:1745] Using max model len 40960
INFO 12-04 14:19:46 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:19:46 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:19:46 [model.py:1745] Using max model len 40960
INFO 12-04 14:19:46 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2205923)[0;0m INFO 12-04 14:20:24 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2205927)[0;0m INFO 12-04 14:20:24 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2205927)[0;0m INFO 12-04 14:20:28 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:57411 backend=nccl
[1;36m(EngineCore_DP0 pid=2205923)[0;0m INFO 12-04 14:20:28 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:52731 backend=nccl
[W1204 14:20:28.387633510 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:57411 (errno: 97 - Address family not supported by protocol).
[W1204 14:20:28.393203718 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:52731 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2205927)[0;0m INFO 12-04 14:20:28 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2205923)[0;0m INFO 12-04 14:20:28 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2205923)[0;0m INFO 12-04 14:20:28 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2205927)[0;0m INFO 12-04 14:20:28 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2205927)[0;0m INFO 12-04 14:20:30 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2205927)[0;0m INFO 12-04 14:20:30 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2205923)[0;0m INFO 12-04 14:20:30 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2205923)[0;0m INFO 12-04 14:20:30 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m ERROR 12-04 14:20:30 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2205927 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2205923)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2205923)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2205923)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2205923)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205923)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2205927 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m ERROR 12-04 14:20:30 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2205923 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2205927)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2205927)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2205927)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2205927)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2205927)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2205923 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:20:31.835669130 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:20:31.836711396 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:20:52 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:20:52 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:20:52 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:20:52 [model.py:1745] Using max model len 40960
INFO 12-04 14:20:52 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:20:52 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:20:52 [model.py:1745] Using max model len 40960
INFO 12-04 14:20:52 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2207147)[0;0m INFO 12-04 14:21:28 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2207148)[0;0m INFO 12-04 14:21:28 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2207148)[0;0m INFO 12-04 14:21:31 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:39985 backend=nccl
[1;36m(EngineCore_DP0 pid=2207147)[0;0m INFO 12-04 14:21:31 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:40785 backend=nccl
[W1204 14:21:31.873916334 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:39985 (errno: 97 - Address family not supported by protocol).
[W1204 14:21:31.876218685 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:40785 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2207147)[0;0m INFO 12-04 14:21:31 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2207148)[0;0m INFO 12-04 14:21:31 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2207148)[0;0m INFO 12-04 14:21:32 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2207147)[0;0m INFO 12-04 14:21:32 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2207148)[0;0m INFO 12-04 14:21:33 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2207148)[0;0m INFO 12-04 14:21:33 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2207147)[0;0m INFO 12-04 14:21:33 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2207147)[0;0m INFO 12-04 14:21:33 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m ERROR 12-04 14:21:34 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2207148 has 22.50 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2207147)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2207147)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2207147)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2207147)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207147)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2207148 has 22.50 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m ERROR 12-04 14:21:34 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2207147 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2207148)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2207148)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2207148)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2207148)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2207148)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2207147 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:21:34.112700648 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:21:34.112678211 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:21:55 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:21:55 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:21:56 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:21:56 [model.py:1745] Using max model len 40960
INFO 12-04 14:21:56 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:21:56 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:21:56 [model.py:1745] Using max model len 40960
INFO 12-04 14:21:56 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2208395)[0;0m INFO 12-04 14:22:30 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2208398)[0;0m INFO 12-04 14:22:30 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2208398)[0;0m INFO 12-04 14:22:33 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:37173 backend=nccl
[1;36m(EngineCore_DP0 pid=2208395)[0;0m INFO 12-04 14:22:33 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:51711 backend=nccl
[W1204 14:22:33.655043925 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:51711 (errno: 97 - Address family not supported by protocol).
[W1204 14:22:33.655043989 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:37173 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2208398)[0;0m INFO 12-04 14:22:33 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2208395)[0;0m INFO 12-04 14:22:33 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2208398)[0;0m INFO 12-04 14:22:33 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2208395)[0;0m INFO 12-04 14:22:33 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2208395)[0;0m INFO 12-04 14:22:35 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2208395)[0;0m INFO 12-04 14:22:35 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2208398)[0;0m INFO 12-04 14:22:35 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2208398)[0;0m INFO 12-04 14:22:35 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m ERROR 12-04 14:22:36 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2208395 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2208398)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2208398)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2208398)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2208398)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208398)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2208395 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m ERROR 12-04 14:22:36 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2208398 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2208395)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2208395)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2208395)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2208395)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2208395)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2208398 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:22:36.020455954 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:22:36.030282263 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:22:57 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:22:57 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:22:57 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:22:57 [model.py:1745] Using max model len 40960
INFO 12-04 14:22:57 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:22:58 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:22:58 [model.py:1745] Using max model len 40960
INFO 12-04 14:22:58 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2209468)[0;0m INFO 12-04 14:23:23 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2209465)[0;0m INFO 12-04 14:23:23 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2209468)[0;0m INFO 12-04 14:23:25 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:52191 backend=nccl
[1;36m(EngineCore_DP0 pid=2209465)[0;0m INFO 12-04 14:23:25 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:43703 backend=nccl
[W1204 14:23:25.012959388 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:52191 (errno: 97 - Address family not supported by protocol).
[W1204 14:23:25.015327141 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:43703 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2209468)[0;0m INFO 12-04 14:23:25 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2209465)[0;0m INFO 12-04 14:23:25 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2209468)[0;0m INFO 12-04 14:23:26 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2209465)[0;0m INFO 12-04 14:23:26 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2209468)[0;0m INFO 12-04 14:23:27 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2209468)[0;0m INFO 12-04 14:23:27 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2209465)[0;0m INFO 12-04 14:23:27 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2209465)[0;0m INFO 12-04 14:23:27 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m ERROR 12-04 14:23:27 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2209465 has 21.89 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m ERROR 12-04 14:23:28 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2209468 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2209468)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2209468)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2209468)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2209468)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209468)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2209465 has 21.89 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2209465)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2209465)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2209465)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2209465)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2209465)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2209468 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:23:28.100922009 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:23:28.106904398 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:23:49 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:23:49 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:23:50 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:23:50 [model.py:1745] Using max model len 40960
INFO 12-04 14:23:50 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:23:50 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:23:50 [model.py:1745] Using max model len 40960
INFO 12-04 14:23:50 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2210372)[0;0m INFO 12-04 14:24:18 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2210369)[0;0m INFO 12-04 14:24:18 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2210369)[0;0m INFO 12-04 14:24:21 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:36433 backend=nccl
[1;36m(EngineCore_DP0 pid=2210372)[0;0m INFO 12-04 14:24:21 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:57803 backend=nccl
[W1204 14:24:21.892358317 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:36433 (errno: 97 - Address family not supported by protocol).
[W1204 14:24:21.899439974 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:57803 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2210369)[0;0m INFO 12-04 14:24:21 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2210372)[0;0m INFO 12-04 14:24:21 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2210369)[0;0m INFO 12-04 14:24:22 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2210372)[0;0m INFO 12-04 14:24:22 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2210372)[0;0m INFO 12-04 14:24:23 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2210372)[0;0m INFO 12-04 14:24:23 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2210369)[0;0m INFO 12-04 14:24:23 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2210369)[0;0m INFO 12-04 14:24:23 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m ERROR 12-04 14:24:24 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2210369 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2210372)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2210372)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2210372)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2210372)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210372)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2210369 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m ERROR 12-04 14:24:24 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2210372 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2210369)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2210369)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2210369)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2210369)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2210369)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2210372 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:24:24.265774370 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:24:24.265756539 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:24:46 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:24:46 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:24:46 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:24:46 [model.py:1745] Using max model len 40960
INFO 12-04 14:24:46 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:24:46 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:24:46 [model.py:1745] Using max model len 40960
INFO 12-04 14:24:46 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2211413)[0;0m INFO 12-04 14:25:14 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2211410)[0;0m INFO 12-04 14:25:14 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2211413)[0;0m INFO 12-04 14:25:16 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:38235 backend=nccl
[1;36m(EngineCore_DP0 pid=2211410)[0;0m INFO 12-04 14:25:16 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:53521 backend=nccl
[W1204 14:25:16.710225377 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:53521 (errno: 97 - Address family not supported by protocol).
[W1204 14:25:16.710225395 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:38235 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2211410)[0;0m INFO 12-04 14:25:16 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2211413)[0;0m INFO 12-04 14:25:16 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2211410)[0;0m INFO 12-04 14:25:16 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2211413)[0;0m INFO 12-04 14:25:16 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2211410)[0;0m INFO 12-04 14:25:17 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2211410)[0;0m INFO 12-04 14:25:17 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2211413)[0;0m INFO 12-04 14:25:17 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2211413)[0;0m INFO 12-04 14:25:17 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m ERROR 12-04 14:25:18 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2211410 has 25.59 GiB memory in use. Including non-PyTorch memory, this process has 18.79 GiB memory in use. Of the allocated memory 18.27 GiB is allocated by PyTorch, and 18.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2211413)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2211413)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2211413)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2211413)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211413)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2211410 has 25.59 GiB memory in use. Including non-PyTorch memory, this process has 18.79 GiB memory in use. Of the allocated memory 18.27 GiB is allocated by PyTorch, and 18.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m ERROR 12-04 14:25:18 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 25.56 GiB memory in use. Process 2211413 has 18.79 GiB memory in use. Of the allocated memory 25.04 GiB is allocated by PyTorch, and 18.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2211410)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2211410)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2211410)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2211410)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2211410)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 25.56 GiB memory in use. Process 2211413 has 18.79 GiB memory in use. Of the allocated memory 25.04 GiB is allocated by PyTorch, and 18.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:25:19.741647066 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:25:19.806237950 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:25:40 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:25:40 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:25:40 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:25:40 [model.py:1745] Using max model len 40960
INFO 12-04 14:25:40 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:25:40 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:25:40 [model.py:1745] Using max model len 40960
INFO 12-04 14:25:40 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2212196)[0;0m INFO 12-04 14:26:06 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2212199)[0;0m INFO 12-04 14:26:06 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2212199)[0;0m INFO 12-04 14:26:10 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:49611 backend=nccl
[1;36m(EngineCore_DP0 pid=2212196)[0;0m INFO 12-04 14:26:10 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:58697 backend=nccl
[W1204 14:26:10.916284672 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:49611 (errno: 97 - Address family not supported by protocol).
[W1204 14:26:10.916733886 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:58697 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2212199)[0;0m INFO 12-04 14:26:10 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2212196)[0;0m INFO 12-04 14:26:10 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2212196)[0;0m INFO 12-04 14:26:11 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2212199)[0;0m INFO 12-04 14:26:11 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2212199)[0;0m INFO 12-04 14:26:12 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2212199)[0;0m INFO 12-04 14:26:12 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2212196)[0;0m INFO 12-04 14:26:12 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2212196)[0;0m INFO 12-04 14:26:12 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m ERROR 12-04 14:26:13 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2212199 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2212196)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2212196)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2212196)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2212196)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212196)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2212199 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m ERROR 12-04 14:26:13 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2212196 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2212199)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2212199)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2212199)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2212199)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2212199)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2212196 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:26:14.827929339 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:26:14.827929240 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:26:35 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:26:35 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:26:35 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:26:35 [model.py:1745] Using max model len 40960
INFO 12-04 14:26:35 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:26:35 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:26:35 [model.py:1745] Using max model len 40960
INFO 12-04 14:26:35 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2213343)[0;0m INFO 12-04 14:27:06 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2213344)[0;0m INFO 12-04 14:27:06 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2213343)[0;0m INFO 12-04 14:27:08 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:46539 backend=nccl
[1;36m(EngineCore_DP0 pid=2213344)[0;0m INFO 12-04 14:27:08 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:58611 backend=nccl
[W1204 14:27:08.553777658 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:46539 (errno: 97 - Address family not supported by protocol).
[W1204 14:27:08.555309863 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:58611 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2213343)[0;0m INFO 12-04 14:27:08 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2213344)[0;0m INFO 12-04 14:27:08 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2213344)[0;0m INFO 12-04 14:27:08 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2213343)[0;0m INFO 12-04 14:27:08 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2213343)[0;0m INFO 12-04 14:27:09 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2213343)[0;0m INFO 12-04 14:27:09 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2213344)[0;0m INFO 12-04 14:27:09 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2213344)[0;0m INFO 12-04 14:27:09 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m ERROR 12-04 14:27:10 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2213344 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2213343)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2213343)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2213343)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2213343)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213343)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2213344 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m ERROR 12-04 14:27:10 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2213343 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2213344)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2213344)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2213344)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2213344)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2213344)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2213343 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:27:11.811754076 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:27:11.815476720 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:27:32 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:27:32 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:27:32 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:27:32 [model.py:1745] Using max model len 40960
INFO 12-04 14:27:32 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:27:32 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:27:32 [model.py:1745] Using max model len 40960
INFO 12-04 14:27:32 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2214740)[0;0m INFO 12-04 14:27:55 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2214737)[0;0m INFO 12-04 14:27:55 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2214737)[0;0m INFO 12-04 14:27:57 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:41077 backend=nccl
[1;36m(EngineCore_DP0 pid=2214740)[0;0m INFO 12-04 14:27:57 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:55883 backend=nccl
[W1204 14:27:57.575972634 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:55883 (errno: 97 - Address family not supported by protocol).
[W1204 14:27:57.576091215 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:41077 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2214737)[0;0m INFO 12-04 14:27:57 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2214740)[0;0m INFO 12-04 14:27:57 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2214737)[0;0m INFO 12-04 14:27:57 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2214740)[0;0m INFO 12-04 14:27:57 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2214737)[0;0m INFO 12-04 14:27:58 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2214737)[0;0m INFO 12-04 14:27:58 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2214740)[0;0m INFO 12-04 14:27:58 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2214740)[0;0m INFO 12-04 14:27:58 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m ERROR 12-04 14:27:59 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 2214737 has 23.71 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2214740)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2214740)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2214740)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2214740)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214740)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Process 2214737 has 23.71 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m ERROR 12-04 14:27:59 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2214740 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2214737)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2214737)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2214737)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2214737)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2214737)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2214740 has 20.63 GiB memory in use. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:28:00.671501924 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:28:00.701094981 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:28:21 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:28:21 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:28:21 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:28:21 [model.py:1745] Using max model len 40960
INFO 12-04 14:28:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:28:21 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:28:21 [model.py:1745] Using max model len 40960
INFO 12-04 14:28:21 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2215716)[0;0m INFO 12-04 14:28:48 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2215713)[0;0m INFO 12-04 14:28:48 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2215716)[0;0m INFO 12-04 14:28:51 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:46219 backend=nccl
[1;36m(EngineCore_DP0 pid=2215713)[0;0m INFO 12-04 14:28:51 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:33947 backend=nccl
[W1204 14:28:51.749501077 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:46219 (errno: 97 - Address family not supported by protocol).
[W1204 14:28:51.751359239 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:33947 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2215713)[0;0m INFO 12-04 14:28:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2215716)[0;0m INFO 12-04 14:28:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2215713)[0;0m INFO 12-04 14:28:51 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2215716)[0;0m INFO 12-04 14:28:51 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2215713)[0;0m INFO 12-04 14:28:52 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2215713)[0;0m INFO 12-04 14:28:52 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2215716)[0;0m INFO 12-04 14:28:52 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2215716)[0;0m INFO 12-04 14:28:52 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m ERROR 12-04 14:28:53 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2215713 has 23.71 GiB memory in use. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2215716)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2215716)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2215716)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2215716)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215716)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2215713 has 23.71 GiB memory in use. Including non-PyTorch memory, this process has 20.63 GiB memory in use. Of the allocated memory 20.11 GiB is allocated by PyTorch, and 18.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m ERROR 12-04 14:28:53 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Process 2215716 has 20.61 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2215713)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2215713)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2215713)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2215713)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2215713)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Including non-PyTorch memory, this process has 23.71 GiB memory in use. Process 2215716 has 20.61 GiB memory in use. Of the allocated memory 23.19 GiB is allocated by PyTorch, and 18.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:28:54.907332530 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:28:54.922030892 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:29:15 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:29:15 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:29:15 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:29:15 [model.py:1745] Using max model len 40960
INFO 12-04 14:29:15 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:29:15 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:29:15 [model.py:1745] Using max model len 40960
INFO 12-04 14:29:15 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2216962)[0;0m INFO 12-04 14:29:40 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2216959)[0;0m INFO 12-04 14:29:40 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2216962)[0;0m INFO 12-04 14:29:43 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:33281 backend=nccl
[1;36m(EngineCore_DP0 pid=2216959)[0;0m INFO 12-04 14:29:43 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:50501 backend=nccl
[W1204 14:29:43.719310581 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:33281 (errno: 97 - Address family not supported by protocol).
[W1204 14:29:43.720730676 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:50501 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2216962)[0;0m INFO 12-04 14:29:43 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2216959)[0;0m INFO 12-04 14:29:43 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2216962)[0;0m INFO 12-04 14:29:43 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2216959)[0;0m INFO 12-04 14:29:43 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2216959)[0;0m INFO 12-04 14:29:45 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2216959)[0;0m INFO 12-04 14:29:45 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2216962)[0;0m INFO 12-04 14:29:45 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2216962)[0;0m INFO 12-04 14:29:45 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m ERROR 12-04 14:29:45 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Process 2216962 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2216959)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2216959)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2216959)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2216959)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216959)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 64.00 MiB is free. Process 2216962 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m ERROR 12-04 14:29:45 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2216959 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2216962)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2216962)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2216962)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2216962)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2216962)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2216959 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:29:46.866699154 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:29:46.897670749 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:30:07 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:30:07 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:30:07 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:30:07 [model.py:1745] Using max model len 40960
INFO 12-04 14:30:07 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:30:07 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:30:07 [model.py:1745] Using max model len 40960
INFO 12-04 14:30:07 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2218188)[0;0m INFO 12-04 14:30:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2218182)[0;0m INFO 12-04 14:30:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2218188)[0;0m INFO 12-04 14:30:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:55941 backend=nccl
[1;36m(EngineCore_DP0 pid=2218182)[0;0m INFO 12-04 14:30:53 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:59361 backend=nccl
[W1204 14:30:53.969975861 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:55941 (errno: 97 - Address family not supported by protocol).
[W1204 14:30:53.972742540 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:59361 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2218188)[0;0m INFO 12-04 14:30:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2218182)[0;0m INFO 12-04 14:30:53 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2218188)[0;0m INFO 12-04 14:30:54 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2218182)[0;0m INFO 12-04 14:30:54 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2218182)[0;0m INFO 12-04 14:30:55 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2218182)[0;0m INFO 12-04 14:30:55 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2218188)[0;0m INFO 12-04 14:30:55 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2218188)[0;0m INFO 12-04 14:30:55 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m ERROR 12-04 14:30:56 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Process 2218182 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2218188)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2218188)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2218188)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2218188)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218188)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 124.00 MiB is free. Process 2218182 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m ERROR 12-04 14:30:56 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2218188 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2218182)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2218182)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2218182)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2218182)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2218182)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2218188 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:30:56.193673250 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:30:56.194667583 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:31:18 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:31:18 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:31:18 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:31:18 [model.py:1745] Using max model len 40960
INFO 12-04 14:31:18 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:31:18 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:31:18 [model.py:1745] Using max model len 40960
INFO 12-04 14:31:18 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2219662)[0;0m INFO 12-04 14:31:58 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2219659)[0;0m INFO 12-04 14:31:58 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2219662)[0;0m INFO 12-04 14:32:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:39865 backend=nccl
[1;36m(EngineCore_DP0 pid=2219659)[0;0m INFO 12-04 14:32:02 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:41325 backend=nccl
[W1204 14:32:02.501667724 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:39865 (errno: 97 - Address family not supported by protocol).
[W1204 14:32:02.503746062 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:41325 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2219662)[0;0m INFO 12-04 14:32:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2219659)[0;0m INFO 12-04 14:32:02 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2219662)[0;0m INFO 12-04 14:32:02 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2219659)[0;0m INFO 12-04 14:32:02 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2219662)[0;0m INFO 12-04 14:32:03 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2219662)[0;0m INFO 12-04 14:32:03 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2219659)[0;0m INFO 12-04 14:32:03 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2219659)[0;0m INFO 12-04 14:32:03 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m ERROR 12-04 14:32:04 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2219662 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2219659)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2219659)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2219659)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2219659)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219659)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2219662 has 22.51 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m ERROR 12-04 14:32:04 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2219659 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2219662)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2219662)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2219662)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2219662)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2219662)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2219659 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:32:05.810863580 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:32:05.810992623 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:32:26 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:32:26 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:32:26 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:32:26 [model.py:1745] Using max model len 40960
INFO 12-04 14:32:26 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:32:26 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:32:26 [model.py:1745] Using max model len 40960
INFO 12-04 14:32:26 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2221756)[0;0m INFO 12-04 14:33:02 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2221753)[0;0m INFO 12-04 14:33:02 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2221756)[0;0m INFO 12-04 14:33:05 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:38249 backend=nccl
[1;36m(EngineCore_DP0 pid=2221753)[0;0m INFO 12-04 14:33:05 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:37549 backend=nccl
[W1204 14:33:05.969558979 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:38249 (errno: 97 - Address family not supported by protocol).
[W1204 14:33:05.970556092 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:37549 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2221756)[0;0m INFO 12-04 14:33:05 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2221753)[0;0m INFO 12-04 14:33:05 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2221756)[0;0m INFO 12-04 14:33:06 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2221753)[0;0m INFO 12-04 14:33:06 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2221753)[0;0m INFO 12-04 14:33:07 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2221753)[0;0m INFO 12-04 14:33:07 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2221756)[0;0m INFO 12-04 14:33:07 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2221756)[0;0m INFO 12-04 14:33:07 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m ERROR 12-04 14:33:08 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2221753 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2221756)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2221756)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2221756)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2221756)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221756)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2221753 has 22.48 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m ERROR 12-04 14:33:08 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2221756 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2221753)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2221753)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2221753)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2221753)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2221753)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2221756 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:33:08.311792296 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:33:08.326865822 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:33:30 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:33:30 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:33:30 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:33:30 [model.py:1745] Using max model len 40960
INFO 12-04 14:33:30 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:33:30 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:33:30 [model.py:1745] Using max model len 40960
INFO 12-04 14:33:30 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2223291)[0;0m INFO 12-04 14:33:57 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2223288)[0;0m INFO 12-04 14:33:57 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2223288)[0;0m INFO 12-04 14:33:59 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:44501 backend=nccl
[1;36m(EngineCore_DP0 pid=2223291)[0;0m INFO 12-04 14:33:59 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:34231 backend=nccl
[W1204 14:33:59.884973928 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:34231 (errno: 97 - Address family not supported by protocol).
[W1204 14:33:59.884973964 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:44501 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2223291)[0;0m INFO 12-04 14:33:59 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2223288)[0;0m INFO 12-04 14:33:59 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2223291)[0;0m INFO 12-04 14:34:00 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2223288)[0;0m INFO 12-04 14:34:00 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2223291)[0;0m INFO 12-04 14:34:00 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2223291)[0;0m INFO 12-04 14:34:00 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2223288)[0;0m INFO 12-04 14:34:00 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2223288)[0;0m INFO 12-04 14:34:00 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m ERROR 12-04 14:34:01 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Process 2223291 has 24.94 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2223288)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2223288)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2223288)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2223288)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223288)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Process 2223291 has 24.94 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 18.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m ERROR 12-04 14:34:01 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2223288 has 19.43 GiB memory in use. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2223291)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2223291)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2223291)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2223291)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2223291)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Process 2223288 has 19.43 GiB memory in use. Including non-PyTorch memory, this process has 24.94 GiB memory in use. Of the allocated memory 24.42 GiB is allocated by PyTorch, and 18.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:34:02.887961701 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:34:02.924442663 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:34:23 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:34:23 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:34:23 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:34:23 [model.py:1745] Using max model len 40960
INFO 12-04 14:34:23 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:34:24 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:34:24 [model.py:1745] Using max model len 40960
INFO 12-04 14:34:24 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2224493)[0;0m INFO 12-04 14:34:54 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2224490)[0;0m INFO 12-04 14:34:54 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2224493)[0;0m INFO 12-04 14:34:57 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:39369 backend=nccl
[1;36m(EngineCore_DP0 pid=2224490)[0;0m INFO 12-04 14:34:57 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:45131 backend=nccl
[W1204 14:34:57.904934066 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:39369 (errno: 97 - Address family not supported by protocol).
[W1204 14:34:57.904860864 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:45131 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2224490)[0;0m INFO 12-04 14:34:57 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2224493)[0;0m INFO 12-04 14:34:57 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2224490)[0;0m INFO 12-04 14:34:58 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2224493)[0;0m INFO 12-04 14:34:58 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2224493)[0;0m INFO 12-04 14:34:59 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2224493)[0;0m INFO 12-04 14:34:59 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2224490)[0;0m INFO 12-04 14:34:59 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2224490)[0;0m INFO 12-04 14:34:59 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m ERROR 12-04 14:35:00 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2224490 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2224493)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2224493)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2224493)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2224493)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224493)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2224490 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m ERROR 12-04 14:35:00 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2224493 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2224490)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2224490)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2224490)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2224490)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2224490)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2224493 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:35:00.201292190 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:35:00.212816495 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:35:21 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:35:22 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:35:22 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:35:22 [model.py:1745] Using max model len 40960
INFO 12-04 14:35:22 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:35:22 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:35:22 [model.py:1745] Using max model len 40960
INFO 12-04 14:35:22 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2225862)[0;0m INFO 12-04 14:36:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2225859)[0;0m INFO 12-04 14:36:04 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2225859)[0;0m INFO 12-04 14:36:07 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:39257 backend=nccl
[1;36m(EngineCore_DP0 pid=2225862)[0;0m INFO 12-04 14:36:07 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:51389 backend=nccl
[W1204 14:36:07.860264134 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:51389 (errno: 97 - Address family not supported by protocol).
[W1204 14:36:07.860265555 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:39257 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2225862)[0;0m INFO 12-04 14:36:07 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2225859)[0;0m INFO 12-04 14:36:07 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2225862)[0;0m INFO 12-04 14:36:08 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2225859)[0;0m INFO 12-04 14:36:08 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2225862)[0;0m INFO 12-04 14:36:09 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2225862)[0;0m INFO 12-04 14:36:09 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2225859)[0;0m INFO 12-04 14:36:09 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2225859)[0;0m INFO 12-04 14:36:09 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m ERROR 12-04 14:36:10 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2225862 has 22.50 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2225859)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2225859)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2225859)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2225859)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225859)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Process 2225862 has 22.50 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m ERROR 12-04 14:36:10 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2225859 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2225862)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2225862)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2225862)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2225862)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2225862)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2225859 has 21.87 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:36:10.042145202 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:36:10.042064861 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:36:31 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:36:31 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:36:32 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:36:32 [model.py:1745] Using max model len 40960
INFO 12-04 14:36:32 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:36:32 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:36:32 [model.py:1745] Using max model len 40960
INFO 12-04 14:36:32 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2227300)[0;0m INFO 12-04 14:36:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2227297)[0;0m INFO 12-04 14:36:59 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2227297)[0;0m INFO 12-04 14:37:01 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:43409 backend=nccl
[1;36m(EngineCore_DP0 pid=2227300)[0;0m INFO 12-04 14:37:01 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:48443 backend=nccl
[W1204 14:37:01.866401982 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:43409 (errno: 97 - Address family not supported by protocol).
[W1204 14:37:01.868443366 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:48443 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2227297)[0;0m INFO 12-04 14:37:01 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2227300)[0;0m INFO 12-04 14:37:01 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2227297)[0;0m INFO 12-04 14:37:02 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2227300)[0;0m INFO 12-04 14:37:02 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2227300)[0;0m INFO 12-04 14:37:02 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2227300)[0;0m INFO 12-04 14:37:02 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2227297)[0;0m INFO 12-04 14:37:02 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2227297)[0;0m INFO 12-04 14:37:02 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m ERROR 12-04 14:37:03 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2227300 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2227297)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2227297)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2227297)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2227297)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227297)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2227300 has 22.48 GiB memory in use. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m ERROR 12-04 14:37:03 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2227297 has 21.88 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2227300)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2227300)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2227300)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2227300)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2227300)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 4.00 MiB is free. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Process 2227297 has 21.88 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:37:04.875328406 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:37:04.876426808 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:37:25 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:37:25 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:37:25 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:37:25 [model.py:1745] Using max model len 40960
INFO 12-04 14:37:25 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:37:25 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:37:25 [model.py:1745] Using max model len 40960
INFO 12-04 14:37:25 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(EngineCore_DP0 pid=2228376)[0;0m INFO 12-04 14:37:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2228379)[0;0m INFO 12-04 14:37:49 [core.py:93] Initializing a V1 LLM engine (v0.11.2) with config: model='Qwen/Qwen3-14B', speculative_config=None, tokenizer='Qwen/Qwen3-14B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser='', reasoning_parser_plugin='', enable_in_reasoning=False), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-14B, enable_prefix_caching=True, enable_chunked_prefill=True, pooler_config=None, compilation_config={'level': None, 'mode': <CompilationMode.VLLM_COMPILE: 3>, 'debug_dump_path': None, 'cache_dir': '', 'compile_cache_save_format': 'binary', 'backend': 'inductor', 'custom_ops': ['none'], 'splitting_ops': ['vllm::unified_attention', 'vllm::unified_attention_with_output', 'vllm::unified_mla_attention', 'vllm::unified_mla_attention_with_output', 'vllm::mamba_mixer2', 'vllm::mamba_mixer', 'vllm::short_conv', 'vllm::linear_attention', 'vllm::plamo2_mamba_mixer', 'vllm::gdn_attention_core', 'vllm::kda_attention', 'vllm::sparse_attn_indexer'], 'compile_mm_encoder': False, 'use_inductor': None, 'compile_sizes': [], 'inductor_compile_config': {'enable_auto_functionalized_v2': False, 'combo_kernels': True, 'benchmark_combo_kernel': True}, 'inductor_passes': {}, 'cudagraph_mode': <CUDAGraphMode.FULL_AND_PIECEWISE: (2, 1)>, 'cudagraph_num_of_warmups': 1, 'cudagraph_capture_sizes': [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496, 512], 'cudagraph_copy_inputs': False, 'cudagraph_specialize_lora': True, 'use_inductor_graph_partition': False, 'pass_config': {}, 'max_cudagraph_capture_size': 512, 'local_cache_dir': None}
[1;36m(EngineCore_DP0 pid=2228376)[0;0m INFO 12-04 14:37:51 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:53381 backend=nccl
[1;36m(EngineCore_DP0 pid=2228379)[0;0m INFO 12-04 14:37:51 [parallel_state.py:1208] world_size=1 rank=0 local_rank=0 distributed_init_method=tcp://10.38.4.102:50005 backend=nccl
[W1204 14:37:51.221459534 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:53381 (errno: 97 - Address family not supported by protocol).
[W1204 14:37:51.221666411 socket.cpp:767] [c10d] The client socket cannot be initialized to connect to [gpu-26-3.rc.tch.harvard.edu]:50005 (errno: 97 - Address family not supported by protocol).
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2228376)[0;0m INFO 12-04 14:37:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2228379)[0;0m INFO 12-04 14:37:51 [parallel_state.py:1394] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2228376)[0;0m INFO 12-04 14:37:52 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2228379)[0;0m INFO 12-04 14:37:52 [gpu_model_runner.py:3259] Starting to load model Qwen/Qwen3-14B...
[1;36m(EngineCore_DP0 pid=2228376)[0;0m INFO 12-04 14:37:53 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2228376)[0;0m INFO 12-04 14:37:53 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2228379)[0;0m INFO 12-04 14:37:53 [cuda.py:418] Valid backends: ['FLASH_ATTN', 'FLASHINFER', 'TRITON_ATTN', 'FLEX_ATTENTION']
[1;36m(EngineCore_DP0 pid=2228379)[0;0m INFO 12-04 14:37:53 [cuda.py:427] Using FLASH_ATTN backend.
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m ERROR 12-04 14:37:54 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2228379 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2228376)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2228376)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2228376)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2228376)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228376)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 54.00 MiB is free. Including non-PyTorch memory, this process has 21.87 GiB memory in use. Process 2228379 has 22.51 GiB memory in use. Of the allocated memory 21.35 GiB is allocated by PyTorch, and 18.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self._init_executor()
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     super().__init__(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m ERROR 12-04 14:37:54 [core.py:842] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2228376 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 846, in run_engine_core
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 833, in run_engine_core
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 606, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 102, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/abstract.py", line 101, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/executor/uniproc_executor.py", line 48, in _init_executor
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     self.driver_worker.load_model()
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 273, in load_model
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 3276, in load_model
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 49, in load_model
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     model = initialize_model(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m             ^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 55, in initialize_model
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 279, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     self.model = Qwen3Model(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m                  ^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 253, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 276, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     old_init(self, **kwargs)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 337, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 651, in make_layers
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_DP0 pid=2228379)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 339, in <lambda>
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     lambda prefix: decoder_layer_type(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m                    ^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen3.py", line 201, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     self.mlp = Qwen3MLP(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/models/qwen2.py", line 84, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 631, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     super().__init__(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 484, in __init__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 215, in create_weights
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     data=torch.empty(
[1;36m(EngineCore_DP0 pid=2228379)[0;0m          ^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m   File "/home/ch269957/.conda/envs/slm/lib/python3.12/site-packages/torch/utils/_device.py", line 103, in __torch_function__
[1;36m(EngineCore_DP0 pid=2228379)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=2228379)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=2228379)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 340.00 MiB. GPU 0 has a total capacity of 44.39 GiB of which 34.00 MiB is free. Process 2228376 has 21.87 GiB memory in use. Including non-PyTorch memory, this process has 22.48 GiB memory in use. Of the allocated memory 21.96 GiB is allocated by PyTorch, and 18.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W1204 14:37:55.413510574 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[rank0]:[W1204 14:37:55.413510456 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:38:16 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
Error occurred: Engine core initialization failed. See root cause above. Failed core proc(s): {}
Retrying due to an error......
[ModelCache] Loading model: Qwen/Qwen3-14B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-14B
[ModelCache] Detected 1 GPU(s), 44.4GB total VRAM
[ModelCache] Using tensor_parallel_size=1
INFO 12-04 14:38:16 [utils.py:253] non-default args: {'max_model_len': 40960, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'model': 'Qwen/Qwen3-14B'}
INFO 12-04 14:38:16 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:38:16 [model.py:1745] Using max model len 40960
INFO 12-04 14:38:16 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 12-04 14:38:16 [model.py:631] Resolved architecture: Qwen3ForCausalLM
INFO 12-04 14:38:16 [model.py:1745] Using max model len 40960
INFO 12-04 14:38:16 [scheduler.py:216] Chunked prefill is enabled with max_num_batched_tokens=8192.
slurmstepd-gpu-26-3: error: *** STEP 12735850.0 ON gpu-26-3 CANCELLED AT 2025-12-04T14:38:17 ***
