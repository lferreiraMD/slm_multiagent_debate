Auto-enabled temperature diversity (no model/persona diversity detected)
Using 5 different temperatures: ['0.50', '0.62', '0.75', '0.87', '1.00']
============================================================
Math Task - Multiagent Debate (NO COMPRESSION)
============================================================
Model: Qwen/Qwen3-0.6B
Temperature diversity mode:
  Agent 1: temp=0.5
  Agent 2: temp=0.6249975
  Agent 3: temp=0.749995
  Agent 4: temp=0.8749925000000001
  Agent 5: temp=0.99999
Agents: 5
Rounds: 3
Problems: 20
Generation params: {'temperature': 1.0, 'max_tokens': None, 'top_p': 1.0, 'n': 1}
============================================================
  0%|          | 0/20 [00:00<?, ?it/s]
--- Problem 1/20, Round 1, Agent 1/5 ---
INFO 12-03 14:46:52 [__init__.py:216] Automatically detected platform cuda.
[ModelCache] Loading model: Qwen/Qwen3-0.6B (backend=vllm)
[ModelCache] Using max_model_len=40960 for Qwen/Qwen3-0.6B
[ModelCache] Auto-config: 2 GPU(s) detected, tensor_parallel_size=2
INFO 12-03 14:46:54 [utils.py:233] non-default args: {'max_model_len': 40960, 'tensor_parallel_size': 2, 'max_num_batched_tokens': 8192, 'disable_log_stats': True, 'disable_custom_all_reduce': True, 'enable_chunked_prefill': True, 'enable_sleep_mode': True}
INFO 12-03 14:46:54 [model.py:547] Resolved architecture: Qwen3ForCausalLM
`torch_dtype` is deprecated! Use `dtype` instead!
INFO 12-03 14:46:54 [model.py:1510] Using max model len 40960
INFO 12-03 14:46:54 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=8192.
WARNING 12-03 14:46:55 [__init__.py:3036] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized
INFO 12-03 14:46:58 [__init__.py:216] Automatically detected platform cuda.
[1;36m(EngineCore_DP0 pid=536623)[0;0m INFO 12-03 14:46:58 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=536623)[0;0m INFO 12-03 14:46:58 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='Qwen/Qwen3-0.6B', speculative_config=None, tokenizer='Qwen/Qwen3-0.6B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-0.6B, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention","vllm.sparse_attn_indexer"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":[2,1],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[1;36m(EngineCore_DP0 pid=536623)[0;0m WARNING 12-03 14:46:58 [multiproc_executor.py:720] Reducing Torch parallelism from 16 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
[1;36m(EngineCore_DP0 pid=536623)[0;0m INFO 12-03 14:46:58 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1], buffer_handle=(2, 16777216, 10, 'psm_987c9c12'), local_subscribe_addr='ipc:///tmp/225f6ce5-102b-4673-b176-1d7fe64cf024', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 12-03 14:47:00 [__init__.py:216] Automatically detected platform cuda.
INFO 12-03 14:47:00 [__init__.py:216] Automatically detected platform cuda.
INFO 12-03 14:47:03 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_30bb6b9a'), local_subscribe_addr='ipc:///tmp/269f3374-00ab-4ac2-9d6a-cae058035577', remote_subscribe_addr=None, remote_addr_ipv6=False)
INFO 12-03 14:47:04 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_593df11e'), local_subscribe_addr='ipc:///tmp/6a7c32df-3bde-4ab9-b751-a6aec7cd197c', remote_subscribe_addr=None, remote_addr_ipv6=False)
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
INFO 12-03 14:47:04 [__init__.py:1384] Found nccl from library libnccl.so.2
INFO 12-03 14:47:04 [__init__.py:1384] Found nccl from library libnccl.so.2
INFO 12-03 14:47:04 [pynccl.py:103] vLLM is using nccl==2.27.3
INFO 12-03 14:47:04 [pynccl.py:103] vLLM is using nccl==2.27.3
WARNING 12-03 14:47:04 [symm_mem.py:58] SymmMemCommunicator: Device capability 8.6 not supported, communicator is not available.
WARNING 12-03 14:47:04 [symm_mem.py:58] SymmMemCommunicator: Device capability 8.6 not supported, communicator is not available.
INFO 12-03 14:47:04 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_c8a3343a'), local_subscribe_addr='ipc:///tmp/03471fdd-3151-4e7e-b590-fff2dcb1b3bc', remote_subscribe_addr=None, remote_addr_ipv6=False)
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
INFO 12-03 14:47:04 [__init__.py:1384] Found nccl from library libnccl.so.2
INFO 12-03 14:47:04 [pynccl.py:103] vLLM is using nccl==2.27.3
[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1
INFO 12-03 14:47:04 [__init__.py:1384] Found nccl from library libnccl.so.2
INFO 12-03 14:47:04 [pynccl.py:103] vLLM is using nccl==2.27.3
INFO 12-03 14:47:04 [parallel_state.py:1208] rank 1 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1
INFO 12-03 14:47:04 [parallel_state.py:1208] rank 0 in world size 2 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
INFO 12-03 14:47:04 [topk_topp_sampler.py:55] Using FlashInfer for top-p & top-k sampling.
INFO 12-03 14:47:04 [topk_topp_sampler.py:55] Using FlashInfer for top-p & top-k sampling.
[1;36m(Worker_TP1 pid=536708)[0;0m INFO 12-03 14:47:04 [gpu_model_runner.py:2602] Starting to load model Qwen/Qwen3-0.6B...
[1;36m(Worker_TP0 pid=536707)[0;0m INFO 12-03 14:47:04 [gpu_model_runner.py:2602] Starting to load model Qwen/Qwen3-0.6B...
[1;36m(Worker_TP1 pid=536708)[0;0m INFO 12-03 14:47:04 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(Worker_TP0 pid=536707)[0;0m INFO 12-03 14:47:04 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(Worker_TP1 pid=536708)[0;0m INFO 12-03 14:47:04 [cuda.py:366] Using Flash Attention backend on V1 engine.
[1;36m(Worker_TP0 pid=536707)[0;0m INFO 12-03 14:47:04 [cuda.py:366] Using Flash Attention backend on V1 engine.
[1;36m(Worker_TP1 pid=536708)[0;0m INFO 12-03 14:47:04 [weight_utils.py:392] Using model weights format ['*.safetensors']
[1;36m(Worker_TP0 pid=536707)[0;0m INFO 12-03 14:47:05 [weight_utils.py:392] Using model weights format ['*.safetensors']
[1;36m(Worker_TP1 pid=536708)[0;0m INFO 12-03 14:47:05 [weight_utils.py:450] No model.safetensors.index.json found in remote.
[1;36m(Worker_TP0 pid=536707)[0;0m INFO 12-03 14:47:05 [weight_utils.py:450] No model.safetensors.index.json found in remote.
[1;36m(Worker_TP0 pid=536707)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
[1;36m(Worker_TP1 pid=536708)[0;0m INFO 12-03 14:47:05 [default_loader.py:267] Loading weights took 0.14 seconds
[1;36m(Worker_TP0 pid=536707)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.20it/s]
[1;36m(Worker_TP0 pid=536707)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  8.19it/s]
[1;36m(Worker_TP0 pid=536707)[0;0m 
[1;36m(Worker_TP0 pid=536707)[0;0m INFO 12-03 14:47:05 [default_loader.py:267] Loading weights took 0.14 seconds
[1;36m(Worker_TP1 pid=536708)[0;0m INFO 12-03 14:47:05 [gpu_model_runner.py:2653] Model loading took 0.5660 GiB and 0.383774 seconds
[1;36m(Worker_TP0 pid=536707)[0;0m INFO 12-03 14:47:05 [gpu_model_runner.py:2653] Model loading took 0.5660 GiB and 0.473392 seconds
[1;36m(Worker_TP1 pid=536708)[0;0m INFO 12-03 14:47:09 [backends.py:548] Using cache directory: /home/leonardo/.cache/vllm/torch_compile_cache/d13988b57d/rank_1_0/backbone for vLLM's torch.compile
[1;36m(Worker_TP1 pid=536708)[0;0m INFO 12-03 14:47:09 [backends.py:559] Dynamo bytecode transform time: 3.54 s
[1;36m(Worker_TP0 pid=536707)[0;0m INFO 12-03 14:47:09 [backends.py:548] Using cache directory: /home/leonardo/.cache/vllm/torch_compile_cache/d13988b57d/rank_0_0/backbone for vLLM's torch.compile
[1;36m(Worker_TP0 pid=536707)[0;0m INFO 12-03 14:47:09 [backends.py:559] Dynamo bytecode transform time: 3.62 s
[1;36m(Worker_TP1 pid=536708)[0;0m INFO 12-03 14:47:10 [backends.py:164] Directly load the compiled graph(s) for dynamic shape from the cache, took 1.024 s
[1;36m(Worker_TP0 pid=536707)[0;0m INFO 12-03 14:47:11 [backends.py:164] Directly load the compiled graph(s) for dynamic shape from the cache, took 1.056 s
[1;36m(Worker_TP1 pid=536708)[0;0m INFO 12-03 14:47:11 [monitor.py:34] torch.compile takes 3.54 s in total
[1;36m(Worker_TP0 pid=536707)[0;0m INFO 12-03 14:47:11 [monitor.py:34] torch.compile takes 3.62 s in total
[1;36m(Worker_TP1 pid=536708)[0;0m INFO 12-03 14:47:12 [gpu_worker.py:298] Available KV cache memory: 20.17 GiB
[1;36m(Worker_TP0 pid=536707)[0;0m INFO 12-03 14:47:12 [gpu_worker.py:298] Available KV cache memory: 20.17 GiB
[1;36m(EngineCore_DP0 pid=536623)[0;0m INFO 12-03 14:47:12 [kv_cache_utils.py:1087] GPU KV cache size: 377,584 tokens
[1;36m(EngineCore_DP0 pid=536623)[0;0m INFO 12-03 14:47:12 [kv_cache_utils.py:1091] Maximum concurrency for 40,960 tokens per request: 9.22x
[1;36m(EngineCore_DP0 pid=536623)[0;0m INFO 12-03 14:47:12 [kv_cache_utils.py:1087] GPU KV cache size: 377,584 tokens
[1;36m(EngineCore_DP0 pid=536623)[0;0m INFO 12-03 14:47:12 [kv_cache_utils.py:1091] Maximum concurrency for 40,960 tokens per request: 9.22x
[1;36m(Worker_TP0 pid=536707)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|â–Œ         | 4/67 [00:00<00:01, 32.89it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|â–ˆâ–        | 8/67 [00:00<00:01, 33.47it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 12/67 [00:00<00:01, 33.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|â–ˆâ–ˆâ–       | 16/67 [00:00<00:01, 34.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:00<00:01, 35.01it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/67 [00:00<00:01, 35.45it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/67 [00:00<00:01, 35.30it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 32/67 [00:00<00:01, 34.95it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/67 [00:01<00:00, 35.89it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:01<00:00, 36.94it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:01<00:00, 38.28it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:01<00:00, 38.53it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:01<00:00, 38.73it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 58/67 [00:01<00:00, 39.71it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:01<00:00, 38.77it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 66/67 [00:01<00:00, 38.51it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:01<00:00, 36.60it/s]
[1;36m(Worker_TP0 pid=536707)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/35 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):  11%|â–ˆâ–        | 4/35 [00:00<00:00, 37.26it/s]Capturing CUDA graphs (decode, FULL):  23%|â–ˆâ–ˆâ–Ž       | 8/35 [00:00<00:00, 38.79it/s]Capturing CUDA graphs (decode, FULL):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 13/35 [00:00<00:00, 41.00it/s]Capturing CUDA graphs (decode, FULL):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/35 [00:00<00:00, 42.45it/s]Capturing CUDA graphs (decode, FULL):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 23/35 [00:00<00:00, 42.67it/s]Capturing CUDA graphs (decode, FULL):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 28/35 [00:00<00:00, 43.91it/s]Capturing CUDA graphs (decode, FULL):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/35 [00:00<00:00, 42.69it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:00<00:00, 42.30it/s]
[1;36m(Worker_TP1 pid=536708)[0;0m INFO 12-03 14:47:15 [gpu_model_runner.py:3480] Graph capturing finished in 3 secs, took 1.06 GiB
[1;36m(Worker_TP0 pid=536707)[0;0m INFO 12-03 14:47:15 [gpu_model_runner.py:3480] Graph capturing finished in 3 secs, took 1.06 GiB
[1;36m(EngineCore_DP0 pid=536623)[0;0m INFO 12-03 14:47:15 [core.py:210] init engine (profile, create kv cache, warmup model) took 10.22 seconds
INFO 12-03 14:47:16 [llm.py:306] Supported_tasks: ['generate']

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 439.42it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.07s/it, est. speed input: 15.66 toks/s, output: 304.65 toks/s][A
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.07s/it, est. speed input: 15.66 toks/s, output: 304.65 toks/s][AProcessed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.07s/it, est. speed input: 15.66 toks/s, output: 304.65 toks/s]
Agent 1 response: The result of the expression $6 + 19 \times 28 + 14 - 10 \times 7$ is **482**....

--- Problem 1/20, Round 1, Agent 2/5 ---
[ModelCache] Using cached model: Qwen/Qwen3-0.6B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 2238.16it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.24s/it, est. speed input: 21.41 toks/s, output: 308.69 toks/s][A
Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.24s/it, est. speed input: 21.41 toks/s, output: 308.69 toks/s][AProcessed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.24s/it, est. speed input: 21.41 toks/s, output: 308.69 toks/s]
Agent 2 response: The result of the expression 6 + 19*28 + 14 - 10*7 is 482....

--- Problem 1/20, Round 1, Agent 3/5 ---
[ModelCache] Using cached model: Qwen/Qwen3-0.6B

Adding requests:   0%|          | 0/1 [00:00<?, ?it/s][AAdding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 2510.06it/s]

Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s][A