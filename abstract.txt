Multi-Agent Debate (MAD) has been a promising mechanism to improve reasoning and factual consistency in language models. In multi-agent debate, multiple agents propose answers, critique each other, and converge to an ideally superior solution. Prior work (Du et al., 2023) treats agents as symmetric peers, but doesn’t fully answer why multi-agent debate helps. In this research project, we propose that cognitive diversity among agents, such as variation in reasoning style, prompting priors, or heuristics, is a key driver of multi-agent debate gains.

We adopt a small-language-model (SLM) setting (e.g., 1.5B-4B parameter range) to examine this hypothesis in a cost-effective, reproducible environment. We construct multiple debate conditions: (1) homogeneous groups of agents all using the same model and prompt style; (2) heterogeneous groups where the same model is prompted to adopt distinct reasoning styles (such as “intuitive”, “slow”, “skeptic”); (3) heterogeneous groups composed of different models; and (4) heterogeneous groups varying on the decoding parameters. We hold the number of agents and rounds constant, and evaluate on benchmark reasoning and factuality tasks (such as GSM8K word problems, biography generation, and MMLU multiple-choice questions).

In this paper, we introduce a diversity-gain metric that quantifies improvements in outcome quality (accuracy) as a function of response embedding and argument diversity (measured via cosine distances, disagreement rates), as referenced in a critique of MAD presented by Wynn et. al., 2025. We then test whether higher intra-group stylistic/response variance correlates with higher accuracy gains.